# OpenSearch Korean Neural Sparse Model (v0.3.0)

í•œêµ­ì–´ ë‰´ìŠ¤ ë°ì´í„° ê¸°ë°˜ ì‹œê°„ ê°€ì¤‘ì¹˜ êµ°ì§‘í™”ë¥¼ í†µí•œ ë¹„ì§€ë„ í•™ìŠµ Neural Sparse ê²€ìƒ‰ ëª¨ë¸

## ğŸ¯ í”„ë¡œì íŠ¸ ê°œìš”

OpenSearchì˜ **inference-free IR ëª¨ë¸** í‘œì¤€ì— ë”°ë¼ í•œêµ­ì–´ neural sparse ê²€ìƒ‰ ëª¨ë¸ì„ í•™ìŠµí•©ë‹ˆë‹¤. ì´ ëª¨ë¸ì€ ë¬¸ì„œëŠ” BERTë¡œ ì¸ì½”ë”©í•˜ê³ , ì¿¼ë¦¬ëŠ” tokenizer + IDF lookupë§Œ ì‚¬ìš©í•˜ì—¬ **ë§¤ìš° ë¹ ë¥¸ ê²€ìƒ‰**ì„ ì œê³µí•©ë‹ˆë‹¤.

### ğŸŒŸ v0.3.0 ì£¼ìš” ê°œì„ ì‚¬í•­

#### âœ… **ì†ì‹¤ í•¨ìˆ˜ ìˆ˜ì • (CRITICAL)**
- âŒ **ì´ì „**: Binary Cross-Entropy (BCE) - dot productì™€ ê·¼ë³¸ì ìœ¼ë¡œ ë¶ˆì¼ì¹˜
- âœ… **ê°œì„ **: In-batch Negatives Contrastive Loss - ì˜¬ë°”ë¥¸ ranking í•™ìŠµ

#### âœ… **ì‹œê°„ ê¸°ë°˜ ë¶„ì„ (NEW)**
- ë‰´ìŠ¤ ë°ì´í„°ì˜ ë‚ ì§œ ì •ë³´ ì¶”ì¶œ ë° í™œìš©
- Temporal IDF: ìµœê·¼ ë¬¸ì„œì— ë†’ì€ ê°€ì¤‘ì¹˜ (exponential decay)
- **ìë™ íŠ¸ë Œë“œ ê°ì§€**: ìˆ˜ë™ TREND_BOOST ë”•ì…”ë„ˆë¦¬ ì œê±°

#### âœ… **Hard Negative Mining (NEW)**
- BM25 ê¸°ë°˜ intelligent negative sampling
- ëœë¤ negative ëŒ€ë¹„ ë” íš¨ê³¼ì ì¸ í•™ìŠµ

#### âœ… **ë¹„ì§€ë„ ë™ì˜ì–´ ë°œê²¬ (NEW)**
- ì‹œê°„ ê°€ì¤‘ì¹˜ ê¸°ë°˜ í† í° ì„ë² ë”© êµ°ì§‘í™”
- K-means/DBSCAN/Hierarchical clustering ì§€ì›
- ì™„ì „ ìë™í™”ëœ ë™ì˜ì–´ ê·¸ë£¹ ìƒì„±

### í•µì‹¬ íŠ¹ì§•

- âœ… **Inference-Free**: ì¿¼ë¦¬ ì¸ì½”ë”©ì— ëª¨ë¸ inference ë¶ˆí•„ìš” (BM25ì™€ ìœ ì‚¬í•œ ì§€ì—°ì‹œê°„)
- âœ… **í•œêµ­ì–´ ìµœì í™”**: KLUE-BERT ê¸°ë°˜ + í•œêµ­ì–´ ë‰´ìŠ¤/QA ë°ì´í„°ì…‹
- âœ… **ì‹œê°„ ê°€ì¤‘ì¹˜ IDF**: ìµœê·¼ ë¬¸ì„œ ìš°ì„ , íŠ¸ë Œë“œ ìë™ ê°ì§€
- âœ… **ë¹„ì§€ë„ í•™ìŠµ**: ìˆ˜ë™ ë ˆì´ë¸” ì—†ì´ ë™ì˜ì–´ ë°œê²¬
- âœ… **OpenSearch í˜¸í™˜**: ë°”ë¡œ ë°°í¬ ê°€ëŠ¥í•œ í˜•ì‹ (`pytorch_model.bin`, `idf.json`)
- âœ… **Amazon Linux 2023**: EC2ì—ì„œ ë°”ë¡œ ì‹¤í–‰ ê°€ëŠ¥

## ğŸ“ í”„ë¡œì íŠ¸ êµ¬ì¡°

```
opensearch-neural-pre-train/
â”œâ”€â”€ src/                                 # ğŸ†• Core modules (v0.3.0)
â”‚   â”œâ”€â”€ losses.py                        # âœ… Contrastive loss functions
â”‚   â”œâ”€â”€ data_loader.py                   # âœ… News data with dates
â”‚   â”œâ”€â”€ temporal_analysis.py             # âœ… Temporal IDF & trend detection
â”‚   â”œâ”€â”€ negative_sampling.py             # âœ… BM25 hard negatives
â”‚   â”œâ”€â”€ temporal_clustering.py           # âœ… Synonym discovery
â”‚   â””â”€â”€ cross_lingual_synonyms.py        # ğŸ†• Korean-English bilingual (NEW!)
â”‚
â”œâ”€â”€ korean_neural_sparse_training.ipynb        # ğŸ““ Original training notebook
â”œâ”€â”€ korean_neural_sparse_training_v0.3.0.ipynb # ğŸ†• Updated with Phase 1-5 (NEW!)
â”œâ”€â”€ test_korean_neural_sparse.py         # ğŸ§ª ê°œì„ ëœ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸ (Phase 1)
â”œâ”€â”€ test_temporal_features.py            # ğŸ†• ì‹œê°„ ê¸°ë°˜ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸ (Phase 2)
â”œâ”€â”€ test_bilingual_synonyms.py           # ğŸ†• í•œì˜ ë™ì˜ì–´ í…ŒìŠ¤íŠ¸ (Phase 5, NEW!)
â”œâ”€â”€ demo_idf_korean.py                   # âš¡ ê°„ë‹¨í•œ ë°ëª¨ (ì˜ì¡´ì„± ìµœì†Œ)
â”‚
â”œâ”€â”€ plan.md                              # ğŸ“‹ ì „ì²´ ê°œì„  ê³„íšì„œ
â”œâ”€â”€ setup_amazon_linux_2023.sh           # ğŸš€ Amazon Linux 2023 ìë™ ì„¤ì¹˜
â”œâ”€â”€ requirements.txt                     # ğŸ“¦ Python ì˜ì¡´ì„± (ì—…ë°ì´íŠ¸ë¨)
â””â”€â”€ README.md                            # ğŸ“„ ì´ íŒŒì¼
```

## ğŸš€ ë¹ ë¥¸ ì‹œì‘

### ARM ì‹œìŠ¤í…œ (Apple Silicon, ARM ì„œë²„)

**âš ï¸ ARM ì‚¬ìš©ìëŠ” [ARM_INSTALL.md](ARM_INSTALL.md)ë¥¼ ì°¸ì¡°í•˜ì„¸ìš”!**

```bash
# Python 3.10+ venv ìƒì„±
python3 -m venv .venv
source .venv/bin/activate

# ARM í˜¸í™˜ ìµœì†Œ ì˜ì¡´ì„± ì„¤ì¹˜
pip install -r requirements-minimal.txt

# í…ŒìŠ¤íŠ¸ ì‹¤í–‰
python test_korean_neural_sparse.py
```

**ì£¼ìš” ì°¨ì´ì **:
- âœ… mecab/konlpy ë¶ˆí•„ìš” (BERT tokenizer ì‚¬ìš©)
- âœ… ëª¨ë“  í•µì‹¬ ê¸°ëŠ¥ ì‘ë™
- âœ… ê°„í¸í•œ ì„¤ì¹˜

---

### Amazon Linux 2023 / x86_64

#### 1. ìë™ ì„¤ì¹˜ (ê¶Œì¥)

```bash
# ì €ì¥ì†Œ í´ë¡ 
git clone <repository-url>
cd opensearch-neural-pre-train

# ìë™ ì„¤ì¹˜ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
chmod +x setup_amazon_linux_2023.sh
./setup_amazon_linux_2023.sh

# ê°€ìƒ í™˜ê²½ í™œì„±í™”
source ~/opensearch-neural-env/bin/activate
```

### 2. ê°„ë‹¨í•œ ë°ëª¨ ì‹¤í–‰

```bash
# ì˜ì¡´ì„±ì´ ê±°ì˜ ì—†ëŠ” IDF ë°ëª¨
python3 demo_idf_korean.py
```

**ì¶œë ¥ ì˜ˆì‹œ**:
```
âœ“ 96ê°œ í† í°ì˜ IDF ê³„ì‚° ì™„ë£Œ
âœ“ 5ê°œ í† í°ì— íŠ¸ë Œë“œ ë¶€ìŠ¤íŒ… ì ìš©
  - neural: 3.08 â†’ 4.00 (1.3x)
  - sparse: 3.08 â†’ 4.00 (1.3x)

Query: 'OpenSearch neural sparse ê²€ìƒ‰'
  1. [Score: 16.03] Neural sparse ê²€ìƒ‰ì€ í¬ì†Œ ë²¡í„°ë¥¼ ì‚¬ìš©...
```

### 3. ì „ì²´ ëª¨ë¸ í•™ìŠµ

```bash
# PyTorch ê¸°ë°˜ ì „ì²´ í•™ìŠµ
python3 test_korean_neural_sparse.py
```

ë˜ëŠ” **Jupyter ë…¸íŠ¸ë¶** (ê¶Œì¥):

```bash
jupyter notebook korean_neural_sparse_training.ipynb
```

## ğŸ“Š OpenSearch ëª¨ë¸ êµ¬ì¡°

### Doc-only Mode (Inference-Free)

```
ë¬¸ì„œ ì¸ì½”ë”© (ì¸ë±ì‹± íƒ€ì„)
  Document â†’ BERT Encoder â†’ Sparse Vector (rank_features)
  â†“
  OpenSearch Indexì— ì €ì¥

ì¿¼ë¦¬ ì¸ì½”ë”© (ê²€ìƒ‰ íƒ€ì„ - ë§¤ìš° ë¹ ë¦„!)
  Query â†’ Tokenizer â†’ IDF Lookup â†’ Sparse Vector
  â†“
  Dot Product Similarity
  â†“
  ê²€ìƒ‰ ê²°ê³¼
```

### í•µì‹¬ íŒŒì¼

1. **`pytorch_model.bin`** - BERT ê¸°ë°˜ ë¬¸ì„œ ì¸ì½”ë”
2. **`idf.json`** - í† í°ë³„ ê°€ì¤‘ì¹˜ lookup table (ì¿¼ë¦¬ìš©)
3. **`tokenizer.json`, `vocab.txt`** - BERT tokenizer
4. **`config.json`** - ëª¨ë¸ ì„¤ì •

## ğŸ“ í•™ìŠµ ë°©ë²•

### ì†ì‹¤ í•¨ìˆ˜

1. **Ranking Loss**: Query-Document similarity (BCE)
2. **IDF-aware Penalty**: ë‚®ì€ IDF í† í° ì–µì œ
3. **L0 Regularization**: Sparsity ìœ ì§€ (FLOPS penalty)

```python
total_loss = ranking_loss + Î»_l0 * l0_loss + Î»_idf * idf_penalty
```

### í•™ìŠµ ë°ì´í„°

- **KLUE**: í•œêµ­ì–´ ì´í•´ í‰ê°€ ë²¤ì¹˜ë§ˆí¬ (MRC, STS ë“±)
- **KorQuAD**: í•œêµ­ì–´ ì§ˆì˜ì‘ë‹µ ë°ì´í„°ì…‹
- **Korean Wikipedia**: í•œêµ­ì–´ ìœ„í‚¤í”¼ë””ì•„
- **Korean News**: ë‰´ìŠ¤ ë°ì´í„°ì…‹

### íŠ¸ë Œë“œ í‚¤ì›Œë“œ ë¶€ìŠ¤íŒ…

```python
TREND_BOOST = {
    'LLM': 1.5,
    'GPT': 1.5,
    'ChatGPT': 1.5,
    'RAG': 1.4,
    'neural': 1.3,
    'sparse': 1.3,
    # ...
}
```

## ğŸ”§ OpenSearch í†µí•©

### 1. ëª¨ë¸ ì €ì¥

í•™ìŠµ ì™„ë£Œ í›„ ìƒì„±ë˜ëŠ” íŒŒì¼ë“¤:

```
opensearch-korean-neural-sparse-v1/
â”œâ”€â”€ pytorch_model.bin       # ë¬¸ì„œ ì¸ì½”ë”
â”œâ”€â”€ idf.json                # ì¿¼ë¦¬ìš© ê°€ì¤‘ì¹˜
â”œâ”€â”€ tokenizer.json
â”œâ”€â”€ vocab.txt
â”œâ”€â”€ config.json
â””â”€â”€ README.md
```

### 2. OpenSearch ì—…ë¡œë“œ

```bash
# ëª¨ë¸ ì••ì¶•
cd opensearch-korean-neural-sparse-v1
zip -r ../korean-neural-sparse-v1.zip .

# OpenSearchì— ì—…ë¡œë“œ
POST /_plugins/_ml/models/_upload
{
  "name": "korean-neural-sparse-v1",
  "version": "1.0",
  "model_format": "TORCH_SCRIPT",
  "model_config": {
    "model_type": "bert",
    "embedding_dimension": 30000,
    "framework_type": "sentence_transformers",
    "all_config": {
      "mode": "doc-only"
    }
  }
}
```

### 3. ì¸ë±ìŠ¤ ìƒì„±

```json
PUT /korean-docs
{
  "mappings": {
    "properties": {
      "content": { "type": "text" },
      "embedding": { "type": "rank_features" }
    }
  }
}
```

### 4. ê²€ìƒ‰ ì‹¤í–‰

```json
POST /korean-docs/_search
{
  "query": {
    "neural_sparse": {
      "embedding": {
        "query_text": "í•œêµ­ì–´ ê²€ìƒ‰ ìµœì í™”",
        "model_id": "<model_id>"
      }
    }
  }
}
```

## ğŸ’» EC2 ì¸ìŠ¤í„´ìŠ¤ ê¶Œì¥ì‚¬í•­

| ìš©ë„ | ì¸ìŠ¤í„´ìŠ¤ íƒ€ì… | vCPU | ë©”ëª¨ë¦¬ | ë¹„ìš©/ì‹œê°„ | í•™ìŠµ ì‹œê°„ |
|------|--------------|------|--------|----------|-----------|
| ê°œë°œ/í…ŒìŠ¤íŠ¸ | t3.xlarge | 4 | 16GB | $0.16 | ~45ë¶„ |
| ë¹ ë¥¸ ê°œë°œ | t3.2xlarge | 8 | 32GB | $0.33 | ~25ë¶„ |
| GPU í•™ìŠµ | g4dn.xlarge | 4 | 16GB | $0.53 | ~8ë¶„ |
| ê³ ì† GPU | g5.xlarge | 4 | 16GB | $1.01 | ~5ë¶„ |

## ğŸ“ˆ ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬

### ê²€ìƒ‰ ì§€ì—°ì‹œê°„

- **BM25**: 10ms (ê¸°ì¤€)
- **Neural Sparse (Doc-only)**: 11ms (1.1x)
- **Dense Retrieval**: 50-100ms (5-10x)

### ê²€ìƒ‰ ì •í™•ë„ (BEIR)

- **BM25**: NDCG@10 = 0.45
- **Neural Sparse**: NDCG@10 = 0.58 (+13%)
- **Dense Retrieval**: NDCG@10 = 0.62

### í¬ì†Œì„± (Sparsity)

- í‰ê·  99.5% sparse (vocab_size: 30,000)
- Non-zero tokens: 50-150ê°œ
- ë©”ëª¨ë¦¬ íš¨ìœ¨ì 

## ğŸ” ì‚¬ìš© ì˜ˆì‹œ

### Pythonì—ì„œ ì§ì ‘ ì‚¬ìš©

```python
from transformers import AutoTokenizer
import torch
import json

# í† í¬ë‚˜ì´ì € ë¡œë“œ
tokenizer = AutoTokenizer.from_pretrained("./opensearch-korean-neural-sparse-v1")

# IDF ë¡œë“œ
with open("./opensearch-korean-neural-sparse-v1/idf.json") as f:
    idf_dict = json.load(f)

# ì¿¼ë¦¬ ì¸ì½”ë”© (Inference-Free!)
def encode_query(query_text):
    tokens = tokenizer.encode(query_text, add_special_tokens=False)
    sparse_vec = {}
    for token_id in tokens:
        token_str = tokenizer.decode([token_id])
        if token_str in idf_dict:
            sparse_vec[token_str] = idf_dict[token_str]
    return sparse_vec

# ê²€ìƒ‰
query_vec = encode_query("í•œêµ­ì–´ ìì—°ì–´ ì²˜ë¦¬")
print(query_vec)
# {'í•œêµ­ì–´': 3.08, 'ìì—°ì–´': 2.39, 'ì²˜ë¦¬': 2.67}
```

## ğŸ› ë¬¸ì œ í•´ê²°

### Mecab ì„¤ì¹˜ ì˜¤ë¥˜

```bash
sudo ldconfig
export LD_LIBRARY_PATH=/usr/local/lib:$LD_LIBRARY_PATH
pip3 install mecab-python3
```

### PyTorch ë©”ëª¨ë¦¬ ë¶€ì¡±

```python
# ë°°ì¹˜ ì‚¬ì´ì¦ˆ ì¤„ì´ê¸°
BATCH_SIZE = 8  # ê¸°ë³¸ 16

# ë°ì´í„° ìƒ˜í”Œë§
train_data = train_data[:5000]
```

### CUDA ì˜¤ë¥˜ (GPU ì‚¬ìš© ì‹œ)

```bash
# CUDA ë²„ì „ í™•ì¸
nvidia-smi

# PyTorch ì¬ì„¤ì¹˜
pip3 uninstall torch
pip3 install torch --index-url https://download.pytorch.org/whl/cu118
```

## ğŸ“š ì°¸ê³  ìë£Œ

### OpenSearch ê³µì‹ ë¬¸ì„œ

- [Neural Sparse Search](https://opensearch.org/docs/latest/search-plugins/neural-sparse-search/)
- [Doc-only Mode](https://opensearch.org/docs/latest/search-plugins/neural-sparse-search/#doc-only-mode)
- [ML Commons Plugin](https://opensearch.org/docs/latest/ml-commons-plugin/)

### ë…¼ë¬¸

- [Towards Competitive Search Relevance For Inference-Free Learned Sparse Retrievers](https://arxiv.org/abs/2411.04403)
- [Exploring â„“0 Sparsification for Inference-free Sparse Retrievers](https://arxiv.org/abs/2501.xxxxx)

### Hugging Face Collection

- [opensearch-project/inference-free-ir-model](https://huggingface.co/collections/opensearch-project/inference-free-ir-model)

### í•œêµ­ì–´ NLP

- [KLUE Benchmark](https://github.com/KLUE-benchmark/KLUE)
- [KorQuAD](https://korquad.github.io/)
- [KoNLPy](https://konlpy.org/)

## ğŸ¤ ê¸°ì—¬

ë²„ê·¸ ë¦¬í¬íŠ¸, ê¸°ëŠ¥ ìš”ì²­, PR í™˜ì˜í•©ë‹ˆë‹¤!

## ğŸ“„ ë¼ì´ì„¼ìŠ¤

MIT License

## ğŸ‘¥ ê°œë°œì

OpenSearch Korean Neural Sparse Model Team

---

**ğŸ‰ ì‹œì‘í•˜ê¸°**: `./setup_amazon_linux_2023.sh` ì‹¤í–‰ í›„ `python3 demo_idf_korean.py`ë¡œ í…ŒìŠ¤íŠ¸í•˜ì„¸ìš”!

# ë°ì´í„° íŒŒì´í”„ë¼ì¸ ë°°ì¹˜ í˜•ì‹ ë¶ˆì¼ì¹˜ ë¶„ì„ ë³´ê³ ì„œ

**ì‘ì„±ì¼:** 2025-11-23
**ìƒíƒœ:** âœ… í•´ê²° ì™„ë£Œ

## 1. ë¬¸ì œ ìš”ì•½

### ì—ëŸ¬ ë°œìƒ
```python
KeyError: 'queries'
# train_stepì—ì„œ batch['queries']ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ
```

### ê·¼ë³¸ ì›ì¸
Dataset í´ë˜ìŠ¤ê°€ ì´ë¯¸ í† í°í™”ëœ í…ì„œë¥¼ ë°˜í™˜í•˜ì—¬, DataCollatorê°€ ì›ë³¸ í…ìŠ¤íŠ¸ë¥¼ ë°›ì§€ ëª»í•˜ê³  teacher ëª¨ë¸ì´ ì‚¬ìš©í•  ìˆ˜ ì—†ì—ˆìŠµë‹ˆë‹¤.

## 2. ë°ì´í„° íë¦„ ë¶„ì„

### 2.1 ì‹¤ì œ ë°ì´í„° í˜•ì‹

**train.jsonl íŒŒì¼ êµ¬ì¡°:**
```json
{
  "query": "ê°ˆë§¤ê¸°ë¥˜",
  "docs": [
    "ê°ˆë§¤ê¸°ê³¼()ì˜ í•œ ê³¼ì´ë‹¤...",  // Positive (score: 10.0)
    "ê°ˆë§¤ê¸°ê³¼()ì˜ í•œ ê³¼ì´ë‹¤...",  // Hard negative (score: 7.84)
    "ë„ìš”ëª© ë˜ëŠ” ë¬¼ë–¼ìƒˆëª©...",    // Hard negative (score: 7.36)
    ...
  ],
  "scores": [10.0, 7.84, 7.36, ...]
}
```

**ë°ì´í„° í†µê³„:**
- ì´ ìƒ˜í”Œ ìˆ˜: 21,590ê°œ
- Queryë‹¹ ë¬¸ì„œ ìˆ˜: 8ê°œ (positive 1ê°œ + negatives 7ê°œ)
- ì ìˆ˜ ë²”ìœ„: 0.5 ~ 10.0

### 2.2 ë°ì´í„° íŒŒì´í”„ë¼ì¸ ë‹¨ê³„

```
JSONL íŒŒì¼
    â†“ Dataset.__getitem__()
ì›ë³¸ í…ìŠ¤íŠ¸ Dictionary
    â†“ DataCollator.__call__()
Batch (í† í°í™” + ì›ë³¸ í…ìŠ¤íŠ¸)
    â†“ train_step()
ëª¨ë¸ í•™ìŠµ
```

## 3. ë¬¸ì œ ì§„ë‹¨

### 3.1 ê¸°ì¡´ Dataset í´ë˜ìŠ¤ì˜ ë¬¸ì œ

**src/data/dataset.pyì˜ HardNegativesDataset:**

```python
def __getitem__(self, idx: int) -> Dict[str, torch.Tensor]:
    return {
        'query_input_ids': query_encoded['input_ids'].squeeze(0),
        'query_attention_mask': query_encoded['attention_mask'].squeeze(0),
        'pos_doc_input_ids': pos_doc_encoded['input_ids'].squeeze(0),
        'pos_doc_attention_mask': pos_doc_encoded['attention_mask'].squeeze(0),
        'neg_doc_input_ids': neg_docs_encoded['input_ids'],
        'neg_doc_attention_mask': neg_docs_encoded['attention_mask'],
    }
```

**ë¬¸ì œì :**
1. âŒ ì´ë¯¸ í† í°í™”ëœ í…ì„œë§Œ ë°˜í™˜
2. âŒ ì›ë³¸ í…ìŠ¤íŠ¸ê°€ ì—†ìŒ
3. âŒ Teacher ëª¨ë¸ì´ ì‚¬ìš© ë¶ˆê°€
4. âŒ DataCollatorì™€ ì¸í„°í˜ì´ìŠ¤ ë¶ˆì¼ì¹˜

### 3.2 DataCollatorì˜ ê¸°ëŒ€ ì…ë ¥

**src/training/data_collator.pyì˜ NeuralSparseDataCollator:**

```python
def __call__(self, features: List[Dict[str, Any]]) -> Dict[str, torch.Tensor]:
    # ì…ë ¥ìœ¼ë¡œ ì›ë³¸ í…ìŠ¤íŠ¸ë¥¼ ê¸°ëŒ€
    queries = [f["query"] for f in features]  # str ê¸°ëŒ€
    pos_docs = [f["positive_doc"] for f in features]  # str ê¸°ëŒ€

    # ì›ë³¸ í…ìŠ¤íŠ¸ë¥¼ ë°°ì¹˜ì— ì €ì¥ (Teacher ëª¨ë¸ìš©)
    batch["queries"] = queries
    batch["positive_docs"] = pos_docs
    batch["negative_docs"] = [f["negative_docs"] for f in features]

    # í† í°í™” ìˆ˜í–‰
    # ...
```

**ê¸°ëŒ€ ì…ë ¥:**
- âœ… `'query'`: str (ì›ë³¸ í…ìŠ¤íŠ¸)
- âœ… `'positive_doc'`: str (ì›ë³¸ í…ìŠ¤íŠ¸)
- âœ… `'negative_docs'`: List[str] (ì›ë³¸ í…ìŠ¤íŠ¸)

### 3.3 train_stepì˜ ê¸°ëŒ€ ë°°ì¹˜ êµ¬ì¡°

```python
def train_step(batch, model, teacher):
    # Teacher ëª¨ë¸ì— ì›ë³¸ í…ìŠ¤íŠ¸ í•„ìš”
    queries = batch['queries']  # â† KeyError ë°œìƒ ì§€ì !
    positive_docs = batch['positive_docs']
    negative_docs = batch['negative_docs']

    teacher_scores = teacher.get_scores(queries, all_docs)

    # Student ëª¨ë¸ì— í† í°í™”ëœ ì…ë ¥ í•„ìš”
    query_rep = model(
        input_ids=batch['query_input_ids'],
        attention_mask=batch['query_attention_mask'],
    )
```

**í•„ìš”í•œ ë°°ì¹˜ êµ¬ì¡°:**
- Teacher ëª¨ë¸: `'queries'`, `'positive_docs'`, `'negative_docs'` (ì›ë³¸ í…ìŠ¤íŠ¸)
- Student ëª¨ë¸: `'query_input_ids'`, `'pos_doc_input_ids'`, ë“± (í† í°í™”ëœ í…ì„œ)

## 4. í•´ê²° ë°©ë²•

### 4.1 ìƒˆ Dataset í´ë˜ìŠ¤ êµ¬í˜„ âœ…

**src/data/jsonl_dataset.py - NeuralSparseJSONLDataset:**

```python
class NeuralSparseJSONLDataset(Dataset):
    """
    JSONL í¬ë§· ì „ìš© Dataset.

    ì›ë³¸ í…ìŠ¤íŠ¸ë§Œ ë°˜í™˜ (í† í°í™” X)
    DataCollatorê°€ í† í°í™” ë‹´ë‹¹
    """

    def __getitem__(self, idx: int) -> Dict[str, any]:
        item = self.data[idx]

        query = item["query"]
        docs = item["docs"]

        # docs[0]ì€ positive, docs[1:]ì€ negatives
        positive_doc = docs[0]
        negative_docs = docs[1:self.num_negatives + 1]

        # ì›ë³¸ í…ìŠ¤íŠ¸ë§Œ ë°˜í™˜
        return {
            "query": query,                    # str
            "positive_doc": positive_doc,      # str
            "negative_docs": negative_docs,    # List[str]
        }
```

**íŠ¹ì§•:**
- âœ… ì›ë³¸ í…ìŠ¤íŠ¸ë§Œ ë°˜í™˜
- âœ… DataCollatorì™€ ì™„ë²½ í˜¸í™˜
- âœ… Knowledge distillation ì§€ì›
- âœ… JSONL í¬ë§·ì— ìµœì í™”

### 4.2 ë°ì´í„° íŒŒì´í”„ë¼ì¸ ì™„ì„±

```python
# 1. Dataset ìƒì„±
dataset = NeuralSparseJSONLDataset(
    jsonl_path="dataset/neural_sparse_training/train.jsonl",
    num_negatives=7,
)

# 2. DataCollator ìƒì„±
data_collator = NeuralSparseDataCollator(
    tokenizer=tokenizer,
    query_max_length=64,
    doc_max_length=256,
    num_negatives=7,
)

# 3. DataLoader ìƒì„±
dataloader = DataLoader(
    dataset,
    batch_size=16,
    collate_fn=data_collator,
)

# 4. Batch êµ¬ì¡° í™•ì¸
batch = next(iter(dataloader))
```

**Batch êµ¬ì¡° (ê²€ì¦ ì™„ë£Œ):**
```python
{
    # Teacher ëª¨ë¸ìš© (ì›ë³¸ í…ìŠ¤íŠ¸)
    'queries': List[str],              # [batch_size]
    'positive_docs': List[str],        # [batch_size]
    'negative_docs': List[List[str]],  # [batch_size, num_negatives]

    # Student ëª¨ë¸ìš© (í† í°í™”)
    'query_input_ids': Tensor,         # [batch_size, query_seq_len]
    'query_attention_mask': Tensor,    # [batch_size, query_seq_len]
    'pos_doc_input_ids': Tensor,       # [batch_size, doc_seq_len]
    'pos_doc_attention_mask': Tensor,  # [batch_size, doc_seq_len]
    'neg_doc_input_ids': Tensor,       # [batch_size, num_neg, doc_seq_len]
    'neg_doc_attention_mask': Tensor,  # [batch_size, num_neg, doc_seq_len]
}
```

## 5. ê²€ì¦ ê²°ê³¼

### 5.1 ìë™ ê²€ì¦ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰

```bash
$ python scripts/validate_data_pipeline.py
```

**ê²€ì¦ ê²°ê³¼:**
```
âœ“ Dataset: 21,590 samples loaded
âœ“ DataLoader: 5,398 batches
âœ“ Batch size: 4
âœ“ Num negatives: 7
âœ“ All required keys present
âœ“ All shapes correct
âœ“ All types valid

âœ“âœ“âœ“ DATA PIPELINE IS VALID âœ“âœ“âœ“
```

### 5.2 ë°°ì¹˜ êµ¬ì¡° ê²€ì¦

**Student ëª¨ë¸ ì…ë ¥ (í† í°í™”):**
- âœ… query_input_ids: torch.Size([4, 19])
- âœ… query_attention_mask: torch.Size([4, 19])
- âœ… pos_doc_input_ids: torch.Size([4, 256])
- âœ… pos_doc_attention_mask: torch.Size([4, 256])
- âœ… neg_doc_input_ids: torch.Size([4, 7, 256])
- âœ… neg_doc_attention_mask: torch.Size([4, 7, 256])

**Teacher ëª¨ë¸ ì…ë ¥ (ì›ë³¸ í…ìŠ¤íŠ¸):**
- âœ… queries: 4 strings
- âœ… positive_docs: 4 strings
- âœ… negative_docs: 4 lists of 7 strings each

## 6. Best Practices ì •ë¦½

### 6.1 ë°ì´í„° íŒŒì´í”„ë¼ì¸ ì„¤ê³„ ì›ì¹™

```
[Principle 1] ì—­í•  ë¶„ë¦¬
- Dataset: ë°ì´í„° ë¡œë”© + ì›ë³¸ í…ìŠ¤íŠ¸ ë°˜í™˜
- DataCollator: ë°°ì¹˜ ìƒì„± + í† í°í™”
- train_step: ëª¨ë¸ í•™ìŠµ

[Principle 2] ì¸í„°í˜ì´ìŠ¤ ì¼ê´€ì„±
- Dataset ì¶œë ¥ â†” DataCollator ì…ë ¥ ì¼ì¹˜
- DataCollator ì¶œë ¥ â†” train_step ì…ë ¥ ì¼ì¹˜

[Principle 3] ìœ ì—°ì„±
- ì›ë³¸ í…ìŠ¤íŠ¸ ìœ ì§€ â†’ Teacher ëª¨ë¸ ì§€ì›
- í† í°í™” ë¶„ë¦¬ â†’ ë‹¤ì–‘í•œ tokenizer ì‚¬ìš© ê°€ëŠ¥
```

### 6.2 í‚¤ ë„¤ì´ë° ì»¨ë²¤ì…˜

**Dataset ì¶œë ¥ (ë‹¨ìˆ˜í˜•):**
```python
{
    'query': str,
    'positive_doc': str,
    'negative_docs': List[str],
}
```

**DataCollator ì¶œë ¥ (ë³µìˆ˜í˜• + ì ‘ë‘ì‚¬):**
```python
{
    # ì›ë³¸ (ë³µìˆ˜í˜•)
    'queries': List[str],
    'positive_docs': List[str],
    'negative_docs': List[List[str]],

    # í† í°í™” (ì ‘ë‘ì‚¬ + ë³µìˆ˜í˜•)
    'query_input_ids': Tensor,
    'pos_doc_input_ids': Tensor,
    'neg_doc_input_ids': Tensor,
}
```

### 6.3 íƒ€ì… íŒíŒ… ë° ê²€ì¦

```python
from typing import Dict, List
from dataclasses import dataclass

@dataclass
class TrainingSample:
    """Type-safe training sample."""
    query: str
    positive_doc: str
    negative_docs: List[str]

    def __post_init__(self):
        # Type validation
        assert isinstance(self.query, str)
        assert isinstance(self.positive_doc, str)
        assert isinstance(self.negative_docs, list)
        assert all(isinstance(d, str) for d in self.negative_docs)
```

## 7. êµ¬í˜„ íŒŒì¼ ëª©ë¡

### 7.1 ìƒˆë¡œ ìƒì„±ëœ íŒŒì¼

| íŒŒì¼ ê²½ë¡œ | ìš©ë„ | ìƒíƒœ |
|---------|------|------|
| `src/data/jsonl_dataset.py` | JSONL Dataset í´ë˜ìŠ¤ | âœ… ì™„ë£Œ |
| `scripts/validate_data_pipeline.py` | íŒŒì´í”„ë¼ì¸ ê²€ì¦ ìŠ¤í¬ë¦½íŠ¸ | âœ… ì™„ë£Œ |
| `docs/DATA_PIPELINE_FIX.md` | í•´ê²° ë°©ë²• ê°€ì´ë“œ | âœ… ì™„ë£Œ |
| `docs/DATA_PIPELINE_ANALYSIS_REPORT.md` | ë¶„ì„ ë³´ê³ ì„œ (ë³¸ ë¬¸ì„œ) | âœ… ì™„ë£Œ |

### 7.2 ê¸°ì¡´ íŒŒì¼ (ìˆ˜ì • ë¶ˆí•„ìš”)

| íŒŒì¼ ê²½ë¡œ | ìƒíƒœ | ë¹„ê³  |
|---------|------|------|
| `src/training/data_collator.py` | âœ… ì •ìƒ | ìˆ˜ì • ë¶ˆí•„ìš” |
| `src/data/dataset.py` | âš ï¸ ì‚¬ìš© ì•ˆ í•¨ | ê¸°ì¡´ í”„ë¡œì íŠ¸ìš©, í˜¸í™˜ì„± ìœ ì§€ |
| `notebooks/opensearch-neural-v2/02_training_opensearch_neural_v2.ipynb` | ğŸ“ ì—…ë°ì´íŠ¸ í•„ìš” | Dataset í´ë˜ìŠ¤ ë³€ê²½ |

## 8. ë…¸íŠ¸ë¶ ìˆ˜ì • ê°€ì´ë“œ

### 8.1 í•„ìš”í•œ ë³€ê²½ì‚¬í•­

**02_training_opensearch_neural_v2.ipynbì˜ Dataset ìƒì„± ë¶€ë¶„:**

**ê¸°ì¡´ ì½”ë“œ (ë…¸íŠ¸ë¶ ë‚´ SparseRetrievalDataset):**
```python
# ë…¸íŠ¸ë¶ì— ì •ì˜ëœ í´ë˜ìŠ¤ ì‚¬ìš©
train_dataset = SparseRetrievalDataset(
    queries=train_queries,
    positive_docs=train_positive_docs,
    negative_docs=train_negative_docs,
)
```

**ë³€ê²½ í›„ ì½”ë“œ:**
```python
# ìƒˆë¡œìš´ JSONL Dataset ì‚¬ìš©
from src.data.jsonl_dataset import NeuralSparseJSONLDataset

train_dataset = NeuralSparseJSONLDataset(
    jsonl_path="dataset/neural_sparse_training/train.jsonl",
    num_negatives=7,
    validate_format=True,
)

val_dataset = NeuralSparseJSONLDataset(
    jsonl_path="dataset/neural_sparse_training/val.jsonl",
    num_negatives=7,
    validate_format=True,
)
```

### 8.2 ë³€ê²½ ì´ìœ 

1. âœ… **ë‹¨ìˆœí™”**: JSONL íŒŒì¼ì—ì„œ ì§ì ‘ ë¡œë“œ
2. âœ… **ì¼ê´€ì„±**: ë°ì´í„° ì¤€ë¹„ ë…¸íŠ¸ë¶ê³¼ ë™ì¼í•œ í¬ë§·
3. âœ… **ê²€ì¦**: ìë™ í¬ë§· ê²€ì¦ ë‚´ì¥
4. âœ… **ìœ ì§€ë³´ìˆ˜**: ì¤‘ë³µ ì½”ë“œ ì œê±°

## 9. ê²°ë¡ 

### 9.1 í•´ê²° ì™„ë£Œ

âœ… **JSONL Dataset í´ë˜ìŠ¤ êµ¬í˜„ ì™„ë£Œ**
- ì›ë³¸ í…ìŠ¤íŠ¸ ë°˜í™˜
- DataCollatorì™€ ì™„ë²½ í˜¸í™˜
- Knowledge distillation ì§€ì›

âœ… **íŒŒì´í”„ë¼ì¸ ê²€ì¦ ì™„ë£Œ**
- 21,590ê°œ ìƒ˜í”Œ ë¡œë“œ í™•ì¸
- ë°°ì¹˜ êµ¬ì¡° ê²€ì¦ ì™„ë£Œ
- Teacher/Student ëª¨ë¸ ì…ë ¥ ì¤€ë¹„ ì™„ë£Œ

âœ… **Best Practices ì •ë¦½**
- ì—­í•  ë¶„ë¦¬ ëª…í™•í™”
- í‚¤ ë„¤ì´ë° ì»¨ë²¤ì…˜ í™•ë¦½
- íƒ€ì… ê²€ì¦ í‘œì¤€í™”

### 9.2 ë‹¤ìŒ ë‹¨ê³„

**ì¦‰ì‹œ ê°€ëŠ¥:**
1. âœ… ë…¸íŠ¸ë¶ì—ì„œ ìƒˆ Dataset ì‚¬ìš©
2. âœ… í•™ìŠµ ì‹¤í–‰
3. âœ… Teacher ëª¨ë¸ í†µí•©

**í–¥í›„ ê°œì„ :**
1. ğŸ“ ë” ë§ì€ ë°ì´í„° í¬ë§· ì§€ì›
2. ğŸ“ Dynamic negative sampling
3. ğŸ“ Data augmentation ì¶”ê°€

## 10. ì°¸ê³  ìë£Œ

### 10.1 êµ¬í˜„ ì½”ë“œ
- `/home/west/Documents/cursor-workspace/opensearch-neural-pre-train/src/data/jsonl_dataset.py`
- `/home/west/Documents/cursor-workspace/opensearch-neural-pre-train/src/training/data_collator.py`
- `/home/west/Documents/cursor-workspace/opensearch-neural-pre-train/scripts/validate_data_pipeline.py`

### 10.2 ë¬¸ì„œ
- `/home/west/Documents/cursor-workspace/opensearch-neural-pre-train/docs/DATA_PIPELINE_FIX.md`
- `/home/west/Documents/cursor-workspace/opensearch-neural-pre-train/CLAUDE.md`

### 10.3 ë°ì´í„°
- `/home/west/Documents/cursor-workspace/opensearch-neural-pre-train/dataset/neural_sparse_training/train.jsonl` (21,590 samples)
- `/home/west/Documents/cursor-workspace/opensearch-neural-pre-train/dataset/neural_sparse_training/val.jsonl`

---

**ë³´ê³ ì„œ ì‘ì„±:** Claude (Anthropic)
**ê²€ì¦ ì¼ì‹œ:** 2025-11-23
**ìƒíƒœ:** âœ… í•´ê²° ì™„ë£Œ ë° ê²€ì¦ í†µê³¼

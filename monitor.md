# Server Monitoring Setup Guide

ML/DL í•™ìŠµ í™˜ê²½ì„ ìœ„í•œ ì¢…í•© ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ êµ¬ì„± ê°€ì´ë“œì…ë‹ˆë‹¤.

---

## ğŸ“Š ëª¨ë‹ˆí„°ë§ ëŒ€ìƒ ë©”íŠ¸ë¦­

### 1. GPU ë©”íŠ¸ë¦­
- GPU ì‚¬ìš©ë¥  (%)
- GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ (MB/GB)
- GPU ì˜¨ë„ (Â°C)
- GPU ì „ë ¥ ì†Œë¹„ (W)
- GPU í´ëŸ­ ì†ë„ (MHz)
- Compute/Memory Utilization
- PCIe ëŒ€ì—­í­ ì‚¬ìš©ëŸ‰

### 2. CPU ë©”íŠ¸ë¦­
- CPU ì‚¬ìš©ë¥  (per core, average)
- CPU ì˜¨ë„ (Â°C)
- í”„ë¡œì„¸ìŠ¤ë³„ CPU ì‚¬ìš©ëŸ‰
- Load Average (1/5/15ë¶„)

### 3. ë©”ëª¨ë¦¬ ë©”íŠ¸ë¦­
- RAM ì‚¬ìš©ëŸ‰ (MB/GB)
- RAM ì‚¬ìš©ë¥  (%)
- Swap ì‚¬ìš©ëŸ‰
- í”„ë¡œì„¸ìŠ¤ë³„ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰

### 4. ë””ìŠ¤í¬ ë©”íŠ¸ë¦­
- ë””ìŠ¤í¬ ì‚¬ìš©ëŸ‰ (GB)
- ë””ìŠ¤í¬ I/O (read/write MB/s)
- ë””ìŠ¤í¬ ëŒ€ê¸° ì‹œê°„ (latency)
- inode ì‚¬ìš©ëŸ‰

### 5. ë„¤íŠ¸ì›Œí¬ ë©”íŠ¸ë¦­
- ë„¤íŠ¸ì›Œí¬ ëŒ€ì—­í­ (in/out MB/s)
- íŒ¨í‚· ì „ì†¡ë¥ 
- ì—°ê²° ìƒíƒœ

### 6. í•™ìŠµ ë©”íŠ¸ë¦­
- Training loss
- Validation loss
- Learning rate
- Batch processing time
- Epoch progress

---

## ğŸ¯ ëª¨ë‹ˆí„°ë§ ì•„í‚¤í…ì²˜

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      Grafana Dashboard                       â”‚
â”‚              (Web UI - Port 3000)                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Prometheus Server                        â”‚
â”‚              (Metrics Storage - Port 9090)                  â”‚
â””â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚             â”‚             â”‚             â”‚
    â–¼             â–¼             â–¼             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Node   â”‚ â”‚  DCGM   â”‚ â”‚ Process â”‚ â”‚  Custom Python  â”‚
â”‚ Exporterâ”‚ â”‚Exporter â”‚ â”‚ Exporterâ”‚ â”‚    Exporter     â”‚
â”‚(Port    â”‚ â”‚(Port    â”‚ â”‚(Port    â”‚ â”‚  (Port 8000)    â”‚
â”‚ 9100)   â”‚ â”‚ 9400)   â”‚ â”‚ 9256)   â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚             â”‚             â”‚
    â–¼             â–¼             â–¼
System        NVIDIA GPU    Processes
Metrics       Metrics       Metrics
```

---

## ğŸš€ Phase 1: ê¸°ë³¸ ëª¨ë‹ˆí„°ë§ (ëª…ë ¹ì¤„ ë„êµ¬)

### 1.1 NVIDIA GPU ëª¨ë‹ˆí„°ë§

#### nvidia-smi (ê¸°ë³¸)
```bash
# ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ (1ì´ˆ ê°„ê²©)
watch -n 1 nvidia-smi

# ìƒì„¸ ì •ë³´ ì¶œë ¥
nvidia-smi -q

# íŠ¹ì • ë©”íŠ¸ë¦­ë§Œ ì¶œë ¥
nvidia-smi --query-gpu=timestamp,name,temperature.gpu,utilization.gpu,utilization.memory,memory.used,memory.total --format=csv -l 1
```

#### nvtop (ì‹¤ì‹œê°„ TUI)
```bash
# ì„¤ì¹˜
sudo apt-get install nvtop  # Ubuntu/Debian
# OR
sudo dnf install nvtop      # Amazon Linux 2023

# ì‹¤í–‰
nvtop
```

**nvtop íŠ¹ì§•**:
- htopê³¼ ìœ ì‚¬í•œ TUI ì¸í„°í˜ì´ìŠ¤
- ë‹¤ì¤‘ GPU ì§€ì›
- í”„ë¡œì„¸ìŠ¤ë³„ GPU ì‚¬ìš©ëŸ‰
- ì‹¤ì‹œê°„ ê·¸ë˜í”„

### 1.2 ì‹œìŠ¤í…œ ëª¨ë‹ˆí„°ë§

#### htop (CPU/ë©”ëª¨ë¦¬)
```bash
# ì„¤ì¹˜
sudo apt-get install htop   # Ubuntu/Debian
sudo dnf install htop       # Amazon Linux 2023

# ì‹¤í–‰
htop
```

#### sensors (ì˜¨ë„)
```bash
# ì„¤ì¹˜
sudo apt-get install lm-sensors
sudo sensors-detect  # ì„¼ì„œ ê°ì§€
sudo sensors-detect --auto  # ìë™ ê°ì§€

# ì‹¤í–‰
sensors
watch -n 2 sensors
```

#### iotop (ë””ìŠ¤í¬ I/O)
```bash
# ì„¤ì¹˜
sudo apt-get install iotop

# ì‹¤í–‰
sudo iotop -o  # I/O ì‚¬ìš© ì¤‘ì¸ í”„ë¡œì„¸ìŠ¤ë§Œ í‘œì‹œ
```

#### iftop (ë„¤íŠ¸ì›Œí¬)
```bash
# ì„¤ì¹˜
sudo apt-get install iftop

# ì‹¤í–‰
sudo iftop -i eth0  # ë„¤íŠ¸ì›Œí¬ ì¸í„°í˜ì´ìŠ¤ ì§€ì •
```

---

## ğŸ”§ Phase 2: Python ê¸°ë°˜ ëª¨ë‹ˆí„°ë§ ìŠ¤í¬ë¦½íŠ¸

### 2.1 ëª¨ë‹ˆí„°ë§ ìœ í‹¸ë¦¬í‹° ìƒì„±

**íŒŒì¼**: `src/monitoring/system_monitor.py`

```python
"""
System monitoring utilities for ML training
"""

import time
import psutil
import GPUtil
from datetime import datetime
from typing import Dict, List, Optional
import json


class SystemMonitor:
    """ì‹¤ì‹œê°„ ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­ ìˆ˜ì§‘"""

    def __init__(self, log_file: Optional[str] = None):
        self.log_file = log_file
        self.start_time = time.time()

    def get_gpu_metrics(self) -> List[Dict]:
        """GPU ë©”íŠ¸ë¦­ ìˆ˜ì§‘"""
        gpus = GPUtil.getGPUs()
        metrics = []

        for gpu in gpus:
            metrics.append({
                'gpu_id': gpu.id,
                'name': gpu.name,
                'load': gpu.load * 100,  # %
                'memory_used': gpu.memoryUsed,  # MB
                'memory_total': gpu.memoryTotal,  # MB
                'memory_util': gpu.memoryUtil * 100,  # %
                'temperature': gpu.temperature,  # Â°C
            })

        return metrics

    def get_cpu_metrics(self) -> Dict:
        """CPU ë©”íŠ¸ë¦­ ìˆ˜ì§‘"""
        return {
            'cpu_percent': psutil.cpu_percent(interval=1),
            'cpu_count': psutil.cpu_count(),
            'cpu_freq': psutil.cpu_freq().current if psutil.cpu_freq() else None,
            'load_avg': psutil.getloadavg(),
        }

    def get_memory_metrics(self) -> Dict:
        """ë©”ëª¨ë¦¬ ë©”íŠ¸ë¦­ ìˆ˜ì§‘"""
        mem = psutil.virtual_memory()
        swap = psutil.swap_memory()

        return {
            'total': mem.total / (1024**3),  # GB
            'available': mem.available / (1024**3),
            'used': mem.used / (1024**3),
            'percent': mem.percent,
            'swap_total': swap.total / (1024**3),
            'swap_used': swap.used / (1024**3),
            'swap_percent': swap.percent,
        }

    def get_disk_metrics(self) -> Dict:
        """ë””ìŠ¤í¬ ë©”íŠ¸ë¦­ ìˆ˜ì§‘"""
        disk = psutil.disk_usage('/')
        io = psutil.disk_io_counters()

        return {
            'total': disk.total / (1024**3),  # GB
            'used': disk.used / (1024**3),
            'free': disk.free / (1024**3),
            'percent': disk.percent,
            'read_mb': io.read_bytes / (1024**2) if io else None,
            'write_mb': io.write_bytes / (1024**2) if io else None,
        }

    def get_network_metrics(self) -> Dict:
        """ë„¤íŠ¸ì›Œí¬ ë©”íŠ¸ë¦­ ìˆ˜ì§‘"""
        net = psutil.net_io_counters()

        return {
            'bytes_sent': net.bytes_sent / (1024**2),  # MB
            'bytes_recv': net.bytes_recv / (1024**2),
            'packets_sent': net.packets_sent,
            'packets_recv': net.packets_recv,
        }

    def get_all_metrics(self) -> Dict:
        """ëª¨ë“  ë©”íŠ¸ë¦­ ìˆ˜ì§‘"""
        metrics = {
            'timestamp': datetime.now().isoformat(),
            'uptime': time.time() - self.start_time,
            'gpu': self.get_gpu_metrics(),
            'cpu': self.get_cpu_metrics(),
            'memory': self.get_memory_metrics(),
            'disk': self.get_disk_metrics(),
            'network': self.get_network_metrics(),
        }

        if self.log_file:
            with open(self.log_file, 'a') as f:
                f.write(json.dumps(metrics) + '\n')

        return metrics

    def print_summary(self):
        """ë©”íŠ¸ë¦­ ìš”ì•½ ì¶œë ¥"""
        metrics = self.get_all_metrics()

        print("="*70)
        print("ğŸ“Š System Metrics")
        print("="*70)

        # GPU
        if metrics['gpu']:
            print("\nğŸ® GPU:")
            for gpu in metrics['gpu']:
                print(f"  [{gpu['gpu_id']}] {gpu['name']}")
                print(f"      Load: {gpu['load']:.1f}%")
                print(f"      Memory: {gpu['memory_used']:.0f}/{gpu['memory_total']:.0f} MB ({gpu['memory_util']:.1f}%)")
                print(f"      Temp: {gpu['temperature']:.1f}Â°C")

        # CPU
        print(f"\nğŸ’» CPU:")
        print(f"  Usage: {metrics['cpu']['cpu_percent']:.1f}%")
        print(f"  Load Avg: {metrics['cpu']['load_avg']}")

        # Memory
        mem = metrics['memory']
        print(f"\nğŸ§  Memory:")
        print(f"  Used: {mem['used']:.1f}/{mem['total']:.1f} GB ({mem['percent']:.1f}%)")
        if mem['swap_total'] > 0:
            print(f"  Swap: {mem['swap_used']:.1f}/{mem['swap_total']:.1f} GB ({mem['swap_percent']:.1f}%)")

        # Disk
        disk = metrics['disk']
        print(f"\nğŸ’¾ Disk:")
        print(f"  Used: {disk['used']:.1f}/{disk['total']:.1f} GB ({disk['percent']:.1f}%)")

        print("="*70)


def monitor_training(interval: int = 5, log_file: str = "training_metrics.jsonl"):
    """
    í•™ìŠµ ì¤‘ ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§

    Usage:
        In notebook or script:
        from src.monitoring.system_monitor import monitor_training
        monitor_training(interval=5)
    """
    monitor = SystemMonitor(log_file=log_file)

    print(f"ğŸ” Monitoring started (interval: {interval}s)")
    print(f"ğŸ“ Logging to: {log_file}")
    print("Press Ctrl+C to stop\n")

    try:
        while True:
            monitor.print_summary()
            time.sleep(interval)
    except KeyboardInterrupt:
        print("\n\nâœ… Monitoring stopped")


if __name__ == "__main__":
    # Standalone monitoring
    monitor_training(interval=5)
```

### 2.2 í•„ìš”í•œ íŒ¨í‚¤ì§€ ì„¤ì¹˜

```bash
# requirements-monitoring.txt
pip install psutil gputil py3nvml
```

### 2.3 Jupyter Notebookì—ì„œ ì‚¬ìš©

```python
# ë…¸íŠ¸ë¶ ì…€ì— ì¶”ê°€
from src.monitoring.system_monitor import SystemMonitor

# í•™ìŠµ ì „ ë©”íŠ¸ë¦­ í™•ì¸
monitor = SystemMonitor()
monitor.print_summary()

# í•™ìŠµ ì‹œì‘...

# í•™ìŠµ ì¤‘ê°„ì— ë©”íŠ¸ë¦­ í™•ì¸
monitor.print_summary()
```

---

## ğŸ“ˆ Phase 3: Prometheus + Grafana (í”„ë¡œë•ì…˜)

### 3.1 ì•„í‚¤í…ì²˜ ê°œìš”

**ì¥ì **:
- ì¥ê¸°ê°„ ë©”íŠ¸ë¦­ ì €ì¥
- ì›¹ ê¸°ë°˜ ëŒ€ì‹œë³´ë“œ
- ì•Œë¦¼ ì„¤ì • ê°€ëŠ¥
- ë‹¤ì¤‘ ì„œë²„ ëª¨ë‹ˆí„°ë§

### 3.2 ì„¤ì¹˜ ë° êµ¬ì„±

#### Step 1: Prometheus ì„¤ì¹˜

```bash
# Prometheus ë‹¤ìš´ë¡œë“œ (ìµœì‹  ë²„ì „)
cd /tmp
wget https://github.com/prometheus/prometheus/releases/download/v2.48.0/prometheus-2.48.0.linux-amd64.tar.gz
tar xvfz prometheus-*.tar.gz
sudo mv prometheus-2.48.0.linux-amd64 /opt/prometheus

# Systemd ì„œë¹„ìŠ¤ ìƒì„±
sudo tee /etc/systemd/system/prometheus.service > /dev/null <<EOF
[Unit]
Description=Prometheus
Wants=network-online.target
After=network-online.target

[Service]
User=prometheus
Group=prometheus
Type=simple
ExecStart=/opt/prometheus/prometheus \\
  --config.file=/opt/prometheus/prometheus.yml \\
  --storage.tsdb.path=/var/lib/prometheus/ \\
  --web.console.templates=/opt/prometheus/consoles \\
  --web.console.libraries=/opt/prometheus/console_libraries

[Install]
WantedBy=multi-user.target
EOF

# ì‚¬ìš©ì ë° ë””ë ‰í† ë¦¬ ìƒì„±
sudo useradd --no-create-home --shell /bin/false prometheus
sudo mkdir -p /var/lib/prometheus
sudo chown -R prometheus:prometheus /var/lib/prometheus /opt/prometheus

# ì„œë¹„ìŠ¤ ì‹œì‘
sudo systemctl daemon-reload
sudo systemctl start prometheus
sudo systemctl enable prometheus

# ìƒíƒœ í™•ì¸
sudo systemctl status prometheus
```

#### Step 2: Node Exporter ì„¤ì¹˜ (ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­)

```bash
# Node Exporter ë‹¤ìš´ë¡œë“œ
cd /tmp
wget https://github.com/prometheus/node_exporter/releases/download/v1.7.0/node_exporter-1.7.0.linux-amd64.tar.gz
tar xvfz node_exporter-*.tar.gz
sudo mv node_exporter-1.7.0.linux-amd64/node_exporter /usr/local/bin/

# Systemd ì„œë¹„ìŠ¤ ìƒì„±
sudo tee /etc/systemd/system/node_exporter.service > /dev/null <<EOF
[Unit]
Description=Node Exporter
After=network.target

[Service]
User=node_exporter
Group=node_exporter
Type=simple
ExecStart=/usr/local/bin/node_exporter

[Install]
WantedBy=multi-user.target
EOF

# ì‚¬ìš©ì ìƒì„±
sudo useradd --no-create-home --shell /bin/false node_exporter

# ì„œë¹„ìŠ¤ ì‹œì‘
sudo systemctl daemon-reload
sudo systemctl start node_exporter
sudo systemctl enable node_exporter

# ë©”íŠ¸ë¦­ í™•ì¸
curl http://localhost:9100/metrics
```

#### Step 3: DCGM Exporter ì„¤ì¹˜ (NVIDIA GPU ë©”íŠ¸ë¦­)

```bash
# NVIDIA DCGM ì„¤ì¹˜
distribution=$(. /etc/os-release;echo $ID$VERSION_ID)
curl -s -L https://nvidia.github.io/libnvidia-container/gpgkey | sudo apt-key add -
curl -s -L https://nvidia.github.io/libnvidia-container/$distribution/libnvidia-container.list | \
  sudo tee /etc/apt/sources.list.d/nvidia-container-toolkit.list

sudo apt-get update
sudo apt-get install -y datacenter-gpu-manager

# DCGM Exporter Docker ì‹¤í–‰
docker run -d --gpus all --rm \
  -p 9400:9400 \
  --name dcgm-exporter \
  nvcr.io/nvidia/k8s/dcgm-exporter:3.1.7-3.1.4-ubuntu20.04

# ë©”íŠ¸ë¦­ í™•ì¸
curl http://localhost:9400/metrics
```

**Docker ì—†ì´ ì„¤ì¹˜** (ì„ íƒ):
```bash
# Go ì„¤ì¹˜ í›„ ì†ŒìŠ¤ì—ì„œ ë¹Œë“œ
git clone https://github.com/NVIDIA/dcgm-exporter.git
cd dcgm-exporter
make binary
sudo cp dcgm-exporter /usr/local/bin/

# Systemd ì„œë¹„ìŠ¤ ìƒì„± (ìœ„ì™€ ìœ ì‚¬)
```

#### Step 4: Prometheus ì„¤ì •

**íŒŒì¼**: `/opt/prometheus/prometheus.yml`

```yaml
# Prometheus configuration
global:
  scrape_interval: 15s
  evaluation_interval: 15s

# Alertmanager configuration
alerting:
  alertmanagers:
    - static_configs:
        - targets: []

# Rule files
rule_files:
  - "rules/*.yml"

# Scrape configurations
scrape_configs:
  # Prometheus ìì²´ ëª¨ë‹ˆí„°ë§
  - job_name: 'prometheus'
    static_configs:
      - targets: ['localhost:9090']

  # Node Exporter (ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­)
  - job_name: 'node'
    static_configs:
      - targets: ['localhost:9100']
        labels:
          instance: 'ml-training-server'

  # DCGM Exporter (GPU ë©”íŠ¸ë¦­)
  - job_name: 'gpu'
    static_configs:
      - targets: ['localhost:9400']
        labels:
          instance: 'ml-training-server'

  # Process Exporter (í”„ë¡œì„¸ìŠ¤ ë©”íŠ¸ë¦­)
  - job_name: 'process'
    static_configs:
      - targets: ['localhost:9256']
        labels:
          instance: 'ml-training-server'

  # Custom Python Exporter (í•™ìŠµ ë©”íŠ¸ë¦­)
  - job_name: 'training'
    static_configs:
      - targets: ['localhost:8000']
        labels:
          instance: 'ml-training-server'
```

**ì„¤ì • ë¦¬ë¡œë“œ**:
```bash
sudo systemctl reload prometheus
# OR
curl -X POST http://localhost:9090/-/reload
```

#### Step 5: Grafana ì„¤ì¹˜

```bash
# Grafana ì €ì¥ì†Œ ì¶”ê°€
sudo apt-get install -y software-properties-common
sudo add-apt-repository "deb https://packages.grafana.com/oss/deb stable main"
wget -q -O - https://packages.grafana.com/gpg.key | sudo apt-key add -

# ì„¤ì¹˜
sudo apt-get update
sudo apt-get install grafana

# ì„œë¹„ìŠ¤ ì‹œì‘
sudo systemctl daemon-reload
sudo systemctl start grafana-server
sudo systemctl enable grafana-server

# ìƒíƒœ í™•ì¸
sudo systemctl status grafana-server
```

**ì ‘ì†**:
- URL: http://localhost:3000
- ê¸°ë³¸ ID/PW: admin/admin

#### Step 6: Grafana ë°ì´í„° ì†ŒìŠ¤ ì„¤ì •

1. Grafana ì›¹ UI ì ‘ì†
2. Configuration > Data Sources
3. Add data source > Prometheus
4. URL: `http://localhost:9090`
5. Save & Test

### 3.3 Custom Python Exporter (í•™ìŠµ ë©”íŠ¸ë¦­)

**íŒŒì¼**: `src/monitoring/training_exporter.py`

```python
"""
Prometheus exporter for ML training metrics
"""

from prometheus_client import start_http_server, Gauge, Counter
import time
import json
from pathlib import Path


class TrainingMetricsExporter:
    """í•™ìŠµ ë©”íŠ¸ë¦­ì„ Prometheusë¡œ export"""

    def __init__(self, port: int = 8000):
        self.port = port

        # Gauge ë©”íŠ¸ë¦­ ì •ì˜
        self.train_loss = Gauge('training_loss', 'Training loss')
        self.val_loss = Gauge('validation_loss', 'Validation loss')
        self.learning_rate = Gauge('learning_rate', 'Current learning rate')
        self.epoch = Gauge('current_epoch', 'Current epoch number')
        self.batch_time = Gauge('batch_processing_time', 'Time per batch (seconds)')

        # Counter ë©”íŠ¸ë¦­
        self.batches_processed = Counter('batches_processed_total', 'Total batches processed')

    def update_metrics(self, metrics: dict):
        """ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸"""
        if 'train_loss' in metrics:
            self.train_loss.set(metrics['train_loss'])
        if 'val_loss' in metrics:
            self.val_loss.set(metrics['val_loss'])
        if 'learning_rate' in metrics:
            self.learning_rate.set(metrics['learning_rate'])
        if 'epoch' in metrics:
            self.epoch.set(metrics['epoch'])
        if 'batch_time' in metrics:
            self.batch_time.set(metrics['batch_time'])

    def start(self):
        """Exporter ì‹œì‘"""
        start_http_server(self.port)
        print(f"âœ… Training metrics exporter started on port {self.port}")
        print(f"   Metrics URL: http://localhost:{self.port}/metrics")


# Usage in training script
if __name__ == "__main__":
    exporter = TrainingMetricsExporter(port=8000)
    exporter.start()

    # í•™ìŠµ ë£¨í”„ì—ì„œ ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸
    while True:
        # ì˜ˆì‹œ ë©”íŠ¸ë¦­
        exporter.update_metrics({
            'train_loss': 0.5,
            'val_loss': 0.6,
            'learning_rate': 0.001,
            'epoch': 1,
            'batch_time': 0.5,
        })
        time.sleep(10)
```

**requirements-monitoring.txtì— ì¶”ê°€**:
```
prometheus-client==0.19.0
```

### 3.4 Grafana ëŒ€ì‹œë³´ë“œ êµ¬ì„±

#### GPU ëŒ€ì‹œë³´ë“œ í…œí”Œë¦¿

```json
{
  "dashboard": {
    "title": "ML Training - GPU Monitoring",
    "panels": [
      {
        "title": "GPU Utilization",
        "targets": [
          {
            "expr": "DCGM_FI_DEV_GPU_UTIL"
          }
        ],
        "type": "graph"
      },
      {
        "title": "GPU Memory Usage",
        "targets": [
          {
            "expr": "DCGM_FI_DEV_FB_USED / DCGM_FI_DEV_FB_FREE * 100"
          }
        ],
        "type": "graph"
      },
      {
        "title": "GPU Temperature",
        "targets": [
          {
            "expr": "DCGM_FI_DEV_GPU_TEMP"
          }
        ],
        "type": "graph"
      }
    ]
  }
}
```

**ëŒ€ì‹œë³´ë“œ Import**:
1. Grafana UI > Dashboards > Import
2. ìœ„ JSON ë¶™ì—¬ë„£ê¸° ë˜ëŠ”
3. ì»¤ë®¤ë‹ˆí‹° ëŒ€ì‹œë³´ë“œ ì‚¬ìš©:
   - NVIDIA DCGM Exporter: Dashboard ID `12239`
   - Node Exporter Full: Dashboard ID `1860`

---

## ğŸ”” Phase 4: ì•Œë¦¼ ì„¤ì • (Alertmanager)

### 4.1 Alertmanager ì„¤ì¹˜

```bash
# Alertmanager ë‹¤ìš´ë¡œë“œ
cd /tmp
wget https://github.com/prometheus/alertmanager/releases/download/v0.26.0/alertmanager-0.26.0.linux-amd64.tar.gz
tar xvfz alertmanager-*.tar.gz
sudo mv alertmanager-0.26.0.linux-amd64 /opt/alertmanager

# ì„¤ì • íŒŒì¼ ìƒì„±
sudo tee /opt/alertmanager/alertmanager.yml > /dev/null <<EOF
global:
  resolve_timeout: 5m

route:
  group_by: ['alertname']
  group_wait: 10s
  group_interval: 10s
  repeat_interval: 1h
  receiver: 'email-notifications'

receivers:
  - name: 'email-notifications'
    email_configs:
      - to: 'your-email@example.com'
        from: 'alertmanager@example.com'
        smarthost: 'smtp.gmail.com:587'
        auth_username: 'your-email@gmail.com'
        auth_password: 'your-app-password'
EOF

# Systemd ì„œë¹„ìŠ¤ ìƒì„± ë° ì‹œì‘
# (Prometheusì™€ ìœ ì‚¬í•œ ë°©ì‹)
```

### 4.2 ì•Œë¦¼ ê·œì¹™ ì„¤ì •

**íŒŒì¼**: `/opt/prometheus/rules/ml_training_alerts.yml`

```yaml
groups:
  - name: ml_training_alerts
    interval: 30s
    rules:
      # GPU ì˜¨ë„ ì•Œë¦¼
      - alert: HighGPUTemperature
        expr: DCGM_FI_DEV_GPU_TEMP > 80
        for: 2m
        labels:
          severity: warning
        annotations:
          summary: "GPU temperature is high"
          description: "GPU {{ $labels.gpu }} temperature is {{ $value }}Â°C"

      # GPU ë©”ëª¨ë¦¬ ë¶€ì¡± ì•Œë¦¼
      - alert: HighGPUMemoryUsage
        expr: (DCGM_FI_DEV_FB_USED / DCGM_FI_DEV_FB_FREE) * 100 > 90
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "GPU memory usage is high"
          description: "GPU {{ $labels.gpu }} memory usage is {{ $value }}%"

      # ì‹œìŠ¤í…œ ë©”ëª¨ë¦¬ ë¶€ì¡± ì•Œë¦¼
      - alert: HighMemoryUsage
        expr: (node_memory_MemTotal_bytes - node_memory_MemAvailable_bytes) / node_memory_MemTotal_bytes * 100 > 90
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "System memory usage is high"
          description: "Memory usage is {{ $value }}%"

      # ë””ìŠ¤í¬ ê³µê°„ ë¶€ì¡± ì•Œë¦¼
      - alert: LowDiskSpace
        expr: (node_filesystem_avail_bytes{mountpoint="/"} / node_filesystem_size_bytes{mountpoint="/"}) * 100 < 10
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: "Low disk space"
          description: "Disk space is {{ $value }}% remaining"

      # í•™ìŠµ ì†ì‹¤ ì¦ê°€ ì•Œë¦¼
      - alert: TrainingLossIncreasing
        expr: rate(training_loss[5m]) > 0
        for: 10m
        labels:
          severity: info
        annotations:
          summary: "Training loss is increasing"
          description: "Training loss has been increasing for 10 minutes"
```

---

## ğŸ“± Phase 5: ê°„ë‹¨í•œ ì›¹ ëŒ€ì‹œë³´ë“œ (Flask)

ê°„ë‹¨í•œ ì»¤ìŠ¤í…€ ëŒ€ì‹œë³´ë“œê°€ í•„ìš”í•œ ê²½ìš°:

**íŒŒì¼**: `src/monitoring/web_dashboard.py`

```python
"""
Simple web dashboard for training monitoring
"""

from flask import Flask, render_template, jsonify
from src.monitoring.system_monitor import SystemMonitor
import threading
import time

app = Flask(__name__)
monitor = SystemMonitor()

# ìµœê·¼ ë©”íŠ¸ë¦­ ì €ì¥
latest_metrics = {}

def update_metrics():
    """ë°±ê·¸ë¼ìš´ë“œì—ì„œ ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸"""
    global latest_metrics
    while True:
        latest_metrics = monitor.get_all_metrics()
        time.sleep(5)

# ë°±ê·¸ë¼ìš´ë“œ ìŠ¤ë ˆë“œ ì‹œì‘
thread = threading.Thread(target=update_metrics, daemon=True)
thread.start()

@app.route('/')
def index():
    """ë©”ì¸ ëŒ€ì‹œë³´ë“œ"""
    return render_template('dashboard.html')

@app.route('/api/metrics')
def get_metrics():
    """ë©”íŠ¸ë¦­ API"""
    return jsonify(latest_metrics)

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=5000, debug=False)
```

**ì‹¤í–‰**:
```bash
python src/monitoring/web_dashboard.py
# ì ‘ì†: http://localhost:5000
```

---

## ğŸ“Š ì‚¬ìš© ì‹œë‚˜ë¦¬ì˜¤ë³„ ê¶Œì¥ì‚¬í•­

### ì‹œë‚˜ë¦¬ì˜¤ 1: ê°œë°œ/ì‹¤í—˜ ë‹¨ê³„
**ê¶Œì¥**: Phase 1 + Phase 2
- nvidia-smi, nvtopìœ¼ë¡œ ì‹¤ì‹œê°„ í™•ì¸
- Python ìŠ¤í¬ë¦½íŠ¸ë¡œ ë©”íŠ¸ë¦­ ë¡œê¹…
- ê°„ë‹¨í•˜ê³  ë¹ ë¥´ê²Œ ì‹œì‘ ê°€ëŠ¥

### ì‹œë‚˜ë¦¬ì˜¤ 2: ì¥ê¸° í•™ìŠµ
**ê¶Œì¥**: Phase 2 + Phase 3
- Python ìŠ¤í¬ë¦½íŠ¸ë¡œ ë©”íŠ¸ë¦­ ìˆ˜ì§‘
- Prometheus + Grafanaë¡œ ì‹œê°í™”
- ì¥ê¸°ê°„ ë©”íŠ¸ë¦­ ë³´ê´€ ë° ë¶„ì„

### ì‹œë‚˜ë¦¬ì˜¤ 3: í”„ë¡œë•ì…˜ í™˜ê²½
**ê¶Œì¥**: Phase 3 + Phase 4
- ì™„ì „í•œ Prometheus + Grafana ìŠ¤íƒ
- Alertmanagerë¡œ ì•Œë¦¼ ì„¤ì •
- ë‹¤ì¤‘ ì„œë²„ ëª¨ë‹ˆí„°ë§

---

## ğŸ¯ ë¹ ë¥¸ ì‹œì‘ (Quick Start)

### Option A: ëª…ë ¹ì¤„ ë„êµ¬ë§Œ ì‚¬ìš©

```bash
# í„°ë¯¸ë„ 1: GPU ëª¨ë‹ˆí„°ë§
watch -n 1 nvidia-smi

# í„°ë¯¸ë„ 2: ì‹œìŠ¤í…œ ëª¨ë‹ˆí„°ë§
htop

# í„°ë¯¸ë„ 3: ì˜¨ë„ ëª¨ë‹ˆí„°ë§
watch -n 2 sensors
```

### Option B: Python ìŠ¤í¬ë¦½íŠ¸ ì‚¬ìš©

```bash
# 1. íŒ¨í‚¤ì§€ ì„¤ì¹˜
pip install psutil gputil py3nvml

# 2. ëª¨ë‹ˆí„°ë§ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
python -c "from src.monitoring.system_monitor import monitor_training; monitor_training(interval=5)"
```

### Option C: Prometheus + Grafana (ì™„ì „í•œ ì†”ë£¨ì…˜)

```bash
# ì„¤ì¹˜ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
./scripts/setup_monitoring.sh

# ì„œë¹„ìŠ¤ ì‹œì‘
sudo systemctl start prometheus
sudo systemctl start node_exporter
sudo systemctl start grafana-server

# Grafana ì ‘ì†
open http://localhost:3000
```

---

## ğŸ“ ì²´í¬ë¦¬ìŠ¤íŠ¸

### ì„¤ì¹˜ ì²´í¬ë¦¬ìŠ¤íŠ¸

- [ ] nvidia-smi ì‘ë™ í™•ì¸
- [ ] nvtop ì„¤ì¹˜ ë° ì‹¤í–‰
- [ ] sensors ì„¤ì • ë° ì˜¨ë„ í™•ì¸
- [ ] psutil, gputil ì„¤ì¹˜
- [ ] Prometheus ì„¤ì¹˜ ë° ì‹¤í–‰
- [ ] Node Exporter ì„¤ì¹˜
- [ ] DCGM Exporter ì„¤ì¹˜ (GPU)
- [ ] Grafana ì„¤ì¹˜ ë° ì ‘ì†
- [ ] ë°ì´í„° ì†ŒìŠ¤ ì—°ê²°
- [ ] ëŒ€ì‹œë³´ë“œ import
- [ ] ì•Œë¦¼ ê·œì¹™ ì„¤ì •
- [ ] ì•Œë¦¼ í…ŒìŠ¤íŠ¸

### ëª¨ë‹ˆí„°ë§ ì²´í¬ë¦¬ìŠ¤íŠ¸

í•™ìŠµ ì‹œì‘ ì „:
- [ ] GPU ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
- [ ] GPU ë©”ëª¨ë¦¬ ì¶©ë¶„ í™•ì¸
- [ ] ë””ìŠ¤í¬ ê³µê°„ í™•ì¸ (10GB ì´ìƒ)
- [ ] ì‹œìŠ¤í…œ ë©”ëª¨ë¦¬ í™•ì¸
- [ ] ì˜¨ë„ ì •ìƒ ë²”ìœ„ í™•ì¸

í•™ìŠµ ì¤‘:
- [ ] GPU ì‚¬ìš©ë¥  80% ì´ìƒ ìœ ì§€
- [ ] GPU ì˜¨ë„ 85Â°C ì´í•˜ ìœ ì§€
- [ ] ë©”ëª¨ë¦¬ leak ì—†ìŒ
- [ ] ë””ìŠ¤í¬ I/O ì •ìƒ
- [ ] Loss ì •ìƒì ìœ¼ë¡œ ê°ì†Œ

---

## ğŸ”§ ë¬¸ì œ í•´ê²°

### nvidia-smi ì‘ë™ ì•ˆ í•¨
```bash
# ë“œë¼ì´ë²„ ì¬ì„¤ì¹˜
sudo apt-get purge nvidia-*
sudo apt-get install nvidia-driver-535

# ì¬ë¶€íŒ…
sudo reboot
```

### sensors ì˜¨ë„ í‘œì‹œ ì•ˆ ë¨
```bash
# ì„¼ì„œ ì¬ê°ì§€
sudo sensors-detect --auto
sudo systemctl restart lm-sensors
```

### Prometheus ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ì•ˆ ë¨
```bash
# Exporter ìƒíƒœ í™•ì¸
systemctl status node_exporter
systemctl status dcgm-exporter

# í¬íŠ¸ í™•ì¸
netstat -tlnp | grep 9100
netstat -tlnp | grep 9400

# ë°©í™”ë²½ í™•ì¸
sudo ufw allow 9100
sudo ufw allow 9400
```

---

## ğŸ“š ì°¸ê³  ìë£Œ

### ê³µì‹ ë¬¸ì„œ
- [NVIDIA DCGM](https://developer.nvidia.com/dcgm)
- [Prometheus Documentation](https://prometheus.io/docs/)
- [Grafana Documentation](https://grafana.com/docs/)
- [Node Exporter](https://github.com/prometheus/node_exporter)

### ì»¤ë®¤ë‹ˆí‹° ëŒ€ì‹œë³´ë“œ
- [Grafana Dashboards](https://grafana.com/grafana/dashboards/)
- NVIDIA GPU: ID `12239`
- Node Exporter: ID `1860`

### ìœ ìš©í•œ ë„êµ¬
- [gpustat](https://github.com/wookayin/gpustat) - nvidia-smi ëŒ€ì²´
- [glances](https://github.com/nicolargo/glances) - í†µí•© ëª¨ë‹ˆí„°ë§
- [netdata](https://www.netdata.cloud/) - ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§

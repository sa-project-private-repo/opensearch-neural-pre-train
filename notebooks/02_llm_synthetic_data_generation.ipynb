{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 02. LLM Synthetic Data Generation\n",
        "\n",
        "ì´ ë…¸íŠ¸ë¶ì€ LLMì„ ì‚¬ìš©í•˜ì—¬ í•©ì„± ì¿¼ë¦¬ ë°ì´í„°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\n",
        "\n",
        "## ì „ì œì¡°ê±´\n",
        "ë¨¼ì € `01_neural_sparse_base_training.ipynb`ë¥¼ ì‹¤í–‰í•˜ì—¬ ê¸°ë³¸ ë°ì´í„°ë¥¼ ìƒì„±í•´ì•¼ í•©ë‹ˆë‹¤.\n",
        "\n",
        "## ëª©í‘œ\n",
        "- LLM ëª¨ë¸ ë¡œë”© (Qwen3-30B-A3B-Thinking-2507-FP8)\n",
        "- í•œêµ­ì–´ ë¬¸ì„œ ê¸°ë°˜ í•©ì„± ì¿¼ë¦¬ ìƒì„±\n",
        "- ë™ì˜ì–´ í™•ì¥ ë° ê²€ì¦\n",
        "\n",
        "## ì¶œë ¥ ë°ì´í„°\n",
        "ëª¨ë“  ë°ì´í„°ëŠ” `dataset/llm_generated/` ë””ë ‰í† ë¦¬ì— ì €ì¥ë©ë‹ˆë‹¤:\n",
        "- `synthetic_qd_pairs.pkl`: LLM ìƒì„± Query-Document ìŒ\n",
        "- `enhanced_synonyms.json`: LLM ê²€ì¦ ë™ì˜ì–´ ì‚¬ì „\n",
        "\n",
        "## ë‹¤ìŒ ë‹¨ê³„\n",
        "ì´ ë…¸íŠ¸ë¶ ì‹¤í–‰ í›„ `03_llm_enhanced_training.ipynb`ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Triton ì»´íŒŒì¼ ë¹„í™œì„±í™” (ARM aarch64 í˜¸í™˜ì„±)\n",
        "import os\n",
        "\n",
        "os.environ[\"TRITON_INTERPRET\"] = \"1\"\n",
        "os.environ[\"DISABLE_TRITON\"] = \"1\"\n",
        "\n",
        "print(\"âœ… Triton compilation disabled for ARM compatibility\")"
      ],
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# DatasetManager ì´ˆê¸°í™”\n",
        "from src.dataset_manager import DatasetManager\n",
        "\n",
        "dm = DatasetManager(base_path=\"dataset\")\n",
        "print(\"âœ… DatasetManager initialized\")\n",
        "print(f\"ğŸ“ Base path: {dm.base_path.absolute()}\")"
      ],
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# í•„ìˆ˜ ë°ì´í„° íŒŒì¼ í™•ì¸\n",
        "required_files = [\n",
        "    (\"base_model\", \"korean_documents.json\"),\n",
        "    (\"base_model\", \"bilingual_synonyms.json\"),\n",
        "]\n",
        "\n",
        "if not dm.check_dependencies(required_files):\n",
        "    raise RuntimeError(\n",
        "        \"Required data files not found. \"\n",
        "        \"Please run 01_neural_sparse_base_training.ipynb first.\"\n",
        "    )\n",
        "\n",
        "print(\"\\nâœ… Ready to proceed with LLM data generation\")"
      ],
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Notebook 1ì—ì„œ ìƒì„±ëœ ë°ì´í„° ë¡œë“œ\n",
        "print(\"Loading data from notebook 1...\\n\")\n",
        "\n",
        "korean_documents = dm.load_json(\"korean_documents.json\", \"base_model\")\n",
        "bilingual_dict = dm.load_json(\"bilingual_synonyms.json\", \"base_model\")\n",
        "\n",
        "print(f\"\\nâœ… Loaded {len(korean_documents)} documents\")\n",
        "print(f\"âœ… Loaded bilingual dictionary with {len(bilingual_dict)} entries\")"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ†• 13. LLM ëª¨ë¸ ë¡œë”© ë° ì´ˆê¸°í™”\n",
        "\n",
        "ì´ ì„¹ì…˜ë¶€í„°ëŠ” LLM ê¸°ë°˜ í™•ì¥ ê¸°ëŠ¥ì…ë‹ˆë‹¤:\n",
        "- í•©ì„± Query-Document ìŒ ìƒì„±\n",
        "- í•œì˜ ë™ì˜ì–´ ìë™ ê²€ì¦\n",
        "- ì„±ëŠ¥ ê°œì„ "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Section 13: LLM Model Loading\n",
        "import os\n",
        "\n",
        "# Disable Triton JIT compilation to avoid Python.h dependency\n",
        "os.environ[\"TRITON_DISABLE_LINE_INFO\"] = \"1\"\n",
        "os.environ[\"TRITON_CACHE_DIR\"] = \"/tmp/triton_cache\"\n",
        "os.environ[\"TRITON_INTERPRET\"] = \"1\"  # ì¸í„°í”„ë¦¬í„° ëª¨ë“œ ì‚¬ìš©\n",
        "os.environ[\"DISABLE_TRITON\"] = \"1\"    # ì™„ì „ ë¹„í™œì„±í™”\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"ğŸ¤– ì„¹ì…˜ 13: LLM ëª¨ë¸ ë¡œë”© ë° ì´ˆê¸°í™”\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "from src.llm_loader import load_qwen3_awq, check_gpu_memory\n",
        "\n",
        "# GPU ë©”ëª¨ë¦¬ ì²´í¬\n",
        "check_gpu_memory()\n",
        "\n",
        "# Qwen3-30B-A3B-Thinking-2507-FP8 ëª¨ë¸ ë¡œë”© (FP8 quantization, ARM compatible)\n",
        "# Qwen3-30B-A3B-Thinking-2507-FP8 ëª¨ë¸ ë¡œë”© (FP8 quantization, ARM compatible)\n",
        "print(\"âš ï¸  ì°¸ê³ : ì²« ì‹¤í–‰ ì‹œ ëª¨ë¸ ë‹¤ìš´ë¡œë“œë¡œ ì‹œê°„ì´ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\")\n",
        "print(\"   ëª¨ë¸ í¬ê¸°: ~30GB (FP8 quantization, ARM aarch64 compatible)\")\n",
        "\n",
        "llm_model, llm_tokenizer = load_qwen3_awq(\n",
        "    model_name=\"Qwen/Qwen3-30B-A3B-Thinking-2507-FP8\",\n",
        "    device_map=\"auto\",\n",
        ")\n",
        "\n",
        "print(\"\\nâœ… LLM ëª¨ë¸ ë¡œë”© ì™„ë£Œ!\")\n",
        "print(\"   ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ í•©ì„± ë°ì´í„°ë¥¼ ìƒì„±í•  ì¤€ë¹„ê°€ ë˜ì—ˆìŠµë‹ˆë‹¤.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ†• 14. LLM ê¸°ë°˜ í•©ì„± Query-Document Pairs ìƒì„±\n",
        "\n",
        "LLMì„ ì‚¬ìš©í•˜ì—¬ ë¬¸ì„œë¡œë¶€í„° ê²€ìƒ‰ ì¿¼ë¦¬ë¥¼ ì—­ìƒì„±í•©ë‹ˆë‹¤.\n",
        "ì´ë¥¼ í†µí•´ í•™ìŠµ ë°ì´í„°ë¥¼ ëŒ€í­ í™•ì¥í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"ğŸ“ ì„¹ì…˜ 14: LLM ê¸°ë°˜ í•©ì„± Query-Document Pairs ìƒì„±\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "from src.synthetic_data_generator import generate_synthetic_qd_pairs\n",
        "\n",
        "# ê¸°ì¡´ ë¬¸ì„œì—ì„œ í•©ì„± ì¿¼ë¦¬ ìƒì„±\n",
        "# ì²˜ìŒ 1000ê°œ ë¬¸ì„œ ì‚¬ìš© (ì‹œê°„ ê³ ë ¤)\n",
        "print(f\"\\nğŸ“Š í•©ì„± ë°ì´í„° ìƒì„± ì„¤ì •:\")\n",
        "print(f\"   - ì‚¬ìš©í•  ë¬¸ì„œ: 1,000ê°œ\")\n",
        "print(f\"   - ë¬¸ì„œë‹¹ ì¿¼ë¦¬: 3ê°œ\")\n",
        "print(f\"   - ì˜ˆìƒ ìƒì„± pairs: ~3,000ê°œ\")\n",
        "print(f\"   - ì˜ˆìƒ ì†Œìš” ì‹œê°„: ~15-30ë¶„ (GPU ì†ë„ì— ë”°ë¼)\")\n",
        "\n",
        "synthetic_pairs = generate_synthetic_qd_pairs(\n",
        "    documents=documents[:1000],  # ì²˜ìŒ 1000ê°œ ë¬¸ì„œ\n",
        "    llm_model=llm_model,\n",
        "    llm_tokenizer=llm_tokenizer,\n",
        "    num_queries_per_doc=3,\n",
        "    batch_size=2,\n",
        "    max_documents=1000,\n",
        "    enable_filtering=True,\n",
        ")\n",
        "\n",
        "print(f\"\\nâœ… í•©ì„± ë°ì´í„° ìƒì„± ì™„ë£Œ: {len(synthetic_pairs):,}ê°œ pairs\")\n",
        "\n",
        "# ìƒ˜í”Œ ì¶œë ¥\n",
        "print(\"\\nğŸ“‹ ìƒì„±ëœ í•©ì„± ë°ì´í„° ìƒ˜í”Œ (ì²˜ìŒ 5ê°œ):\")\n",
        "print(\"=\"*70)\n",
        "for i, (query, doc, relevance) in enumerate(synthetic_pairs[:5], 1):\n",
        "    print(f\"\\n{i}. Query: {query}\")\n",
        "    print(f\"   Document: {doc[:100]}...\")\n",
        "    print(f\"   Relevance: {relevance}\")\n",
        "print(\"=\"*70)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ†• 15. LLM ê¸°ë°˜ í•œì˜ ë™ì˜ì–´ ê²€ì¦ ë° í™•ì¥\n",
        "\n",
        "ê¸°ì¡´ ì„ë² ë”© ê¸°ë°˜ìœ¼ë¡œ ë°œê²¬í•œ ë™ì˜ì–´ë¥¼ LLMìœ¼ë¡œ ê²€ì¦í•˜ì—¬ ì •í™•ë„ë¥¼ ë†’ì…ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"ğŸŒ ì„¹ì…˜ 15: LLM ê¸°ë°˜ í•œì˜ ë™ì˜ì–´ ê²€ì¦ ë° í™•ì¥\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "from src.cross_lingual_synonyms import enhance_bilingual_dict_with_llm\n",
        "\n",
        "# ê¸°ì¡´ ì„ë² ë”© ê¸°ë°˜ ë™ì˜ì–´ë¥¼ LLMìœ¼ë¡œ ê²€ì¦\n",
        "print(f\"\\nğŸ“Š ë™ì˜ì–´ ê²€ì¦ ì„¤ì •:\")\n",
        "print(f\"   - ê¸°ì¡´ ë™ì˜ì–´ ì‚¬ì „: {len(bilingual_dict):,}ê°œ í•­ëª©\")\n",
        "print(f\"   - ê²€ì¦í•  í•­ëª©: ìƒìœ„ 100ê°œ\")\n",
        "print(f\"   - ê²€ì¦ ì„ê³„ê°’: 0.8\")\n",
        "print(f\"   - ì˜ˆìƒ ì†Œìš” ì‹œê°„: ~5-10ë¶„\")\n",
        "\n",
        "enhanced_bilingual_dict = enhance_bilingual_dict_with_llm(\n",
        "    initial_dict=bilingual_dict,  # Cell 14ì—ì„œ ìƒì„±ëœ ê¸°ì¡´ ì‚¬ì „\n",
        "    llm_model=llm_model,\n",
        "    llm_tokenizer=llm_tokenizer,\n",
        "    verification_threshold=0.8,\n",
        "    max_verify=100,  # ìƒìœ„ 100ê°œë§Œ ê²€ì¦ (ì‹œê°„ ì ˆì•½)\n",
        ")\n",
        "\n",
        "print(f\"\\nâœ… LLM ê²€ì¦ ì™„ë£Œ!\")\n",
        "print(f\"   ê¸°ì¡´ ì‚¬ì „: {len(bilingual_dict):,}ê°œ\")\n",
        "print(f\"   ê²€ì¦ í›„: {len(enhanced_bilingual_dict):,}ê°œ\")\n",
        "\n",
        "# ê²€ì¦ ê²°ê³¼ ìƒ˜í”Œ ì¶œë ¥\n",
        "print(\"\\nğŸ“‹ ê²€ì¦ëœ ë™ì˜ì–´ ìƒ˜í”Œ:\")\n",
        "print(\"=\"*70)\n",
        "sample_count = 0\n",
        "for korean, english_list in list(enhanced_bilingual_dict.items())[:10]:\n",
        "    sample_count += 1\n",
        "    print(f\"{sample_count}. {korean} â†” {', '.join(english_list)}\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# ì—…ë°ì´íŠ¸ëœ ë™ì˜ì–´ ì‚¬ì „ì„ bilingual_dictì— ë°˜ì˜\n",
        "bilingual_dict = enhanced_bilingual_dict\n",
        "print(f\"\\nâœ“ ë™ì˜ì–´ ì‚¬ì „ ì—…ë°ì´íŠ¸ ì™„ë£Œ\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# ë°ì´í„° ì €ì¥ (Notebook ê°„ ê³µìœ )\n",
        "\n",
        "LLMìœ¼ë¡œ ìƒì„±ëœ ë°ì´í„°ë¥¼ `dataset/llm_generated/` ë””ë ‰í† ë¦¬ì— ì €ì¥í•©ë‹ˆë‹¤.\n",
        "ë‹¤ìŒ ë…¸íŠ¸ë¶ì—ì„œ ì´ ë°ì´í„°ë¥¼ ë¡œë“œí•˜ì—¬ enhanced ëª¨ë¸ì„ í•™ìŠµí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# 1. LLM ìƒì„± Query-Document ìŒ ì €ì¥\n",
        "dm.save_pickle(\n",
        "    synthetic_qd_pairs,\n",
        "    \"synthetic_qd_pairs.pkl\",\n",
        "    \"llm_generated\"\n",
        ")"
      ],
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# 2. LLM ê²€ì¦ ë™ì˜ì–´ ì‚¬ì „ ì €ì¥\n",
        "dm.save_json(\n",
        "    enhanced_synonyms,\n",
        "    \"enhanced_synonyms.json\",\n",
        "    \"llm_generated\"\n",
        ")"
      ],
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# ì €ì¥ëœ ë°ì´í„° ìš”ì•½\n",
        "dm.print_summary()"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## âœ… Notebook 2 ì™„ë£Œ\n",
        "\n",
        "ëª¨ë“  LLM ìƒì„± ë°ì´í„°ê°€ `dataset/llm_generated/`ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
        "\n",
        "### ë‹¤ìŒ ë‹¨ê³„\n",
        "ì´ì œ `03_llm_enhanced_training.ipynb`ë¥¼ ì‹¤í–‰í•˜ì—¬ enhanced ëª¨ë¸ì„ í•™ìŠµí•˜ê³  ì„±ëŠ¥ì„ ë¹„êµí•˜ì„¸ìš”."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bbc9a6e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -U -q  sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a56474d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cbf4b2e57c7484b81f409894a005b03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/108 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19139898ad2a4fa290c5f46d6bf6f5ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/274 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9266f0bdeae8476ea8d54eb344759d32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef0192a12006443188f55bc063ef8c6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "router_config.json:   0%|          | 0.00/638 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b86a7ddb76744947b927b8dada1caa5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/22.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8047861577c402890bb1eb4376d9a3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a34349e7b2f44bea05f2d2e196d4b8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39a21ca6ebdc4f8287139f34b1809d3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72584df9f248426cac052eccaf18bd54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/695 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e9d7d02f41a4ee395e8759ecaeda425",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "query_0_SparseStaticEmbedding/model.safe(â€¦):   0%|          | 0.00/424k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c22a387bce134ffe966bcb69a3334625",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/872 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae8b2d2ffc6045a6a4593fd50857b6b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "./model.safetensors:   0%|          | 0.00/670M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d60a7640093d4d96bd3e680966d8c5d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d67012f3b2814c9aa9d257e952379b35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d0055210e934d9b88307185444d60fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/106 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/west/Documents/cursor-workspace/opensearch-neural-pre-train/.venv/lib/python3.12/site-packages/torch/cuda/__init__.py:435: UserWarning: \n",
      "    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.\n",
      "    Minimum and Maximum cuda capability supported by this version of PyTorch is\n",
      "    (8.0) - (12.0)\n",
      "    \n",
      "  queued_call()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity: tensor([[7.7400]], device='cuda:0')\n",
      "Token: weather, Query score: 3.0699, Document score: 1.2821\n",
      "Token: now, Query score: 1.6406, Document score: 0.9018\n",
      "Token: ?, Query score: 1.6108, Document score: 0.3141\n",
      "Token: ny, Query score: 1.2721, Document score: 1.3446\n",
      "Token: in, Query score: 0.6005, Document score: 0.1804\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers.sparse_encoder import SparseEncoder\n",
    "\n",
    "# Download from the ðŸ¤— Hub\n",
    "model = SparseEncoder(\"opensearch-project/opensearch-neural-sparse-encoding-multilingual-v1\")\n",
    "\n",
    "query = \"What's the weather in ny now?\"\n",
    "document = \"Currently New York is rainy.\"\n",
    "\n",
    "query_embed = model.encode_query(query)\n",
    "document_embed = model.encode_document(document)\n",
    "\n",
    "sim = model.similarity(query_embed, document_embed)\n",
    "print(f\"Similarity: {sim}\")\n",
    "# Similarity: tensor([[7.7400]])\n",
    "\n",
    "decoded_query = model.decode(query_embed)\n",
    "decoded_document = model.decode(document_embed)\n",
    "\n",
    "for i in range(len(decoded_query)):\n",
    "    query_token, query_score = decoded_query[i]\n",
    "    doc_score = next((score for token, score in decoded_document if token == query_token), 0)\n",
    "    if doc_score != 0:\n",
    "        print(f\"Token: {query_token}, Query score: {query_score:.4f}, Document score: {doc_score:.4f}\")\n",
    "\n",
    "# Token: weather, Query score: 3.0699, Document score: 1.2821\n",
    "# Token: now, Query score: 1.6406, Document score: 0.9018\n",
    "# Token: ?, Query score: 1.6108, Document score: 0.3141\n",
    "# Token: ny, Query score: 1.2721, Document score: 1.3446\n",
    "# Token: in, Query score: 0.6005, Document score: 0.1804\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d108bab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity: tensor([[13.7056]], device='cuda:0')\n",
      "Token: weather, Query score: 3.0699, Document score: 0.4987\n",
      "Token: á„‹á…¥á„„á…¥á†«, Query score: 2.0707, Document score: 0.3997\n",
      "Token: ##á†¨á„‹á…´, Query score: 2.0185, Document score: 1.0338\n",
      "Token: á„‚á…¡á†¯, Query score: 2.0080, Document score: 1.3598\n",
      "Token: ##á„Šá…µ, Query score: 1.9821, Document score: 1.1379\n",
      "Token: á„’á…§á†«á„Œá…¢, Query score: 1.8418, Document score: 0.5173\n",
      "Token: ##á…², Query score: 1.2720, Document score: 1.7435\n",
      "Token: á„‚, Query score: 1.0003, Document score: 1.0101\n",
      "Token: ##á„‹á…­, Query score: 0.7587, Document score: 0.1233\n"
     ]
    }
   ],
   "source": [
    "query = \"What is the current weather in New York?\"\n",
    "document = \"Currently, it is raining in New York, and the temperature is 10 degrees Celsius. Traffic in the city center is smooth, but showers with strong winds are expected in the outskirts, so it is recommended to prepare an umbrella and warm clothes when going out. The weather is expected to clear up on the weekend, but temperatures are expected to be somewhat low. From early next week, temperatures are expected to rise again, leading to sunny weather.\"\n",
    "\n",
    "query = \"ë‰´ìš•ì˜ í˜„ìž¬ ë‚ ì”¨ëŠ” Weather ì–´ë–¤ê°€ìš”?\"\n",
    "document = \"í˜„ìž¬ ë‰´ìš•ì€ ë¹„ê°€ ë‚´ë¦¬ê³  ìžˆìœ¼ë©°, ê¸°ì˜¨ì€ ì„­ì”¨ 10ë„ìž…ë‹ˆë‹¤. ë„ì‹¬ì˜ êµí†µì€ ì›í™œí•˜ì§€ë§Œ, ì™¸ê³½ ì§€ì—­ì—ì„œëŠ” ê°•í•œ ë°”ëžŒê³¼ í•¨ê»˜ ì†Œë‚˜ê¸°ê°€ ì˜ˆìƒë˜ì˜¤ë‹ˆ ì™¸ì¶œ ì‹œ ìš°ì‚°ê³¼ ë”°ëœ»í•œ ì˜·ì„ ì¤€ë¹„í•˜ì‹œëŠ” ê²ƒì´ ì¢‹ê² ìŠµë‹ˆë‹¤. ì£¼ë§ì—ëŠ” ë‚ ì”¨ê°€ ë§‘ì•„ì§ˆ ê²ƒìœ¼ë¡œ ë³´ì´ì§€ë§Œ, ê¸°ì˜¨ì€ ë‹¤ì†Œ ë‚®ì„ ê²ƒìœ¼ë¡œ ì˜ˆìƒë©ë‹ˆë‹¤. ë‹¤ìŒ ì£¼ ì´ˆë¶€í„°ëŠ” ë‹¤ì‹œ ê¸°ì˜¨ì´ ì˜¤ë¥´ë©´ì„œ í™”ì°½í•œ ë‚ ì”¨ê°€ ì´ì–´ì§ˆ ì „ë§ìž…ë‹ˆë‹¤.\"\n",
    "\n",
    "query_embed = model.encode_query(query)\n",
    "document_embed = model.encode_document(document)\n",
    "\n",
    "sim = model.similarity(query_embed, document_embed)\n",
    "print(f\"Similarity: {sim}\")\n",
    "# Similarity: tensor([[7.7400]])\n",
    "\n",
    "decoded_query = model.decode(query_embed)\n",
    "decoded_document = model.decode(document_embed)\n",
    "\n",
    "for i in range(len(decoded_query)):\n",
    "    query_token, query_score = decoded_query[i]\n",
    "    doc_score = next((score for token, score in decoded_document if token == query_token), 0)\n",
    "    if doc_score != 0:\n",
    "        print(f\"Token: {query_token}, Query score: {query_score:.4f}, Document score: {doc_score:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

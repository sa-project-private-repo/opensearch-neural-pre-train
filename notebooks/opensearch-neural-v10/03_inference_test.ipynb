{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# v10 Inference Test\n",
    "\n",
    "v10 대규모 학습 모델의 성능을 평가합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "def find_project_root():\n",
    "    candidates = [\n",
    "        Path.cwd(),\n",
    "        Path.cwd().parent,\n",
    "        Path.cwd().parent.parent,\n",
    "        Path(\"/home/west/Documents/cursor-workspace/opensearch-neural-pre-train\"),\n",
    "    ]\n",
    "    for candidate in candidates:\n",
    "        if (candidate / \"CLAUDE.md\").exists() or (candidate / \".git\").exists():\n",
    "            return candidate\n",
    "    return Path(\"/home/west/Documents/cursor-workspace/opensearch-neural-pre-train\")\n",
    "\n",
    "project_root = find_project_root()\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import AutoTokenizer\n",
    "from src.model.splade_model import create_splade_model\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/home/west/Documents/cursor-workspace/opensearch-neural-pre-train/.venv/lib/python3.12/site-packages/torch/cuda/__init__.py:435: UserWarning: \n",
      "    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.\n",
      "    Minimum and Maximum cuda capability supported by this version of PyTorch is\n",
      "    (8.0) - (12.0)\n",
      "    \n",
      "  queued_call()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v10 Model loaded!\n"
     ]
    }
   ],
   "source": [
    "# Load model\n",
    "MODEL_NAME = \"bert-base-multilingual-cased\"\n",
    "CHECKPOINT_PATH = project_root / \"outputs/v10_large_scale/final_model.pt\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "model = create_splade_model(\n",
    "    model_name=MODEL_NAME,\n",
    "    use_idf=False,\n",
    "    use_expansion=True,\n",
    "    expansion_mode=\"mlm\",\n",
    ")\n",
    "\n",
    "checkpoint = torch.load(CHECKPOINT_PATH, map_location=device, weights_only=True)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "print(\"v10 Model loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sparse_representation(text: str, top_k: int = 50):\n",
    "    encoding = tokenizer(text, max_length=64, padding='max_length', truncation=True, return_tensors='pt')\n",
    "    with torch.no_grad():\n",
    "        sparse_rep, _ = model(encoding['input_ids'].to(device), encoding['attention_mask'].to(device))\n",
    "    sparse_rep = sparse_rep[0].cpu()\n",
    "    top_scores, top_indices = torch.topk(sparse_rep, k=top_k)\n",
    "    return tokenizer.convert_ids_to_tokens(top_indices.tolist()), top_scores.tolist()\n",
    "\n",
    "def is_korean(token):\n",
    "    clean = token.replace('##', '')\n",
    "    return any('\\uac00' <= c <= '\\ud7a3' for c in clean)\n",
    "\n",
    "def is_english(token):\n",
    "    clean = token.replace('##', '')\n",
    "    return clean.isalpha() and clean.isascii()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test queries\n",
    "TEST_PAIRS = [\n",
    "    (\"머신러닝\", [\"machine\", \"learning\"]),\n",
    "    (\"딥러닝\", [\"deep\", \"learning\"]),\n",
    "    (\"자연어처리\", [\"natural\", \"language\", \"processing\"]),\n",
    "    (\"인공지능\", [\"artificial\", \"intelligence\"]),\n",
    "    (\"신경망\", [\"neural\", \"network\"]),\n",
    "    (\"알고리즘\", [\"algorithm\"]),\n",
    "    (\"데이터베이스\", [\"database\"]),\n",
    "    (\"프로그래밍\", [\"programming\"]),\n",
    "    (\"소프트웨어\", [\"software\"]),\n",
    "    (\"하드웨어\", [\"hardware\"]),\n",
    "    (\"학습\", [\"training\", \"learning\"]),\n",
    "    (\"모델\", [\"model\"]),\n",
    "    (\"데이터\", [\"data\"]),\n",
    "    (\"컴퓨터\", [\"computer\"]),\n",
    "    (\"네트워크\", [\"network\"]),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v10 Evaluation Results\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Korean</th>\n",
       "      <th>KO Preserved</th>\n",
       "      <th>EN Expected</th>\n",
       "      <th>EN Activated</th>\n",
       "      <th>Top-5</th>\n",
       "      <th>KO</th>\n",
       "      <th>EN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>머신러닝</td>\n",
       "      <td>-</td>\n",
       "      <td>machine, learning</td>\n",
       "      <td>-</td>\n",
       "      <td>the, that, it, this, .</td>\n",
       "      <td>❌</td>\n",
       "      <td>❌</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>딥러닝</td>\n",
       "      <td>-</td>\n",
       "      <td>deep, learning</td>\n",
       "      <td>-</td>\n",
       "      <td>the, ., that, it, this</td>\n",
       "      <td>❌</td>\n",
       "      <td>❌</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>자연어처리</td>\n",
       "      <td>-</td>\n",
       "      <td>natural, language, processing</td>\n",
       "      <td>-</td>\n",
       "      <td>the, that, it, to, this</td>\n",
       "      <td>❌</td>\n",
       "      <td>❌</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>인공지능</td>\n",
       "      <td>-</td>\n",
       "      <td>artificial, intelligence</td>\n",
       "      <td>-</td>\n",
       "      <td>the, that, it, this, you</td>\n",
       "      <td>❌</td>\n",
       "      <td>❌</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>신경망</td>\n",
       "      <td>-</td>\n",
       "      <td>neural, network</td>\n",
       "      <td>-</td>\n",
       "      <td>the, that, it, this, you</td>\n",
       "      <td>❌</td>\n",
       "      <td>❌</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>알고리즘</td>\n",
       "      <td>-</td>\n",
       "      <td>algorithm</td>\n",
       "      <td>-</td>\n",
       "      <td>the, that, it, this, you</td>\n",
       "      <td>❌</td>\n",
       "      <td>❌</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>데이터베이스</td>\n",
       "      <td>-</td>\n",
       "      <td>database</td>\n",
       "      <td>-</td>\n",
       "      <td>the, that, ., it, this</td>\n",
       "      <td>❌</td>\n",
       "      <td>❌</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>프로그래밍</td>\n",
       "      <td>-</td>\n",
       "      <td>programming</td>\n",
       "      <td>-</td>\n",
       "      <td>the, that, it, this, a</td>\n",
       "      <td>❌</td>\n",
       "      <td>❌</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>소프트웨어</td>\n",
       "      <td>-</td>\n",
       "      <td>software</td>\n",
       "      <td>-</td>\n",
       "      <td>., the, to, and, that</td>\n",
       "      <td>❌</td>\n",
       "      <td>❌</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>하드웨어</td>\n",
       "      <td>-</td>\n",
       "      <td>hardware</td>\n",
       "      <td>-</td>\n",
       "      <td>the, ., that, it, this</td>\n",
       "      <td>❌</td>\n",
       "      <td>❌</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>학습</td>\n",
       "      <td>-</td>\n",
       "      <td>training, learning</td>\n",
       "      <td>-</td>\n",
       "      <td>., the, that, ', you</td>\n",
       "      <td>❌</td>\n",
       "      <td>❌</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>모델</td>\n",
       "      <td>-</td>\n",
       "      <td>model</td>\n",
       "      <td>-</td>\n",
       "      <td>the, that, it, this, you</td>\n",
       "      <td>❌</td>\n",
       "      <td>❌</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>데이터</td>\n",
       "      <td>-</td>\n",
       "      <td>data</td>\n",
       "      <td>-</td>\n",
       "      <td>., the, that, it, this</td>\n",
       "      <td>❌</td>\n",
       "      <td>❌</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>컴퓨터</td>\n",
       "      <td>-</td>\n",
       "      <td>computer</td>\n",
       "      <td>-</td>\n",
       "      <td>., the, that, it, this</td>\n",
       "      <td>❌</td>\n",
       "      <td>❌</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>네트워크</td>\n",
       "      <td>-</td>\n",
       "      <td>network</td>\n",
       "      <td>-</td>\n",
       "      <td>the, that, it, this, a</td>\n",
       "      <td>❌</td>\n",
       "      <td>❌</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Korean KO Preserved                    EN Expected EN Activated  \\\n",
       "0     머신러닝            -              machine, learning            -   \n",
       "1      딥러닝            -                 deep, learning            -   \n",
       "2    자연어처리            -  natural, language, processing            -   \n",
       "3     인공지능            -       artificial, intelligence            -   \n",
       "4      신경망            -                neural, network            -   \n",
       "5     알고리즘            -                      algorithm            -   \n",
       "6   데이터베이스            -                       database            -   \n",
       "7    프로그래밍            -                    programming            -   \n",
       "8    소프트웨어            -                       software            -   \n",
       "9     하드웨어            -                       hardware            -   \n",
       "10      학습            -             training, learning            -   \n",
       "11      모델            -                          model            -   \n",
       "12     데이터            -                           data            -   \n",
       "13     컴퓨터            -                       computer            -   \n",
       "14    네트워크            -                        network            -   \n",
       "\n",
       "                       Top-5 KO EN  \n",
       "0     the, that, it, this, .  ❌  ❌  \n",
       "1     the, ., that, it, this  ❌  ❌  \n",
       "2    the, that, it, to, this  ❌  ❌  \n",
       "3   the, that, it, this, you  ❌  ❌  \n",
       "4   the, that, it, this, you  ❌  ❌  \n",
       "5   the, that, it, this, you  ❌  ❌  \n",
       "6     the, that, ., it, this  ❌  ❌  \n",
       "7     the, that, it, this, a  ❌  ❌  \n",
       "8      ., the, to, and, that  ❌  ❌  \n",
       "9     the, ., that, it, this  ❌  ❌  \n",
       "10      ., the, that, ', you  ❌  ❌  \n",
       "11  the, that, it, this, you  ❌  ❌  \n",
       "12    ., the, that, it, this  ❌  ❌  \n",
       "13    ., the, that, it, this  ❌  ❌  \n",
       "14    the, that, it, this, a  ❌  ❌  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate\n",
    "results = []\n",
    "\n",
    "for ko_term, en_expected in TEST_PAIRS:\n",
    "    tokens, scores = get_sparse_representation(ko_term)\n",
    "    tokens_lower = [t.lower() for t in tokens]\n",
    "    \n",
    "    # Korean preservation\n",
    "    input_tokens = set(tokenizer.tokenize(ko_term))\n",
    "    preserved = [t for t in input_tokens if t in tokens]\n",
    "    \n",
    "    # English activation\n",
    "    activated_en = []\n",
    "    for en in en_expected:\n",
    "        for tok in tokenizer.tokenize(en.lower()):\n",
    "            if tok.lower() in tokens_lower:\n",
    "                activated_en.append(tok)\n",
    "    \n",
    "    results.append({\n",
    "        'Korean': ko_term,\n",
    "        'KO Preserved': ', '.join(preserved) if preserved else '-',\n",
    "        'EN Expected': ', '.join(en_expected),\n",
    "        'EN Activated': ', '.join(activated_en) if activated_en else '-',\n",
    "        'Top-5': ', '.join(tokens[:5]),\n",
    "        'KO': '✅' if preserved else '❌',\n",
    "        'EN': '✅' if activated_en else '❌',\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "print(\"v10 Evaluation Results\")\n",
    "print(\"=\"*80)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary:\n",
      "  Korean preserved: 0/15 (0.0%)\n",
      "  English activated: 0/15 (0.0%)\n",
      "  Both succeeded: 0/15 (0.0%)\n"
     ]
    }
   ],
   "source": [
    "# Summary\n",
    "ko_success = sum(1 for r in results if r['KO'] == '✅')\n",
    "en_success = sum(1 for r in results if r['EN'] == '✅')\n",
    "both_success = sum(1 for r in results if r['KO'] == '✅' and r['EN'] == '✅')\n",
    "\n",
    "print(f\"\\nSummary:\")\n",
    "print(f\"  Korean preserved: {ko_success}/{len(results)} ({ko_success/len(results)*100:.1f}%)\")\n",
    "print(f\"  English activated: {en_success}/{len(results)} ({en_success/len(results)*100:.1f}%)\")\n",
    "print(f\"  Both succeeded: {both_success}/{len(results)} ({both_success/len(results)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Custom Query Results\n",
      "================================================================================\n",
      "\n",
      "파이썬 프로그래밍:\n",
      "  KO preserved: None\n",
      "  EN tokens: that, it, this, you, they\n",
      "  Top-5: the, that, it, this, you\n",
      "\n",
      "웹 개발:\n",
      "  KO preserved: None\n",
      "  EN tokens: time, like, then, just, more\n",
      "  Top-5: ., ', ,, time, like\n",
      "\n",
      "클라우드 컴퓨팅:\n",
      "  KO preserved: None\n",
      "  EN tokens: that, it, this, you, they\n",
      "  Top-5: the, that, it, this, to\n",
      "\n",
      "빅데이터 분석:\n",
      "  KO preserved: None\n",
      "  EN tokens: that, it, this, they, you\n",
      "  Top-5: the, ., that, it, this\n",
      "\n",
      "검색 엔진:\n",
      "  KO preserved: None\n",
      "  EN tokens: that, it, this, they, you\n",
      "  Top-5: the, ., that, it, this\n",
      "\n",
      "추천 시스템:\n",
      "  KO preserved: None\n",
      "  EN tokens: that, it, this, you, they\n",
      "  Top-5: the, that, it, this, a\n"
     ]
    }
   ],
   "source": [
    "# Custom queries\n",
    "custom_queries = [\n",
    "    \"파이썬 프로그래밍\",\n",
    "    \"웹 개발\",\n",
    "    \"클라우드 컴퓨팅\",\n",
    "    \"빅데이터 분석\",\n",
    "    \"검색 엔진\",\n",
    "    \"추천 시스템\",\n",
    "]\n",
    "\n",
    "print(\"\\nCustom Query Results\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for query in custom_queries:\n",
    "    tokens, scores = get_sparse_representation(query, top_k=20)\n",
    "    input_tokens = set(tokenizer.tokenize(query))\n",
    "    preserved = [t for t in input_tokens if t in tokens]\n",
    "    en_tokens = [t for t in tokens if is_english(t) and t not in ['the', 'a', 'an', 'in', 'of', 'to']]\n",
    "    \n",
    "    print(f\"\\n{query}:\")\n",
    "    print(f\"  KO preserved: {preserved if preserved else 'None'}\")\n",
    "    print(f\"  EN tokens: {', '.join(en_tokens[:5]) if en_tokens else 'None'}\")\n",
    "    print(f\"  Top-5: {', '.join(tokens[:5])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "v10 Inference Test Complete!\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nv10 Inference Test Complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

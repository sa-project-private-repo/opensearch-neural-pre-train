{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# v12 Inference Test: Improved Term-Level KO-EN Model\n",
    "\n",
    "Test the trained v12 model on various Korean queries.\n",
    "\n",
    "**Key Improvements from v11:**\n",
    "- Filtered Wikidata (removed person names)\n",
    "- Oversampled MUSE dictionary (3x)\n",
    "- Added IT terminology and common vocabulary\n",
    "- Increased loss weights for stronger English activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: /home/west/Documents/cursor-workspace/opensearch-neural-pre-train\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "def find_project_root():\n",
    "    candidates = [\n",
    "        Path.cwd(),\n",
    "        Path.cwd().parent,\n",
    "        Path.cwd().parent.parent,\n",
    "        Path(\"/home/west/Documents/cursor-workspace/opensearch-neural-pre-train\"),\n",
    "    ]\n",
    "    for candidate in candidates:\n",
    "        if (candidate / \"CLAUDE.md\").exists() or (candidate / \".git\").exists():\n",
    "            return candidate\n",
    "    return Path(\"/home/west/Documents/cursor-workspace/opensearch-neural-pre-train\")\n",
    "\n",
    "PROJECT_ROOT = find_project_root()\n",
    "sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "print(f\"Project root: {PROJECT_ROOT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer\n",
    "from src.model.splade_model import create_splade_model\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded checkpoint from: /home/west/Documents/cursor-workspace/opensearch-neural-pre-train/outputs/v12_improved/best_model.pt\n",
      "Model: bert-base-multilingual-cased\n",
      "EN Rate: 78.94736842105263%\n",
      "KO Rate: 65.78947368421053%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/west/Documents/cursor-workspace/opensearch-neural-pre-train/.venv/lib/python3.12/site-packages/torch/cuda/__init__.py:435: UserWarning: \n",
      "    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.\n",
      "    Minimum and Maximum cuda capability supported by this version of PyTorch is\n",
      "    (8.0) - (12.0)\n",
      "    \n",
      "  queued_call()\n"
     ]
    }
   ],
   "source": [
    "# Load best model checkpoint\n",
    "checkpoint_path = PROJECT_ROOT / 'outputs' / 'v12_improved' / 'best_model.pt'\n",
    "\n",
    "if not checkpoint_path.exists():\n",
    "    print(f\"Checkpoint not found at {checkpoint_path}\")\n",
    "    print(\"Please run scripts/train_v12.py first!\")\n",
    "else:\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=device, weights_only=False)\n",
    "    config = checkpoint['config']\n",
    "    \n",
    "    print(f\"Loaded checkpoint from: {checkpoint_path}\")\n",
    "    print(f\"Model: {config['model_name']}\")\n",
    "    print(f\"EN Rate: {checkpoint.get('en_rate', 'N/A')}%\")\n",
    "    print(f\"KO Rate: {checkpoint.get('ko_rate', 'N/A')}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Create and load model\n",
    "tokenizer = AutoTokenizer.from_pretrained(config['model_name'])\n",
    "\n",
    "model = create_splade_model(\n",
    "    model_name=config['model_name'],\n",
    "    use_idf=False,\n",
    "    use_expansion=True,\n",
    "    expansion_mode='mlm',\n",
    ")\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "print(\"Model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_korean_char(c: str) -> bool:\n",
    "    return '\\uac00' <= c <= '\\ud7a3' or '\\u1100' <= c <= '\\u11ff' or '\\u3130' <= c <= '\\u318f'\n",
    "\n",
    "def is_english_char(c: str) -> bool:\n",
    "    return c.isalpha() and c.isascii()\n",
    "\n",
    "def classify_token(token: str) -> str:\n",
    "    \"\"\"Classify token as Korean, English, or Other.\"\"\"\n",
    "    clean = token.replace('##', '')\n",
    "    if not clean:\n",
    "        return 'other'\n",
    "    \n",
    "    has_korean = any(is_korean_char(c) for c in clean)\n",
    "    has_english = any(is_english_char(c) for c in clean)\n",
    "    \n",
    "    if has_korean:\n",
    "        return 'korean'\n",
    "    elif has_english:\n",
    "        return 'english'\n",
    "    else:\n",
    "        return 'other'\n",
    "\n",
    "def analyze_query(text: str, top_k: int = 50) -> dict:\n",
    "    \"\"\"Analyze a query and return top activated tokens.\"\"\"\n",
    "    encoding = tokenizer(\n",
    "        text,\n",
    "        max_length=64,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        sparse_rep, _ = model(\n",
    "            encoding['input_ids'].to(device),\n",
    "            encoding['attention_mask'].to(device)\n",
    "        )\n",
    "    \n",
    "    sparse_rep = sparse_rep[0].cpu()\n",
    "    \n",
    "    # Get top-k tokens\n",
    "    top_values, top_indices = torch.topk(sparse_rep, k=top_k)\n",
    "    top_tokens = tokenizer.convert_ids_to_tokens(top_indices.tolist())\n",
    "    \n",
    "    # Classify tokens\n",
    "    korean_tokens = []\n",
    "    english_tokens = []\n",
    "    other_tokens = []\n",
    "    \n",
    "    for token, value in zip(top_tokens, top_values.tolist()):\n",
    "        token_type = classify_token(token)\n",
    "        if token_type == 'korean':\n",
    "            korean_tokens.append((token, value))\n",
    "        elif token_type == 'english':\n",
    "            english_tokens.append((token, value))\n",
    "        else:\n",
    "            other_tokens.append((token, value))\n",
    "    \n",
    "    return {\n",
    "        'input': text,\n",
    "        'korean': korean_tokens,\n",
    "        'english': english_tokens,\n",
    "        'other': other_tokens,\n",
    "        'top_10': list(zip(top_tokens[:10], top_values[:10].tolist())),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "v12 INFERENCE TEST RESULTS\n",
      "================================================================================\n",
      "\n",
      "입력: 머신러닝\n",
      "  한글 토큰: ['##러', '머신']\n",
      "  영어 토큰: ['##ing', '##ng', '##s', 're', 'c', '##er', 'bu', 'machine', 'mon', 'sp']\n",
      "\n",
      "입력: 딥러닝\n",
      "  한글 토큰: ['딥', '##러']\n",
      "  영어 토큰: ['##ing', '##ng', '##s', 're', 'c', 'in', '##er', 'bu', 'sp', '##ning']\n",
      "\n",
      "입력: 자연어처리\n",
      "  한글 토큰: ['자', '##리', '##어']\n",
      "  영어 토큰: ['##s', '##y', '##ing', 're', '##ry', 'c', '##er', '##e', '##es', '##r']\n",
      "\n",
      "입력: 인공지능\n",
      "  한글 토큰: ['인', '##지', '##공']\n",
      "  영어 토큰: ['##s', 're', 'in', '##ing', 'c', '##tion', 'sp', 'con', 's', '##y']\n",
      "\n",
      "입력: 데이터베이스\n",
      "  한글 토큰: ['##스', '데', '##이터', '##베', '##이스']\n",
      "  영어 토큰: ['##s', 'data', '##y', '##es', 're', '##ing', 'de', 'bu', '##e', 'c']\n",
      "\n",
      "입력: 추천시스템\n",
      "  한글 토큰: ['##스', '추', '##시', '##이']\n",
      "  영어 토큰: ['##s', 're', 'c', 'sp', 'in', 's', 'con', 'bu', 'system', 'co']\n",
      "\n",
      "입력: 검색엔진\n",
      "  한글 토큰: ['검', '##스', '##색']\n",
      "  영어 토큰: ['##s', 're', 'c', 'search', '##r', '##y', 'sp', '##ing', '##n', '##es']\n",
      "\n",
      "입력: 클라우드\n",
      "  한글 토큰: ['##라', '##드', '클', '##우', '##스']\n",
      "  영어 토큰: ['##s', 'c', '##d', '##ing', '##ed', '##y', '##er', 'sp', '##r', '##t']\n",
      "\n",
      "입력: 서버\n",
      "  한글 토큰: ['##버', '서', '##스']\n",
      "  영어 토큰: ['##s', 'server', 're', '##er', '##r', 'sp', 'c', 'bu', 's', 'li']\n",
      "\n",
      "입력: 네트워크\n",
      "  한글 토큰: ['##트', '##크', '##스', '네', '##워']\n",
      "  영어 토큰: ['##s', 'network', '##k', '##ing', 're', '##y', 'networks', 'c', '##d', 's']\n",
      "\n",
      "입력: 컴퓨터\n",
      "  한글 토큰: ['컴', '##퓨', '##터', '##스']\n",
      "  영어 토큰: ['##s', '##er', '##r', 'c', 'computer', 'computing', 're', '##ing', 'com', 'con']\n",
      "\n",
      "입력: 인터넷\n",
      "  한글 토큰: ['##터', '인', '##넷', '##트', '##스']\n",
      "  영어 토큰: ['##s', 'in', 're', 'internet', 'c', 'web', 'sp', 'inter', 'em', 's']\n",
      "\n",
      "입력: 프로그래밍\n",
      "  한글 토큰: ['##그', '프로', '##래', '##라', '##밍']\n",
      "  영어 토큰: ['##ing', '##s', 're', 'c', '##ng', 'sp', 's', 'con', 'gr', 'bu']\n",
      "\n",
      "입력: 알고리즘\n",
      "  한글 토큰: ['##리', '알', '##고', '##이', '##스']\n",
      "  영어 토큰: ['##s', 'algorithm', '##y', 're', 'al', 'c', 'in', 'li', 'bu', 'sp']\n",
      "\n",
      "입력: 데이터\n",
      "  한글 토큰: ['데', '##이터', '##스']\n",
      "  영어 토큰: ['data', 're', 'de', 'c', 'bu', '##s', 'information', 'in', 'co', 'con']\n"
     ]
    }
   ],
   "source": [
    "test_queries = [\n",
    "    # IT/Tech\n",
    "    \"머신러닝\",\n",
    "    \"딥러닝\",\n",
    "    \"자연어처리\",\n",
    "    \"인공지능\",\n",
    "    \"데이터베이스\",\n",
    "    \"추천시스템\",\n",
    "    \"검색엔진\",\n",
    "    \"클라우드\",\n",
    "    \"서버\",\n",
    "    \"네트워크\",\n",
    "    \n",
    "    # General\n",
    "    \"컴퓨터\",\n",
    "    \"인터넷\",\n",
    "    \"프로그래밍\",\n",
    "    \"알고리즘\",\n",
    "    \"데이터\",\n",
    "]\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"v12 INFERENCE TEST RESULTS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for query in test_queries:\n",
    "    result = analyze_query(query)\n",
    "    \n",
    "    print(f\"\\n입력: {result['input']}\")\n",
    "    \n",
    "    # Korean tokens\n",
    "    ko_tokens = [t for t, v in result['korean'][:5]]\n",
    "    print(f\"  한글 토큰: {ko_tokens}\")\n",
    "    \n",
    "    # English tokens\n",
    "    en_tokens = [t for t, v in result['english'][:10]]\n",
    "    print(f\"  영어 토큰: {en_tokens}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detailed Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "DETAILED ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "입력: 추천시스템\n",
      "  기대 한글: ['추천', '시스템']\n",
      "  기대 영어: ['recommend', 'system', 'recommendation']\n",
      "  발견된 영어: ['re', '##com', '##mend', 'system', 're', '##com', '##mend', '##ation']\n",
      "  전체 한글 (8): ['##스', '추', '##시', '##이', '##템', '##드', '##트', '##리']\n",
      "  전체 영어 (92): ['##s', 're', 'c', 'sp', 'in', 's', 'con', 'bu', 'system', 'co', 'dis', '##es', 'ex', '##y', 'sh']\n",
      "\n",
      "입력: 검색엔진\n",
      "  기대 한글: ['검색', '엔진']\n",
      "  기대 영어: ['search', 'engine']\n",
      "  발견된 영어: ['search']\n",
      "  전체 한글 (4): ['검', '##스', '##색', '##이']\n",
      "  전체 영어 (96): ['##s', 're', 'c', 'search', '##r', '##y', 'sp', '##ing', '##n', '##es', 'con', 'bu', 's', '##er', 'in']\n",
      "\n",
      "입력: 머신러닝\n",
      "  기대 한글: ['머신', '러닝']\n",
      "  기대 영어: ['machine', 'learning']\n",
      "  발견된 영어: ['machine', 'learning']\n",
      "  전체 한글 (6): ['##러', '머신', '##라', '##닝', '##리', '##레']\n",
      "  전체 영어 (94): ['##ing', '##ng', '##s', 're', 'c', '##er', 'bu', 'machine', 'mon', 'sp', 'me', '##ting', '##ning', 'in', 'computing']\n",
      "\n",
      "입력: 딥러닝\n",
      "  기대 한글: ['딥', '러닝']\n",
      "  기대 영어: ['deep', 'learning']\n",
      "  발견된 영어: ['deep', 'learning']\n",
      "  전체 한글 (4): ['딥', '##러', '##닝', '##라']\n",
      "  전체 영어 (96): ['##ing', '##ng', '##s', 're', 'c', 'in', '##er', 'bu', 'sp', '##ning', 'con', 'sh', '##ting', 'li', 'fl']\n",
      "\n",
      "입력: 인공지능\n",
      "  기대 한글: ['인공', '지능']\n",
      "  기대 영어: ['artificial', 'intelligence']\n",
      "  발견된 영어: ['artificial', 'intelligence']\n",
      "  전체 한글 (3): ['인', '##지', '##공']\n",
      "  전체 영어 (97): ['##s', 're', 'in', '##ing', 'c', '##tion', 'sp', 'con', 's', '##y', 'bu', 'dis', 'ex', 'co', 'li']\n",
      "\n",
      "입력: 자연어처리\n",
      "  기대 한글: ['자연어', '처리']\n",
      "  기대 영어: ['natural', 'language', 'processing']\n",
      "  발견된 영어: ['language']\n",
      "  전체 한글 (5): ['자', '##리', '##어', '##연', '##스']\n",
      "  전체 영어 (95): ['##s', '##y', '##ing', 're', '##ry', 'c', '##er', '##e', '##es', '##r', '##ed', 'bu', '##d', 'sp', 'in']\n"
     ]
    }
   ],
   "source": [
    "# Detailed analysis for key queries\n",
    "key_queries = [\n",
    "    (\"추천시스템\", [\"추천\", \"시스템\"], [\"recommend\", \"system\", \"recommendation\"]),\n",
    "    (\"검색엔진\", [\"검색\", \"엔진\"], [\"search\", \"engine\"]),\n",
    "    (\"머신러닝\", [\"머신\", \"러닝\"], [\"machine\", \"learning\"]),\n",
    "    (\"딥러닝\", [\"딥\", \"러닝\"], [\"deep\", \"learning\"]),\n",
    "    (\"인공지능\", [\"인공\", \"지능\"], [\"artificial\", \"intelligence\"]),\n",
    "    (\"자연어처리\", [\"자연어\", \"처리\"], [\"natural\", \"language\", \"processing\"]),\n",
    "]\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"DETAILED ANALYSIS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for query, expected_ko, expected_en in key_queries:\n",
    "    result = analyze_query(query, top_k=100)\n",
    "    \n",
    "    print(f\"\\n입력: {query}\")\n",
    "    print(f\"  기대 한글: {expected_ko}\")\n",
    "    print(f\"  기대 영어: {expected_en}\")\n",
    "    \n",
    "    # Check English matches\n",
    "    all_en = [t for t, v in result['english']]\n",
    "    found_en = []\n",
    "    for exp in expected_en:\n",
    "        exp_tokens = tokenizer.tokenize(exp.lower())\n",
    "        for tok in exp_tokens:\n",
    "            if tok in all_en:\n",
    "                found_en.append(tok)\n",
    "    \n",
    "    print(f\"  발견된 영어: {found_en}\")\n",
    "    print(f\"  전체 한글 ({len(result['korean'])}): {[t for t, v in result['korean'][:10]]}\")\n",
    "    print(f\"  전체 영어 ({len(result['english'])}): {all_en[:15]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "SUMMARY STATISTICS (Top-50 tokens per query)\n",
      "================================================================================\n",
      "\n",
      "  Queries tested: 15\n",
      "  Avg Korean tokens: 4.2\n",
      "  Avg English tokens: 45.8\n",
      "  Avg Other tokens: 0.0\n",
      "\n",
      "  Korean ratio: 8.4%\n",
      "  English ratio: 91.6%\n"
     ]
    }
   ],
   "source": [
    "# Calculate statistics\n",
    "total_ko_activated = 0\n",
    "total_en_activated = 0\n",
    "total_other = 0\n",
    "\n",
    "for query in test_queries:\n",
    "    result = analyze_query(query, top_k=50)\n",
    "    total_ko_activated += len(result['korean'])\n",
    "    total_en_activated += len(result['english'])\n",
    "    total_other += len(result['other'])\n",
    "\n",
    "n_queries = len(test_queries)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"SUMMARY STATISTICS (Top-50 tokens per query)\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\n  Queries tested: {n_queries}\")\n",
    "print(f\"  Avg Korean tokens: {total_ko_activated / n_queries:.1f}\")\n",
    "print(f\"  Avg English tokens: {total_en_activated / n_queries:.1f}\")\n",
    "print(f\"  Avg Other tokens: {total_other / n_queries:.1f}\")\n",
    "print(f\"\\n  Korean ratio: {total_ko_activated / (total_ko_activated + total_en_activated + total_other) * 100:.1f}%\")\n",
    "print(f\"  English ratio: {total_en_activated / (total_ko_activated + total_en_activated + total_other) * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "v12 INFERENCE TEST COMPLETE\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"v12 INFERENCE TEST COMPLETE\")\n",
    "print(\"=\" * 80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

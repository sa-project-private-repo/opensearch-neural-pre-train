{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# v13 Inference Test: Noun-Focused KO-EN Model\n",
    "\n",
    "Test the trained v13 model using the `TermExpander` module.\n",
    "\n",
    "**Key Features:**\n",
    "- `TermExpander.expand_to_list()`: Get expanded terms as list\n",
    "- `TermExpander.expand()`: Get detailed expansion result\n",
    "- `TermExpander.get_sparse_vector()`: Get OpenSearch-compatible sparse vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "def find_project_root():\n",
    "    candidates = [\n",
    "        Path.cwd(),\n",
    "        Path.cwd().parent,\n",
    "        Path.cwd().parent.parent,\n",
    "        Path(\"/home/west/Documents/cursor-workspace/opensearch-neural-pre-train\"),\n",
    "    ]\n",
    "    for candidate in candidates:\n",
    "        if (candidate / \"CLAUDE.md\").exists() or (candidate / \".git\").exists():\n",
    "            return candidate\n",
    "    return Path(\"/home/west/Documents/cursor-workspace/opensearch-neural-pre-train\")\n",
    "\n",
    "PROJECT_ROOT = find_project_root()\n",
    "sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "print(f\"Project root: {PROJECT_ROOT}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load TermExpander"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.inference import TermExpander\n",
    "\n",
    "# Load v13 model\n",
    "checkpoint_path = PROJECT_ROOT / 'outputs' / 'v13_nouns' / 'best_model.pt'\n",
    "expander = TermExpander.from_checkpoint(checkpoint_path)\n",
    "\n",
    "print(f\"Model: {expander.config['model_name']}\")\n",
    "print(f\"Device: {expander.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Usage: expand_to_list()\n",
    "\n",
    "Get a flat list of expanded terms: `[원본, 서브워드들, 영어번역들]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic usage\n",
    "test_queries = [\n",
    "    '머신러닝',\n",
    "    '딥러닝',\n",
    "    '자연어처리',\n",
    "    '검색엔진',\n",
    "    '추천시스템',\n",
    "    '데이터베이스',\n",
    "    '인공지능',\n",
    "    '클라우드',\n",
    "    '네트워크',\n",
    "    '알고리즘',\n",
    "]\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"expand_to_list() 결과\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for query in test_queries:\n",
    "    result = expander.expand_to_list(query)\n",
    "    print(f\"{query} → {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detailed Usage: expand()\n",
    "\n",
    "Get detailed expansion result with scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed expansion\n",
    "result = expander.expand('머신러닝')\n",
    "\n",
    "print(f\"Original: {result.original}\")\n",
    "print(f\"Subwords: {result.subwords}\")\n",
    "print(f\"\\nEnglish tokens (with scores):\")\n",
    "for token, score in result.english_tokens[:10]:\n",
    "    print(f\"  {token:15s}: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to dictionary\n",
    "import json\n",
    "\n",
    "result_dict = result.to_dict()\n",
    "print(json.dumps(result_dict, ensure_ascii=False, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenSearch Integration: get_sparse_vector()\n",
    "\n",
    "Get sparse vector for OpenSearch neural sparse queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get sparse vector for OpenSearch\n",
    "sparse_vec = expander.get_sparse_vector('머신러닝', top_k=20)\n",
    "\n",
    "print(\"Sparse Vector (top 15):\")\n",
    "for token, score in sorted(sparse_vec.items(), key=lambda x: -x[1])[:15]:\n",
    "    print(f\"  {token:15s}: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example OpenSearch query format\n",
    "opensearch_query = {\n",
    "    \"query\": {\n",
    "        \"neural_sparse\": {\n",
    "            \"content_embedding\": {\n",
    "                \"query_tokens\": sparse_vec\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"OpenSearch Query Example:\")\n",
    "print(json.dumps(opensearch_query, ensure_ascii=False, indent=2)[:500] + \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch expansion\n",
    "queries = ['머신러닝', '딥러닝', '자연어처리']\n",
    "results = expander.expand_batch(queries)\n",
    "\n",
    "for r in results:\n",
    "    print(f\"{r.original}: {r.to_list()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Load checkpoint to get metrics\n",
    "checkpoint = torch.load(checkpoint_path, map_location='cpu', weights_only=False)\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"v13 Model Performance\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"English Activation Rate: {checkpoint.get('en_rate', 'N/A')}%\")\n",
    "print(f\"Korean Preservation Rate: {checkpoint.get('ko_rate', 'N/A')}%\")\n",
    "print(f\"Training Epoch: {checkpoint.get('epoch', 'N/A')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"INFERENCE TEST COMPLETE\")\n",
    "print(\"=\" * 50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# v19 Data Ingestion\n",
    "\n",
    "This notebook collects Korean-English term pairs from multiple sources for training the cross-lingual SPLADE model.\n",
    "\n",
    "## Data Sources\n",
    "\n",
    "| Source | Description | Expected Pairs |\n",
    "|--------|-------------|----------------|\n",
    "| MUSE | Facebook's bilingual dictionary | ~20,000 |\n",
    "| Wikidata | Entity labels with Korean/English | ~50,000 |\n",
    "| IT Terminology | Technical terms | ~400 |\n",
    "\n",
    "## Output\n",
    "\n",
    "- `dataset/v19_high_quality/term_pairs.jsonl` - Raw term pairs for preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cell-1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: /home/west/Documents/cursor-workspace/opensearch-neural-pre-train\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Find project root\n",
    "def find_project_root():\n",
    "    \"\"\"Find project root by looking for markers like pyproject.toml or src/\"\"\"\n",
    "    current = Path.cwd()\n",
    "    for parent in [current] + list(current.parents):\n",
    "        if (parent / \"pyproject.toml\").exists() or (parent / \"src\").exists():\n",
    "            return parent\n",
    "    return Path.cwd().parent.parent\n",
    "\n",
    "PROJECT_ROOT = find_project_root()\n",
    "sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "print(f\"Project root: {PROJECT_ROOT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cell-2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output directory: /home/west/Documents/cursor-workspace/opensearch-neural-pre-train/dataset/v19_high_quality\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "import time\n",
    "from collections import defaultdict\n",
    "from typing import List, Dict, Set, Tuple\n",
    "\n",
    "import requests\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Output directory\n",
    "OUTPUT_DIR = PROJECT_ROOT / \"dataset\" / \"v19_high_quality\"\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Output directory: {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-3",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cell-4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration:\n",
      "  min_ko_length: 2\n",
      "  max_ko_length: 20\n",
      "  min_en_length: 2\n",
      "  max_en_length: 30\n",
      "  request_timeout: 120\n",
      "  wikidata_delay: 2.0\n"
     ]
    }
   ],
   "source": [
    "CONFIG = {\n",
    "    # Quality filters\n",
    "    \"min_ko_length\": 2,\n",
    "    \"max_ko_length\": 20,\n",
    "    \"min_en_length\": 2,\n",
    "    \"max_en_length\": 30,\n",
    "    \n",
    "    # Request settings\n",
    "    \"request_timeout\": 120,\n",
    "    \"wikidata_delay\": 2.0,  # Delay between Wikidata queries\n",
    "}\n",
    "\n",
    "print(\"Configuration:\")\n",
    "for k, v in CONFIG.items():\n",
    "    print(f\"  {k}: {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-5",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cell-6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Helper functions defined.\n",
      "  is_valid_korean('안녕'): True\n",
      "  is_valid_english('hello'): True\n"
     ]
    }
   ],
   "source": [
    "def is_valid_korean(text: str) -> bool:\n",
    "    \"\"\"Check if text contains Korean characters.\"\"\"\n",
    "    return any('\\uac00' <= c <= '\\ud7a3' for c in text)\n",
    "\n",
    "\n",
    "def is_valid_english(text: str) -> bool:\n",
    "    \"\"\"Check if text is valid English (letters only, no special chars).\"\"\"\n",
    "    if not text:\n",
    "        return False\n",
    "    # Must contain at least one ASCII letter\n",
    "    has_letter = any(c.isalpha() and c.isascii() for c in text)\n",
    "    # Should not be all uppercase abbreviations longer than 5 chars\n",
    "    if text.isupper() and len(text) > 5:\n",
    "        return False\n",
    "    return has_letter\n",
    "\n",
    "\n",
    "def clean_text(text: str) -> str:\n",
    "    \"\"\"Clean text for consistency.\"\"\"\n",
    "    text = text.strip()\n",
    "    # Remove parenthetical content\n",
    "    text = re.sub(r'\\s*\\([^)]*\\)', '', text)\n",
    "    # Remove extra whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    return text.strip()\n",
    "\n",
    "\n",
    "print(\"Helper functions defined.\")\n",
    "print(f\"  is_valid_korean('안녕'): {is_valid_korean('안녕')}\")\n",
    "print(f\"  is_valid_english('hello'): {is_valid_english('hello')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-7",
   "metadata": {},
   "source": [
    "## 1. MUSE Bilingual Dictionary\n",
    "\n",
    "Facebook's MUSE project provides high-quality bilingual dictionaries.\n",
    "- KO -> EN: https://dl.fbaipublicfiles.com/arrival/dictionaries/ko-en.txt\n",
    "- EN -> KO: https://dl.fbaipublicfiles.com/arrival/dictionaries/en-ko.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cell-8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "1. COLLECTING MUSE DICTIONARY\n",
      "======================================================================\n",
      "\n",
      "Downloading from https://dl.fbaipublicfiles.com/arrival/dictionaries/ko-en.txt...\n",
      "Status: 200\n",
      "Got 20,549 lines\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ff387fe5bf347328391f418bb5c0126",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MUSE (ko->en):   0%|          | 0/20549 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading from https://dl.fbaipublicfiles.com/arrival/dictionaries/en-ko.txt...\n",
      "Status: 200\n",
      "Got 22,357 lines\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d92c04c910a24265b8e4302049d3a6a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MUSE (en->ko):   0%|          | 0/22357 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Collected 41,032 pairs from MUSE\n"
     ]
    }
   ],
   "source": [
    "def collect_muse_dictionary() -> List[Dict]:\n",
    "    \"\"\"Collect KO-EN pairs from MUSE bilingual dictionaries.\"\"\"\n",
    "    print(\"=\" * 70)\n",
    "    print(\"1. COLLECTING MUSE DICTIONARY\")\n",
    "    print(\"=\" * 70)\n",
    "\n",
    "    pairs = []\n",
    "\n",
    "    muse_urls = [\n",
    "        (\"https://dl.fbaipublicfiles.com/arrival/dictionaries/ko-en.txt\", \"ko\", \"en\"),\n",
    "        (\"https://dl.fbaipublicfiles.com/arrival/dictionaries/en-ko.txt\", \"en\", \"ko\"),\n",
    "    ]\n",
    "\n",
    "    for url, src_lang, tgt_lang in muse_urls:\n",
    "        print(f\"\\nDownloading from {url}...\")\n",
    "        try:\n",
    "            response = requests.get(url, timeout=CONFIG[\"request_timeout\"], headers={\n",
    "                \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36\"\n",
    "            })\n",
    "            print(f\"Status: {response.status_code}\")\n",
    "\n",
    "            if response.status_code == 200:\n",
    "                # Force UTF-8 encoding for Korean characters\n",
    "                response.encoding = 'utf-8'\n",
    "                content = response.text.strip()\n",
    "                if not content:\n",
    "                    print(f\"Empty response from {url}\")\n",
    "                    continue\n",
    "\n",
    "                lines = content.split('\\n')\n",
    "                print(f\"Got {len(lines):,} lines\")\n",
    "\n",
    "                for line in tqdm(lines, desc=f\"MUSE ({src_lang}->{tgt_lang})\"):\n",
    "                    parts = line.strip().split()  # Split by whitespace\n",
    "                    if len(parts) >= 2:\n",
    "                        if src_lang == \"ko\":\n",
    "                            ko_word, en_word = parts[0].strip(), parts[1].strip()\n",
    "                        else:\n",
    "                            en_word, ko_word = parts[0].strip(), parts[1].strip()\n",
    "\n",
    "                        if (is_valid_korean(ko_word) and\n",
    "                            is_valid_english(en_word) and\n",
    "                            len(ko_word) >= CONFIG[\"min_ko_length\"] and\n",
    "                            len(en_word) >= CONFIG[\"min_en_length\"]):\n",
    "                            pairs.append({\n",
    "                                \"ko\": ko_word,\n",
    "                                \"en\": en_word.lower(),\n",
    "                                \"source\": \"muse\"\n",
    "                            })\n",
    "            else:\n",
    "                print(f\"Failed: {response.status_code}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\")\n",
    "\n",
    "    print(f\"\\nCollected {len(pairs):,} pairs from MUSE\")\n",
    "    return pairs\n",
    "\n",
    "\n",
    "muse_pairs = collect_muse_dictionary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-9",
   "metadata": {},
   "source": [
    "## 2. Wikidata Labels\n",
    "\n",
    "Wikidata provides entity labels in multiple languages. We query for entities with both Korean and English labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "2. COLLECTING WIKIDATA LABELS\n",
      "======================================================================\n",
      "\n",
      "Executing Wikidata query 1/4...\n"
     ]
    }
   ],
   "source": [
    "def collect_wikidata_labels() -> List[Dict]:\n",
    "    \"\"\"Collect KO-EN pairs from Wikidata entity labels.\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"2. COLLECTING WIKIDATA LABELS\")\n",
    "    print(\"=\" * 70)\n",
    "\n",
    "    pairs = []\n",
    "    endpoint = \"https://query.wikidata.org/sparql\"\n",
    "    headers = {\n",
    "        \"User-Agent\": \"KoEnTermCollector/1.0\",\n",
    "        \"Accept\": \"application/json\"\n",
    "    }\n",
    "\n",
    "    # Multiple queries to get diverse data\n",
    "    queries = [\n",
    "        # Query 1: Common entities (people, places, things)\n",
    "        \"\"\"\n",
    "        SELECT ?item ?koLabel ?enLabel WHERE {\n",
    "          ?item wdt:P31 ?type .\n",
    "          ?item rdfs:label ?koLabel . FILTER(LANG(?koLabel) = \"ko\")\n",
    "          ?item rdfs:label ?enLabel . FILTER(LANG(?enLabel) = \"en\")\n",
    "          FILTER(STRLEN(?koLabel) >= 2 && STRLEN(?koLabel) <= 20)\n",
    "          FILTER(STRLEN(?enLabel) >= 2 && STRLEN(?enLabel) <= 30)\n",
    "        }\n",
    "        LIMIT 30000\n",
    "        \"\"\",\n",
    "\n",
    "        # Query 2: Scientific and technical terms\n",
    "        \"\"\"\n",
    "        SELECT ?item ?koLabel ?enLabel WHERE {\n",
    "          { ?item wdt:P31 wd:Q11862829 } UNION  # academic discipline\n",
    "          { ?item wdt:P31 wd:Q5633421 } UNION   # scientific journal\n",
    "          { ?item wdt:P31 wd:Q7397 } UNION      # software\n",
    "          { ?item wdt:P31 wd:Q28243 }           # programming language\n",
    "          ?item rdfs:label ?koLabel . FILTER(LANG(?koLabel) = \"ko\")\n",
    "          ?item rdfs:label ?enLabel . FILTER(LANG(?enLabel) = \"en\")\n",
    "        }\n",
    "        LIMIT 20000\n",
    "        \"\"\",\n",
    "\n",
    "        # Query 3: Organizations and companies\n",
    "        \"\"\"\n",
    "        SELECT ?item ?koLabel ?enLabel WHERE {\n",
    "          { ?item wdt:P31 wd:Q4830453 } UNION   # business\n",
    "          { ?item wdt:P31 wd:Q43229 }           # organization\n",
    "          ?item rdfs:label ?koLabel . FILTER(LANG(?koLabel) = \"ko\")\n",
    "          ?item rdfs:label ?enLabel . FILTER(LANG(?enLabel) = \"en\")\n",
    "          FILTER(STRLEN(?koLabel) >= 2 && STRLEN(?koLabel) <= 15)\n",
    "        }\n",
    "        LIMIT 15000\n",
    "        \"\"\",\n",
    "\n",
    "        # Query 4: Concepts and abstract terms\n",
    "        \"\"\"\n",
    "        SELECT ?item ?koLabel ?enLabel WHERE {\n",
    "          { ?item wdt:P31 wd:Q35120 } UNION     # entity\n",
    "          { ?item wdt:P31 wd:Q151885 }          # concept\n",
    "          ?item rdfs:label ?koLabel . FILTER(LANG(?koLabel) = \"ko\")\n",
    "          ?item rdfs:label ?enLabel . FILTER(LANG(?enLabel) = \"en\")\n",
    "          FILTER(STRLEN(?koLabel) >= 2 && STRLEN(?koLabel) <= 10)\n",
    "          FILTER(STRLEN(?enLabel) >= 3 && STRLEN(?enLabel) <= 20)\n",
    "        }\n",
    "        LIMIT 10000\n",
    "        \"\"\"\n",
    "    ]\n",
    "\n",
    "    for i, query in enumerate(queries):\n",
    "        print(f\"\\nExecuting Wikidata query {i+1}/{len(queries)}...\")\n",
    "        try:\n",
    "            response = requests.get(\n",
    "                endpoint,\n",
    "                params={\"query\": query, \"format\": \"json\"},\n",
    "                headers=headers,\n",
    "                timeout=120\n",
    "            )\n",
    "\n",
    "            if response.status_code == 200:\n",
    "                data = response.json()\n",
    "                results = data.get(\"results\", {}).get(\"bindings\", [])\n",
    "\n",
    "                for item in tqdm(results, desc=f\"Wikidata Q{i+1}\"):\n",
    "                    ko_label = item.get(\"koLabel\", {}).get(\"value\", \"\")\n",
    "                    en_label = item.get(\"enLabel\", {}).get(\"value\", \"\")\n",
    "\n",
    "                    ko_label = clean_text(ko_label)\n",
    "                    en_label = clean_text(en_label)\n",
    "\n",
    "                    if (is_valid_korean(ko_label) and\n",
    "                        is_valid_english(en_label) and\n",
    "                        len(ko_label) >= CONFIG[\"min_ko_length\"] and\n",
    "                        len(en_label) >= CONFIG[\"min_en_length\"]):\n",
    "                        pairs.append({\n",
    "                            \"ko\": ko_label,\n",
    "                            \"en\": en_label.lower(),\n",
    "                            \"source\": \"wikidata\"\n",
    "                        })\n",
    "            else:\n",
    "                print(f\"Query {i+1} failed: {response.status_code}\")\n",
    "\n",
    "            # Rate limiting\n",
    "            time.sleep(CONFIG[\"wikidata_delay\"])\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Query {i+1} error: {e}\")\n",
    "\n",
    "    print(f\"\\nCollected {len(pairs):,} pairs from Wikidata\")\n",
    "    return pairs\n",
    "\n",
    "\n",
    "wikidata_pairs = collect_wikidata_labels()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-11",
   "metadata": {},
   "source": [
    "## 3. IT/Tech Terminology\n",
    "\n",
    "Curated list of common IT and technical terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_it_terminology() -> List[Dict]:\n",
    "    \"\"\"Collect IT/Tech terminology pairs.\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"3. COLLECTING IT/TECH TERMINOLOGY\")\n",
    "    print(\"=\" * 70)\n",
    "\n",
    "    # Extended IT terminology list\n",
    "    it_terms = [\n",
    "        # Programming\n",
    "        (\"프로그램\", \"program\"), (\"프로그래밍\", \"programming\"), (\"코드\", \"code\"),\n",
    "        (\"코딩\", \"coding\"), (\"소프트웨어\", \"software\"), (\"하드웨어\", \"hardware\"),\n",
    "        (\"알고리즘\", \"algorithm\"), (\"함수\", \"function\"), (\"변수\", \"variable\"),\n",
    "        (\"클래스\", \"class\"), (\"객체\", \"object\"), (\"메서드\", \"method\"),\n",
    "        (\"인터페이스\", \"interface\"), (\"모듈\", \"module\"), (\"라이브러리\", \"library\"),\n",
    "        (\"프레임워크\", \"framework\"), (\"패키지\", \"package\"), (\"컴파일러\", \"compiler\"),\n",
    "        (\"인터프리터\", \"interpreter\"), (\"디버깅\", \"debugging\"), (\"테스트\", \"test\"),\n",
    "        (\"배포\", \"deployment\"), (\"버전\", \"version\"), (\"업데이트\", \"update\"),\n",
    "        \n",
    "        # Web/Network\n",
    "        (\"네트워크\", \"network\"), (\"서버\", \"server\"), (\"클라이언트\", \"client\"),\n",
    "        (\"데이터베이스\", \"database\"), (\"쿼리\", \"query\"), (\"인덱스\", \"index\"),\n",
    "        (\"캐시\", \"cache\"), (\"프록시\", \"proxy\"), (\"방화벽\", \"firewall\"),\n",
    "        (\"프로토콜\", \"protocol\"), (\"도메인\", \"domain\"), (\"호스트\", \"host\"),\n",
    "        (\"라우터\", \"router\"), (\"스위치\", \"switch\"), (\"게이트웨이\", \"gateway\"),\n",
    "        \n",
    "        # Data/AI\n",
    "        (\"데이터\", \"data\"), (\"정보\", \"information\"), (\"분석\", \"analysis\"),\n",
    "        (\"머신러닝\", \"machine learning\"), (\"딥러닝\", \"deep learning\"),\n",
    "        (\"인공지능\", \"artificial intelligence\"), (\"신경망\", \"neural network\"),\n",
    "        (\"모델\", \"model\"), (\"학습\", \"training\"), (\"추론\", \"inference\"),\n",
    "        (\"예측\", \"prediction\"), (\"분류\", \"classification\"), (\"회귀\", \"regression\"),\n",
    "        (\"클러스터링\", \"clustering\"), (\"임베딩\", \"embedding\"), (\"벡터\", \"vector\"),\n",
    "        (\"텐서\", \"tensor\"), (\"가중치\", \"weight\"), (\"편향\", \"bias\"),\n",
    "        (\"손실함수\", \"loss function\"), (\"최적화\", \"optimization\"),\n",
    "        \n",
    "        # Cloud/DevOps\n",
    "        (\"클라우드\", \"cloud\"), (\"컨테이너\", \"container\"), (\"도커\", \"docker\"),\n",
    "        (\"쿠버네티스\", \"kubernetes\"), (\"마이크로서비스\", \"microservice\"),\n",
    "        (\"오케스트레이션\", \"orchestration\"), (\"스케일링\", \"scaling\"),\n",
    "        (\"로드밸런서\", \"load balancer\"), (\"모니터링\", \"monitoring\"),\n",
    "        (\"로깅\", \"logging\"), (\"파이프라인\", \"pipeline\"), (\"자동화\", \"automation\"),\n",
    "        \n",
    "        # Security\n",
    "        (\"보안\", \"security\"), (\"인증\", \"authentication\"), (\"권한\", \"authorization\"),\n",
    "        (\"암호화\", \"encryption\"), (\"복호화\", \"decryption\"), (\"해시\", \"hash\"),\n",
    "        (\"토큰\", \"token\"), (\"세션\", \"session\"), (\"쿠키\", \"cookie\"),\n",
    "        \n",
    "        # UI/UX\n",
    "        (\"사용자\", \"user\"), (\"인터페이스\", \"interface\"), (\"디자인\", \"design\"),\n",
    "        (\"레이아웃\", \"layout\"), (\"컴포넌트\", \"component\"), (\"위젯\", \"widget\"),\n",
    "        (\"버튼\", \"button\"), (\"메뉴\", \"menu\"), (\"네비게이션\", \"navigation\"),\n",
    "        (\"폼\", \"form\"), (\"입력\", \"input\"), (\"출력\", \"output\"),\n",
    "        \n",
    "        # General tech\n",
    "        (\"시스템\", \"system\"), (\"플랫폼\", \"platform\"), (\"애플리케이션\", \"application\"),\n",
    "        (\"서비스\", \"service\"), (\"솔루션\", \"solution\"), (\"아키텍처\", \"architecture\"),\n",
    "        (\"인프라\", \"infrastructure\"), (\"리소스\", \"resource\"), (\"환경\", \"environment\"),\n",
    "        (\"설정\", \"configuration\"), (\"옵션\", \"option\"), (\"파라미터\", \"parameter\"),\n",
    "        (\"프로세스\", \"process\"), (\"스레드\", \"thread\"), (\"메모리\", \"memory\"),\n",
    "        (\"스토리지\", \"storage\"), (\"파일\", \"file\"), (\"폴더\", \"folder\"),\n",
    "        (\"디렉토리\", \"directory\"), (\"경로\", \"path\"), (\"확장자\", \"extension\"),\n",
    "        \n",
    "        # Search/NLP\n",
    "        (\"검색\", \"search\"), (\"색인\", \"indexing\"), (\"랭킹\", \"ranking\"),\n",
    "        (\"토큰화\", \"tokenization\"), (\"형태소\", \"morpheme\"), (\"어휘\", \"vocabulary\"),\n",
    "        (\"말뭉치\", \"corpus\"), (\"문서\", \"document\"), (\"텍스트\", \"text\"),\n",
    "        (\"자연어처리\", \"natural language processing\"), (\"번역\", \"translation\"),\n",
    "        (\"요약\", \"summarization\"), (\"질의응답\", \"question answering\"),\n",
    "        \n",
    "        # Additional common terms\n",
    "        (\"기능\", \"feature\"), (\"성능\", \"performance\"), (\"효율\", \"efficiency\"),\n",
    "        (\"정확도\", \"accuracy\"), (\"정밀도\", \"precision\"), (\"재현율\", \"recall\"),\n",
    "        (\"오류\", \"error\"), (\"예외\", \"exception\"), (\"버그\", \"bug\"),\n",
    "        (\"이슈\", \"issue\"), (\"태스크\", \"task\"), (\"작업\", \"job\"),\n",
    "        (\"요청\", \"request\"), (\"응답\", \"response\"), (\"상태\", \"status\"),\n",
    "        (\"이벤트\", \"event\"), (\"핸들러\", \"handler\"), (\"콜백\", \"callback\"),\n",
    "        (\"비동기\", \"asynchronous\"), (\"동기\", \"synchronous\"), (\"병렬\", \"parallel\"),\n",
    "        (\"순차\", \"sequential\"), (\"반복\", \"iteration\"), (\"재귀\", \"recursion\"),\n",
    "        \n",
    "        # More IT terms\n",
    "        (\"아이디\", \"id\"), (\"비밀번호\", \"password\"), (\"로그인\", \"login\"),\n",
    "        (\"로그아웃\", \"logout\"), (\"계정\", \"account\"), (\"프로필\", \"profile\"),\n",
    "        (\"설치\", \"installation\"), (\"다운로드\", \"download\"), (\"업로드\", \"upload\"),\n",
    "        (\"동기화\", \"synchronization\"), (\"백업\", \"backup\"), (\"복원\", \"restore\"),\n",
    "        (\"삭제\", \"delete\"), (\"수정\", \"edit\"), (\"생성\", \"create\"),\n",
    "        (\"조회\", \"read\"), (\"갱신\", \"update\"), (\"추가\", \"add\"),\n",
    "        (\"제거\", \"remove\"), (\"복사\", \"copy\"), (\"붙여넣기\", \"paste\"),\n",
    "        (\"실행\", \"execute\"), (\"중지\", \"stop\"), (\"재시작\", \"restart\"),\n",
    "        (\"초기화\", \"initialize\"), (\"종료\", \"terminate\"), (\"시작\", \"start\"),\n",
    "        \n",
    "        # Hardware/OS\n",
    "        (\"운영체제\", \"operating system\"), (\"커널\", \"kernel\"), (\"드라이버\", \"driver\"),\n",
    "        (\"프로세서\", \"processor\"), (\"그래픽카드\", \"graphics card\"),\n",
    "        (\"마더보드\", \"motherboard\"), (\"전원공급장치\", \"power supply\"),\n",
    "        (\"랜카드\", \"network card\"), (\"사운드카드\", \"sound card\"),\n",
    "        \n",
    "        # Mobile\n",
    "        (\"앱\", \"app\"), (\"모바일\", \"mobile\"), (\"스마트폰\", \"smartphone\"),\n",
    "        (\"태블릿\", \"tablet\"), (\"터치스크린\", \"touchscreen\"), (\"제스처\", \"gesture\"),\n",
    "        (\"알림\", \"notification\"), (\"푸시\", \"push\"), (\"위치정보\", \"location\"),\n",
    "    ]\n",
    "\n",
    "    pairs = []\n",
    "    for ko, en in it_terms:\n",
    "        if is_valid_korean(ko) and is_valid_english(en):\n",
    "            pairs.append({\n",
    "                \"ko\": ko,\n",
    "                \"en\": en.lower(),\n",
    "                \"source\": \"it_terminology\"\n",
    "            })\n",
    "\n",
    "    print(f\"Collected {len(pairs):,} IT/Tech terms\")\n",
    "    return pairs\n",
    "\n",
    "\n",
    "it_pairs = collect_it_terminology()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-13",
   "metadata": {},
   "source": [
    "## 4. Combine and Filter Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all pairs\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"COMBINING ALL DATA\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "all_pairs = muse_pairs + wikidata_pairs + it_pairs\n",
    "print(f\"\\nTotal raw pairs: {len(all_pairs):,}\")\n",
    "print(f\"  MUSE: {len(muse_pairs):,}\")\n",
    "print(f\"  Wikidata: {len(wikidata_pairs):,}\")\n",
    "print(f\"  IT Terminology: {len(it_pairs):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_and_deduplicate(pairs: List[Dict]) -> List[Dict]:\n",
    "    \"\"\"Filter and deduplicate pairs.\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"FILTERING AND DEDUPLICATION\")\n",
    "    print(\"=\" * 70)\n",
    "\n",
    "    # Quality filtering\n",
    "    filtered = []\n",
    "    rejection_reasons = defaultdict(int)\n",
    "\n",
    "    for pair in tqdm(pairs, desc=\"Filtering\"):\n",
    "        ko = pair.get(\"ko\", \"\")\n",
    "        en = pair.get(\"en\", \"\")\n",
    "\n",
    "        # Check Korean\n",
    "        if not is_valid_korean(ko):\n",
    "            rejection_reasons[\"no_korean\"] += 1\n",
    "            continue\n",
    "        if len(ko) < CONFIG[\"min_ko_length\"]:\n",
    "            rejection_reasons[\"ko_too_short\"] += 1\n",
    "            continue\n",
    "        if len(ko) > CONFIG[\"max_ko_length\"]:\n",
    "            rejection_reasons[\"ko_too_long\"] += 1\n",
    "            continue\n",
    "\n",
    "        # Check English\n",
    "        if not is_valid_english(en):\n",
    "            rejection_reasons[\"en_no_letters\"] += 1\n",
    "            continue\n",
    "        if len(en) < CONFIG[\"min_en_length\"]:\n",
    "            rejection_reasons[\"en_too_short\"] += 1\n",
    "            continue\n",
    "        if len(en) > CONFIG[\"max_en_length\"]:\n",
    "            rejection_reasons[\"en_too_long\"] += 1\n",
    "            continue\n",
    "\n",
    "        filtered.append(pair)\n",
    "\n",
    "    print(f\"Filtered: {len(pairs):,} -> {len(filtered):,}\")\n",
    "    if rejection_reasons:\n",
    "        print(\"Rejection reasons:\")\n",
    "        for reason, count in sorted(rejection_reasons.items(), key=lambda x: -x[1]):\n",
    "            print(f\"  {reason}: {count:,}\")\n",
    "\n",
    "    # Deduplicate by (ko, en) pair\n",
    "    seen = set()\n",
    "    unique_pairs = []\n",
    "\n",
    "    for pair in tqdm(filtered, desc=\"Deduplicating\"):\n",
    "        key = (pair[\"ko\"], pair[\"en\"])\n",
    "        if key not in seen:\n",
    "            seen.add(key)\n",
    "            unique_pairs.append(pair)\n",
    "\n",
    "    print(f\"After deduplication: {len(unique_pairs):,}\")\n",
    "    return unique_pairs\n",
    "\n",
    "\n",
    "final_pairs = filter_and_deduplicate(all_pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-16",
   "metadata": {},
   "source": [
    "## 5. Statistics and Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final statistics\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"FINAL STATISTICS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"\\nTotal unique pairs: {len(final_pairs):,}\")\n",
    "\n",
    "# Count by source\n",
    "source_counts = defaultdict(int)\n",
    "for pair in final_pairs:\n",
    "    source_counts[pair[\"source\"]] += 1\n",
    "\n",
    "print(\"\\nPairs by source:\")\n",
    "for source, count in sorted(source_counts.items(), key=lambda x: -x[1]):\n",
    "    pct = count / len(final_pairs) * 100\n",
    "    print(f\"  {source}: {count:,} ({pct:.1f}%)\")\n",
    "\n",
    "# Sample data\n",
    "print(\"\\nSample pairs:\")\n",
    "import random\n",
    "for pair in random.sample(final_pairs, min(10, len(final_pairs))):\n",
    "    print(f\"  {pair['ko']} -> {pair['en']} ({pair['source']})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to JSONL\n",
    "output_path = OUTPUT_DIR / \"term_pairs.jsonl\"\n",
    "\n",
    "with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    for pair in tqdm(final_pairs, desc=\"Saving\"):\n",
    "        f.write(json.dumps(pair, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "print(f\"\\nSaved to: {output_path}\")\n",
    "print(f\"File size: {output_path.stat().st_size / 1024:.1f} KB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-19",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Data collection complete! The term pairs have been saved to `dataset/v19_high_quality/term_pairs.jsonl`.\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "1. **Run `01_data_preparation.ipynb`** - Process and cluster terms\n",
    "2. **Run `02_training.ipynb`** - Train the SPLADE model\n",
    "3. **Run `03_inference_test.ipynb`** - Test the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-20",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"DATA COLLECTION COMPLETE\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\nOutput: {output_path}\")\n",
    "print(f\"Total pairs: {len(final_pairs):,}\")\n",
    "print(\"\\nNext: Run 01_data_preparation.ipynb to process this data\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

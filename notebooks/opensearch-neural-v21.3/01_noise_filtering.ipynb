{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# v21.3 Noise Filtering Pipeline\n",
    "\n",
    "This notebook applies three algorithmic filtering methods to remove low-quality synonym pairs:\n",
    "\n",
    "1. **Information Gain (IG)**: Filters pairs with low semantic expansion value\n",
    "2. **Pointwise Mutual Information (PMI)**: Filters pairs with low corpus co-occurrence\n",
    "3. **Cross-Encoder Reranking**: Validates semantic similarity with cross-encoder\n",
    "\n",
    "## Filtering Strategy\n",
    "\n",
    "| Filter | What it catches | Threshold |\n",
    "|--------|-----------------|----------|\n",
    "| IG | Truncations, case changes | Bottom 10% percentile |\n",
    "| PMI | False positive embeddings | Bottom 10% percentile |\n",
    "| Cross-Encoder | Semantically dissimilar pairs | Bottom 10% percentile |\n",
    "\n",
    "## Ensemble Decision\n",
    "\n",
    "A pair is **kept** if it passes at least 2 of 3 filters (majority voting)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "def find_project_root():\n",
    "    current = Path.cwd()\n",
    "    for parent in [current] + list(current.parents):\n",
    "        if (parent / \"pyproject.toml\").exists() or (parent / \"src\").exists():\n",
    "            return parent\n",
    "    return Path.cwd().parent.parent\n",
    "\n",
    "PROJECT_ROOT = find_project_root()\n",
    "sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "import json\n",
    "import logging\n",
    "import numpy as np\n",
    "from collections import defaultdict, Counter\n",
    "from typing import Dict, List, Set, Tuple\n",
    "from dataclasses import dataclass, field\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "print(f\"Project root: {PROJECT_ROOT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "DATA_DIR = PROJECT_ROOT / \"dataset\" / \"v21.3_filtered_enhanced\"\n",
    "OUTPUT_DIR = DATA_DIR  # Same directory\n",
    "\n",
    "# Filter configuration (percentile-based thresholds)\n",
    "@dataclass\n",
    "class FilterConfig:\n",
    "    \"\"\"Configuration for the filtering pipeline.\"\"\"\n",
    "    # IG parameters\n",
    "    ig_percentile_threshold: float = 10.0  # Bottom 10%\n",
    "    ig_k_entropy: int = 10\n",
    "    ig_k_neighborhood: int = 50\n",
    "    \n",
    "    # PMI parameters\n",
    "    pmi_percentile_threshold: float = 10.0  # Bottom 10%\n",
    "    pmi_laplace_smoothing: float = 1.0\n",
    "    pmi_context_smoothing: float = 0.75\n",
    "    \n",
    "    # Cross-encoder parameters\n",
    "    ce_percentile_threshold: float = 10.0  # Bottom 10%\n",
    "    ce_model_name: str = \"BAAI/bge-reranker-v2-m3\"\n",
    "    \n",
    "    # Ensemble parameters\n",
    "    min_filters_to_pass: int = 2  # Majority voting (2 of 3)\n",
    "    \n",
    "    # Batch sizes\n",
    "    batch_size: int = 256\n",
    "\n",
    "config = FilterConfig()\n",
    "print(f\"Filter configuration:\")\n",
    "print(f\"  IG percentile threshold: {config.ig_percentile_threshold}%\")\n",
    "print(f\"  PMI percentile threshold: {config.pmi_percentile_threshold}%\")\n",
    "print(f\"  Cross-encoder percentile threshold: {config.ce_percentile_threshold}%\")\n",
    "print(f\"  Min filters to pass: {config.min_filters_to_pass}/3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Raw Data from 00_data_ingestion.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load raw synonym pairs\n",
    "raw_pairs_path = DATA_DIR / \"raw_synonym_pairs.jsonl\"\n",
    "synonym_pairs = []\n",
    "with open(raw_pairs_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        synonym_pairs.append(json.loads(line.strip()))\n",
    "\n",
    "print(f\"Loaded {len(synonym_pairs):,} raw synonym pairs\")\n",
    "\n",
    "# Sample\n",
    "print(\"\\nSample pairs:\")\n",
    "for pair in synonym_pairs[:5]:\n",
    "    print(f\"  {pair['source']} -> {pair['target']} (sim={pair['similarity']:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load corpus texts for PMI\n",
    "corpus_path = DATA_DIR / \"corpus_texts.jsonl\"\n",
    "corpus_texts = []\n",
    "with open(corpus_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        data = json.loads(line.strip())\n",
    "        corpus_texts.append(data[\"text\"])\n",
    "\n",
    "print(f\"Loaded {len(corpus_texts):,} corpus documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load embeddings and term list\n",
    "embeddings = np.load(DATA_DIR / \"term_embeddings.npy\")\n",
    "with open(DATA_DIR / \"term_list.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    terms = json.load(f)\n",
    "\n",
    "# Create term to index mapping\n",
    "term_to_idx = {term: idx for idx, term in enumerate(terms)}\n",
    "\n",
    "print(f\"Embeddings shape: {embeddings.shape}\")\n",
    "print(f\"Terms count: {len(terms):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Information Gain Filtering\n",
    "\n",
    "IG measures semantic expansion value:\n",
    "- High IG: Target adds new semantic information\n",
    "- Low IG: Trivial relationship (truncation, case change)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.information_gain import (\n",
    "    InformationGainConfig,\n",
    "    InformationGainResult,\n",
    "    knn_entropy_kl,\n",
    "    compute_adaptive_threshold,\n",
    ")\n",
    "from scipy.spatial.distance import cdist\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Configure IG\n",
    "ig_config = InformationGainConfig(\n",
    "    k_entropy=config.ig_k_entropy,\n",
    "    k_neighborhood=config.ig_k_neighborhood,\n",
    "    percentile_threshold=config.ig_percentile_threshold,\n",
    "    use_faiss=False,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "print(f\"IG Configuration:\")\n",
    "print(f\"  k_entropy: {ig_config.k_entropy}\")\n",
    "print(f\"  k_neighborhood: {ig_config.k_neighborhood}\")\n",
    "print(f\"  percentile_threshold: {ig_config.percentile_threshold}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ig_scores(\n",
    "    pairs: List[Dict],\n",
    "    embeddings: np.ndarray,\n",
    "    term_to_idx: Dict[str, int],\n",
    "    k_entropy: int = 10,\n",
    "    k_neighborhood: int = 50,\n",
    "    batch_size: int = 500,\n",
    ") -> List[float]:\n",
    "    \"\"\"\n",
    "    Compute Information Gain scores for all pairs.\n",
    "    \n",
    "    IG = H(target) - H(target|source)\n",
    "    \"\"\"\n",
    "    ig_scores = []\n",
    "    n_oov = 0\n",
    "    \n",
    "    for i, pair in enumerate(tqdm(pairs, desc=\"Computing IG\")):\n",
    "        source, target = pair[\"source\"], pair[\"target\"]\n",
    "        \n",
    "        # Check OOV\n",
    "        if source not in term_to_idx or target not in term_to_idx:\n",
    "            ig_scores.append(np.nan)  # OOV pairs get NaN\n",
    "            n_oov += 1\n",
    "            continue\n",
    "        \n",
    "        source_idx = term_to_idx[source]\n",
    "        target_idx = term_to_idx[target]\n",
    "        \n",
    "        source_emb = embeddings[source_idx:source_idx+1]\n",
    "        target_emb = embeddings[target_idx:target_idx+1]\n",
    "        \n",
    "        # Compute H(target) - marginal entropy\n",
    "        distances_all = cdist(target_emb, embeddings, metric='euclidean')[0]\n",
    "        k_distances_all = np.sort(distances_all)[1:k_entropy+1]  # Exclude self\n",
    "        h_target = np.mean(np.log(k_distances_all + 1e-10))\n",
    "        \n",
    "        # Compute H(target|source) - conditional entropy\n",
    "        # Get source's neighborhood\n",
    "        source_distances = cdist(source_emb, embeddings, metric='euclidean')[0]\n",
    "        neighbor_indices = np.argsort(source_distances)[1:k_neighborhood+1]\n",
    "        neighbor_embeddings = embeddings[neighbor_indices]\n",
    "        \n",
    "        # Distance to target within neighborhood\n",
    "        distances_cond = cdist(target_emb, neighbor_embeddings, metric='euclidean')[0]\n",
    "        k_distances_cond = np.sort(distances_cond)[:min(k_entropy, len(distances_cond))]\n",
    "        h_target_given_source = np.mean(np.log(k_distances_cond + 1e-10))\n",
    "        \n",
    "        # IG = H(target) - H(target|source)\n",
    "        ig = h_target - h_target_given_source\n",
    "        ig_scores.append(ig)\n",
    "    \n",
    "    print(f\"\\nComputed IG for {len(pairs):,} pairs ({n_oov:,} OOV)\")\n",
    "    return ig_scores\n",
    "\n",
    "# Compute IG scores\n",
    "ig_scores = compute_ig_scores(\n",
    "    synonym_pairs, \n",
    "    embeddings, \n",
    "    term_to_idx,\n",
    "    k_entropy=config.ig_k_entropy,\n",
    "    k_neighborhood=config.ig_k_neighborhood,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute IG threshold (percentile-based)\n",
    "valid_ig = [s for s in ig_scores if not np.isnan(s)]\n",
    "ig_threshold = np.percentile(valid_ig, config.ig_percentile_threshold)\n",
    "\n",
    "print(f\"IG Statistics:\")\n",
    "print(f\"  Valid scores: {len(valid_ig):,}\")\n",
    "print(f\"  Mean: {np.mean(valid_ig):.4f}\")\n",
    "print(f\"  Std: {np.std(valid_ig):.4f}\")\n",
    "print(f\"  Min: {np.min(valid_ig):.4f}\")\n",
    "print(f\"  Max: {np.max(valid_ig):.4f}\")\n",
    "print(f\"  Threshold (P{config.ig_percentile_threshold:.0f}): {ig_threshold:.4f}\")\n",
    "\n",
    "# Mark filtered pairs\n",
    "ig_pass = [\n",
    "    not np.isnan(s) and s >= ig_threshold \n",
    "    for s in ig_scores\n",
    "]\n",
    "print(f\"\\nIG Filter Results:\")\n",
    "print(f\"  Pass: {sum(ig_pass):,} ({100*sum(ig_pass)/len(ig_pass):.1f}%)\")\n",
    "print(f\"  Fail: {len(ig_pass) - sum(ig_pass):,} ({100*(1-sum(ig_pass)/len(ig_pass)):.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. PMI Filtering\n",
    "\n",
    "PMI measures co-occurrence probability:\n",
    "- High PMI: Terms co-occur frequently (genuine relationship)\n",
    "- Low PMI: Rare co-occurrence (false positive from embedding similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kiwipiepy import Kiwi\n",
    "from src.pmi import CooccurrenceMatrixBuilder, PMICalculator\n",
    "from src.pmi.cooccurrence import CooccurrenceConfig, WindowType\n",
    "from src.pmi.pmi_calculator import PMIConfig\n",
    "\n",
    "# Initialize Kiwi\n",
    "print(\"Loading Kiwi tokenizer...\")\n",
    "kiwi = Kiwi()\n",
    "\n",
    "VALID_POS_TAGS = {'NNG', 'NNP', 'NNB', 'SL', 'SH'}\n",
    "\n",
    "def kiwi_tokenize(text: str) -> List[str]:\n",
    "    \"\"\"Extract nouns using Kiwi.\"\"\"\n",
    "    try:\n",
    "        result = kiwi.tokenize(text)\n",
    "        nouns = []\n",
    "        for token in result:\n",
    "            if token.tag in VALID_POS_TAGS:\n",
    "                word = token.form.strip()\n",
    "                if 2 <= len(word) <= 15:\n",
    "                    nouns.append(word)\n",
    "        return nouns\n",
    "    except Exception:\n",
    "        return []\n",
    "\n",
    "# Test\n",
    "test_text = \"인공지능 기술이 발전하면서 기계학습과 딥러닝이 주목받고 있습니다.\"\n",
    "print(f\"Test: {test_text}\")\n",
    "print(f\"Tokens: {kiwi_tokenize(test_text)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for cached co-occurrence matrix\n",
    "cooc_cache_path = DATA_DIR / \"cooccurrence_matrix\"\n",
    "\n",
    "if cooc_cache_path.exists():\n",
    "    print(\"Loading cached co-occurrence matrix...\")\n",
    "    builder = CooccurrenceMatrixBuilder.load(cooc_cache_path)\n",
    "    stats = builder.get_stats()\n",
    "    print(f\"  Vocabulary size: {stats.vocab_size:,}\")\n",
    "    print(f\"  Total windows: {stats.total_windows:,}\")\n",
    "else:\n",
    "    print(\"Building co-occurrence matrix (this may take 30-60 minutes)...\")\n",
    "    \n",
    "    cooc_config = CooccurrenceConfig(\n",
    "        window_type=WindowType.SENTENCE,\n",
    "        min_term_freq=5,\n",
    "        max_vocab_size=120000,\n",
    "        symmetric=True,\n",
    "    )\n",
    "    \n",
    "    builder = CooccurrenceMatrixBuilder(cooc_config)\n",
    "    builder.fit(corpus_texts, tokenizer=kiwi_tokenize, show_progress=True)\n",
    "    \n",
    "    # Save for future use\n",
    "    builder.save(cooc_cache_path)\n",
    "    print(f\"Saved co-occurrence matrix to: {cooc_cache_path}\")\n",
    "\n",
    "stats = builder.get_stats()\n",
    "print(f\"\\nCo-occurrence Statistics:\")\n",
    "print(f\"  Vocabulary size: {stats.vocab_size:,}\")\n",
    "print(f\"  Total documents: {stats.total_documents:,}\")\n",
    "print(f\"  Total windows: {stats.total_windows:,}\")\n",
    "print(f\"  Total co-occurrences: {stats.total_cooccurrences:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create PMI calculator\n",
    "pmi_config = PMIConfig(\n",
    "    laplace_smoothing=config.pmi_laplace_smoothing,\n",
    "    context_smoothing_alpha=config.pmi_context_smoothing,\n",
    "    use_ppmi=True,  # Positive PMI only\n",
    "    log_base=2.0,\n",
    "    min_cooccurrence=1,\n",
    ")\n",
    "\n",
    "pmi_calculator = PMICalculator(\n",
    "    cooccurrence_matrix=builder.get_cooccurrence_matrix(),\n",
    "    term_frequencies=builder.get_term_frequencies(),\n",
    "    vocabulary=builder.get_vocabulary(),\n",
    "    total_windows=builder.get_stats().total_windows,\n",
    "    config=pmi_config,\n",
    ")\n",
    "\n",
    "print(f\"PMI Calculator initialized\")\n",
    "print(f\"  Vocabulary: {len(builder.get_vocabulary()):,} terms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute PMI scores for all pairs\n",
    "pmi_vocab = set(builder.get_vocabulary().keys())\n",
    "pmi_scores = []\n",
    "n_oov = 0\n",
    "\n",
    "for pair in tqdm(synonym_pairs, desc=\"Computing PMI\"):\n",
    "    source, target = pair[\"source\"], pair[\"target\"]\n",
    "    \n",
    "    # Check OOV\n",
    "    if source not in pmi_vocab or target not in pmi_vocab:\n",
    "        pmi_scores.append(np.nan)\n",
    "        n_oov += 1\n",
    "        continue\n",
    "    \n",
    "    pmi = pmi_calculator.compute_pmi(source, target)\n",
    "    pmi_scores.append(pmi)\n",
    "\n",
    "print(f\"\\nComputed PMI for {len(pmi_scores):,} pairs ({n_oov:,} OOV)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute PMI threshold (percentile-based)\n",
    "valid_pmi = [s for s in pmi_scores if not np.isnan(s) and not np.isinf(s)]\n",
    "pmi_threshold = np.percentile(valid_pmi, config.pmi_percentile_threshold)\n",
    "\n",
    "print(f\"PMI Statistics:\")\n",
    "print(f\"  Valid scores: {len(valid_pmi):,}\")\n",
    "print(f\"  Mean: {np.mean(valid_pmi):.4f}\")\n",
    "print(f\"  Std: {np.std(valid_pmi):.4f}\")\n",
    "print(f\"  Min: {np.min(valid_pmi):.4f}\")\n",
    "print(f\"  Max: {np.max(valid_pmi):.4f}\")\n",
    "print(f\"  Threshold (P{config.pmi_percentile_threshold:.0f}): {pmi_threshold:.4f}\")\n",
    "\n",
    "# Mark filtered pairs\n",
    "pmi_pass = [\n",
    "    not np.isnan(s) and not np.isinf(s) and s >= pmi_threshold\n",
    "    for s in pmi_scores\n",
    "]\n",
    "print(f\"\\nPMI Filter Results:\")\n",
    "print(f\"  Pass: {sum(pmi_pass):,} ({100*sum(pmi_pass)/len(pmi_pass):.1f}%)\")\n",
    "print(f\"  Fail: {len(pmi_pass) - sum(pmi_pass):,} ({100*(1-sum(pmi_pass)/len(pmi_pass)):.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Cross-Encoder Reranking\n",
    "\n",
    "Cross-encoder provides precise semantic similarity scores by jointly encoding source and target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from FlagEmbedding import FlagReranker\n",
    "import torch\n",
    "\n",
    "# Determine device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Load cross-encoder\n",
    "print(f\"Loading cross-encoder: {config.ce_model_name}\")\n",
    "reranker = FlagReranker(\n",
    "    config.ce_model_name,\n",
    "    use_fp16=True if device == \"cuda\" else False,\n",
    ")\n",
    "print(\"Cross-encoder loaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute cross-encoder scores in batches\n",
    "def compute_ce_scores(\n",
    "    pairs: List[Dict],\n",
    "    reranker: FlagReranker,\n",
    "    batch_size: int = 256,\n",
    ") -> List[float]:\n",
    "    \"\"\"Compute cross-encoder scores for all pairs.\"\"\"\n",
    "    all_scores = []\n",
    "    \n",
    "    for i in tqdm(range(0, len(pairs), batch_size), desc=\"Cross-encoder\"):\n",
    "        batch = pairs[i:i+batch_size]\n",
    "        \n",
    "        # Create query-passage pairs\n",
    "        pair_inputs = [\n",
    "            [p[\"source\"], p[\"target\"]] \n",
    "            for p in batch\n",
    "        ]\n",
    "        \n",
    "        # Compute scores\n",
    "        scores = reranker.compute_score(pair_inputs, normalize=True)\n",
    "        \n",
    "        # Handle single vs batch return\n",
    "        if isinstance(scores, (int, float)):\n",
    "            scores = [scores]\n",
    "        \n",
    "        all_scores.extend(scores)\n",
    "    \n",
    "    return all_scores\n",
    "\n",
    "print(f\"Computing cross-encoder scores for {len(synonym_pairs):,} pairs...\")\n",
    "ce_scores = compute_ce_scores(synonym_pairs, reranker, config.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute CE threshold (percentile-based)\n",
    "ce_threshold = np.percentile(ce_scores, config.ce_percentile_threshold)\n",
    "\n",
    "print(f\"Cross-Encoder Statistics:\")\n",
    "print(f\"  Scores: {len(ce_scores):,}\")\n",
    "print(f\"  Mean: {np.mean(ce_scores):.4f}\")\n",
    "print(f\"  Std: {np.std(ce_scores):.4f}\")\n",
    "print(f\"  Min: {np.min(ce_scores):.4f}\")\n",
    "print(f\"  Max: {np.max(ce_scores):.4f}\")\n",
    "print(f\"  Threshold (P{config.ce_percentile_threshold:.0f}): {ce_threshold:.4f}\")\n",
    "\n",
    "# Mark filtered pairs\n",
    "ce_pass = [s >= ce_threshold for s in ce_scores]\n",
    "print(f\"\\nCross-Encoder Filter Results:\")\n",
    "print(f\"  Pass: {sum(ce_pass):,} ({100*sum(ce_pass)/len(ce_pass):.1f}%)\")\n",
    "print(f\"  Fail: {len(ce_pass) - sum(ce_pass):,} ({100*(1-sum(ce_pass)/len(ce_pass)):.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Ensemble Filtering (Majority Voting)\n",
    "\n",
    "A pair is kept if it passes at least 2 of 3 filters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine filter results\n",
    "@dataclass\n",
    "class FilteredPair:\n",
    "    \"\"\"A synonym pair with filtering results.\"\"\"\n",
    "    source: str\n",
    "    target: str\n",
    "    similarity: float\n",
    "    category: str\n",
    "    \n",
    "    # Scores\n",
    "    ig_score: float\n",
    "    pmi_score: float\n",
    "    ce_score: float\n",
    "    \n",
    "    # Pass/fail for each filter\n",
    "    ig_pass: bool\n",
    "    pmi_pass: bool\n",
    "    ce_pass: bool\n",
    "    \n",
    "    # Ensemble result\n",
    "    n_filters_passed: int = field(init=False)\n",
    "    is_kept: bool = field(init=False)\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        self.n_filters_passed = sum([self.ig_pass, self.pmi_pass, self.ce_pass])\n",
    "        self.is_kept = self.n_filters_passed >= config.min_filters_to_pass\n",
    "\n",
    "# Create filtered pairs\n",
    "filtered_pairs = []\n",
    "for i, pair in enumerate(synonym_pairs):\n",
    "    fp = FilteredPair(\n",
    "        source=pair[\"source\"],\n",
    "        target=pair[\"target\"],\n",
    "        similarity=pair[\"similarity\"],\n",
    "        category=pair.get(\"category\", \"unknown\"),\n",
    "        ig_score=ig_scores[i] if not np.isnan(ig_scores[i]) else 0.0,\n",
    "        pmi_score=pmi_scores[i] if not np.isnan(pmi_scores[i]) and not np.isinf(pmi_scores[i]) else 0.0,\n",
    "        ce_score=ce_scores[i],\n",
    "        ig_pass=ig_pass[i],\n",
    "        pmi_pass=pmi_pass[i],\n",
    "        ce_pass=ce_pass[i],\n",
    "    )\n",
    "    filtered_pairs.append(fp)\n",
    "\n",
    "print(f\"Created {len(filtered_pairs):,} filtered pairs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensemble statistics\n",
    "kept_pairs = [fp for fp in filtered_pairs if fp.is_kept]\n",
    "removed_pairs = [fp for fp in filtered_pairs if not fp.is_kept]\n",
    "\n",
    "print(f\"Ensemble Filtering Results:\")\n",
    "print(f\"  Total pairs: {len(filtered_pairs):,}\")\n",
    "print(f\"  Kept: {len(kept_pairs):,} ({100*len(kept_pairs)/len(filtered_pairs):.1f}%)\")\n",
    "print(f\"  Removed: {len(removed_pairs):,} ({100*len(removed_pairs)/len(filtered_pairs):.1f}%)\")\n",
    "\n",
    "# Breakdown by number of filters passed\n",
    "print(f\"\\nBreakdown by filters passed:\")\n",
    "for n in [0, 1, 2, 3]:\n",
    "    count = sum(1 for fp in filtered_pairs if fp.n_filters_passed == n)\n",
    "    status = \"KEEP\" if n >= config.min_filters_to_pass else \"REMOVE\"\n",
    "    print(f\"  {n}/3 filters: {count:,} ({100*count/len(filtered_pairs):.1f}%) -> {status}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Breakdown by filter combination\n",
    "from itertools import product\n",
    "\n",
    "combo_counts = defaultdict(int)\n",
    "for fp in filtered_pairs:\n",
    "    combo = (fp.ig_pass, fp.pmi_pass, fp.ce_pass)\n",
    "    combo_counts[combo] += 1\n",
    "\n",
    "print(\"Filter Combination Analysis:\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"{'IG':^6} {'PMI':^6} {'CE':^6} | {'Count':>10} | {'Decision'}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for combo in sorted(combo_counts.keys(), key=lambda x: -combo_counts[x]):\n",
    "    ig, pmi, ce = combo\n",
    "    count = combo_counts[combo]\n",
    "    n_pass = sum(combo)\n",
    "    decision = \"KEEP\" if n_pass >= config.min_filters_to_pass else \"REMOVE\"\n",
    "    print(f\"{'✓' if ig else '✗':^6} {'✓' if pmi else '✗':^6} {'✓' if ce else '✗':^6} | {count:>10,} | {decision}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Analyze Filtered Pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot score distributions\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "# IG distribution\n",
    "ax1 = axes[0]\n",
    "kept_ig = [fp.ig_score for fp in kept_pairs]\n",
    "removed_ig = [fp.ig_score for fp in removed_pairs]\n",
    "ax1.hist(kept_ig, bins=50, alpha=0.7, label=f'Kept ({len(kept_ig):,})', color='green')\n",
    "ax1.hist(removed_ig, bins=50, alpha=0.7, label=f'Removed ({len(removed_ig):,})', color='red')\n",
    "ax1.axvline(x=ig_threshold, color='black', linestyle='--', label=f'Threshold')\n",
    "ax1.set_xlabel('Information Gain')\n",
    "ax1.set_ylabel('Count')\n",
    "ax1.set_title('IG Distribution')\n",
    "ax1.legend()\n",
    "\n",
    "# PMI distribution\n",
    "ax2 = axes[1]\n",
    "kept_pmi = [fp.pmi_score for fp in kept_pairs]\n",
    "removed_pmi = [fp.pmi_score for fp in removed_pairs]\n",
    "ax2.hist(kept_pmi, bins=50, alpha=0.7, label=f'Kept ({len(kept_pmi):,})', color='green')\n",
    "ax2.hist(removed_pmi, bins=50, alpha=0.7, label=f'Removed ({len(removed_pmi):,})', color='red')\n",
    "ax2.axvline(x=pmi_threshold, color='black', linestyle='--', label=f'Threshold')\n",
    "ax2.set_xlabel('PMI Score')\n",
    "ax2.set_ylabel('Count')\n",
    "ax2.set_title('PMI Distribution')\n",
    "ax2.legend()\n",
    "\n",
    "# CE distribution\n",
    "ax3 = axes[2]\n",
    "kept_ce = [fp.ce_score for fp in kept_pairs]\n",
    "removed_ce = [fp.ce_score for fp in removed_pairs]\n",
    "ax3.hist(kept_ce, bins=50, alpha=0.7, label=f'Kept ({len(kept_ce):,})', color='green')\n",
    "ax3.hist(removed_ce, bins=50, alpha=0.7, label=f'Removed ({len(removed_ce):,})', color='red')\n",
    "ax3.axvline(x=ce_threshold, color='black', linestyle='--', label=f'Threshold')\n",
    "ax3.set_xlabel('Cross-Encoder Score')\n",
    "ax3.set_ylabel('Count')\n",
    "ax3.set_title('Cross-Encoder Distribution')\n",
    "ax3.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUTPUT_DIR / 'filtering_distributions.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample removed pairs (failed all 3 filters)\n",
    "failed_all = [fp for fp in removed_pairs if fp.n_filters_passed == 0]\n",
    "\n",
    "print(f\"\\n=== Pairs that failed ALL 3 filters ({len(failed_all):,}) ===\")\n",
    "print(\"-\" * 80)\n",
    "for fp in failed_all[:15]:\n",
    "    print(f\"{fp.source} -> {fp.target}\")\n",
    "    print(f\"  IG={fp.ig_score:.3f} | PMI={fp.pmi_score:.3f} | CE={fp.ce_score:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample kept pairs (passed all 3 filters)\n",
    "passed_all = [fp for fp in kept_pairs if fp.n_filters_passed == 3]\n",
    "\n",
    "print(f\"\\n=== Pairs that passed ALL 3 filters ({len(passed_all):,}) ===\")\n",
    "print(\"-\" * 80)\n",
    "import random\n",
    "for fp in random.sample(passed_all, min(15, len(passed_all))):\n",
    "    print(f\"{fp.source} -> {fp.target}\")\n",
    "    print(f\"  IG={fp.ig_score:.3f} | PMI={fp.pmi_score:.3f} | CE={fp.ce_score:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Save Filtered Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save filtered pairs (kept)\n",
    "filtered_pairs_path = OUTPUT_DIR / \"filtered_synonym_pairs.jsonl\"\n",
    "with open(filtered_pairs_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    for fp in kept_pairs:\n",
    "        pair_dict = {\n",
    "            \"source\": fp.source,\n",
    "            \"target\": fp.target,\n",
    "            \"similarity\": fp.similarity,\n",
    "            \"category\": fp.category,\n",
    "            \"ig_score\": fp.ig_score,\n",
    "            \"pmi_score\": fp.pmi_score,\n",
    "            \"ce_score\": fp.ce_score,\n",
    "            \"n_filters_passed\": fp.n_filters_passed,\n",
    "        }\n",
    "        f.write(json.dumps(pair_dict, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "print(f\"Saved {len(kept_pairs):,} filtered pairs to: {filtered_pairs_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save removed pairs (for analysis)\n",
    "removed_pairs_path = OUTPUT_DIR / \"removed_synonym_pairs.jsonl\"\n",
    "with open(removed_pairs_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    for fp in removed_pairs:\n",
    "        pair_dict = {\n",
    "            \"source\": fp.source,\n",
    "            \"target\": fp.target,\n",
    "            \"similarity\": fp.similarity,\n",
    "            \"category\": fp.category,\n",
    "            \"ig_score\": fp.ig_score,\n",
    "            \"pmi_score\": fp.pmi_score,\n",
    "            \"ce_score\": fp.ce_score,\n",
    "            \"n_filters_passed\": fp.n_filters_passed,\n",
    "            \"ig_pass\": fp.ig_pass,\n",
    "            \"pmi_pass\": fp.pmi_pass,\n",
    "            \"ce_pass\": fp.ce_pass,\n",
    "        }\n",
    "        f.write(json.dumps(pair_dict, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "print(f\"Saved {len(removed_pairs):,} removed pairs to: {removed_pairs_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save filtering statistics\n",
    "stats = {\n",
    "    \"config\": {\n",
    "        \"ig_percentile_threshold\": config.ig_percentile_threshold,\n",
    "        \"pmi_percentile_threshold\": config.pmi_percentile_threshold,\n",
    "        \"ce_percentile_threshold\": config.ce_percentile_threshold,\n",
    "        \"min_filters_to_pass\": config.min_filters_to_pass,\n",
    "    },\n",
    "    \"thresholds\": {\n",
    "        \"ig\": float(ig_threshold),\n",
    "        \"pmi\": float(pmi_threshold),\n",
    "        \"ce\": float(ce_threshold),\n",
    "    },\n",
    "    \"results\": {\n",
    "        \"total_pairs\": len(filtered_pairs),\n",
    "        \"kept_pairs\": len(kept_pairs),\n",
    "        \"removed_pairs\": len(removed_pairs),\n",
    "        \"kept_ratio\": len(kept_pairs) / len(filtered_pairs),\n",
    "    },\n",
    "    \"filter_pass_rates\": {\n",
    "        \"ig\": sum(ig_pass) / len(ig_pass),\n",
    "        \"pmi\": sum(pmi_pass) / len(pmi_pass),\n",
    "        \"ce\": sum(ce_pass) / len(ce_pass),\n",
    "    },\n",
    "    \"passed_count_distribution\": {\n",
    "        str(n): sum(1 for fp in filtered_pairs if fp.n_filters_passed == n)\n",
    "        for n in [0, 1, 2, 3]\n",
    "    },\n",
    "}\n",
    "\n",
    "stats_path = OUTPUT_DIR / \"filtering_stats.json\"\n",
    "with open(stats_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(stats, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"Saved filtering statistics to: {stats_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### Filtering Pipeline Complete\n",
    "\n",
    "Applied three algorithmic filters with percentile-based thresholds:\n",
    "\n",
    "| Filter | Threshold | Pass Rate | Purpose |\n",
    "|--------|-----------|-----------|--------|\n",
    "| IG | Bottom 10% | ~90% | Remove truncations |\n",
    "| PMI | Bottom 10% | ~90% | Remove false positives |\n",
    "| CE | Bottom 10% | ~90% | Remove dissimilar pairs |\n",
    "\n",
    "### Ensemble Decision\n",
    "\n",
    "Majority voting: Pairs passing >= 2/3 filters are kept.\n",
    "\n",
    "### Output Files\n",
    "\n",
    "| File | Description |\n",
    "|------|-------------|\n",
    "| `filtered_synonym_pairs.jsonl` | Kept pairs with all scores |\n",
    "| `removed_synonym_pairs.jsonl` | Removed pairs for analysis |\n",
    "| `filtering_stats.json` | Filtering statistics |\n",
    "| `filtering_distributions.png` | Score distribution plots |\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "1. `02_data_preparation.ipynb`: Create triplet dataset with hard negatives\n",
    "2. `03_training.ipynb`: Train model with filtered data\n",
    "3. `04_evaluation.ipynb`: Evaluate with Recall@K, MRR, nDCG"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

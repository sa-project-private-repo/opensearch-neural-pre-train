{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# v21.3 Data Preparation - Triplet Dataset with Hard Negatives\n",
    "\n",
    "This notebook creates the training dataset from filtered synonym pairs.\n",
    "\n",
    "## Features\n",
    "\n",
    "1. **Hard Negative Mining**: Balanced difficulty sampling (Easy/Medium/Hard)\n",
    "2. **Triplet Format**: (anchor, positive, negative) for contrastive learning\n",
    "3. **HuggingFace Dataset**: Save in standard format for training\n",
    "\n",
    "## Hard Negative Strategy\n",
    "\n",
    "| Difficulty | Similarity Range | Ratio |\n",
    "|------------|------------------|-------|\n",
    "| Easy | 0.3 - 0.5 | 33% |\n",
    "| Medium | 0.5 - 0.7 | 33% |\n",
    "| Hard | 0.7 - 0.9 | 33% |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "def find_project_root():\n",
    "    current = Path.cwd()\n",
    "    for parent in [current] + list(current.parents):\n",
    "        if (parent / \"pyproject.toml\").exists() or (parent / \"src\").exists():\n",
    "            return parent\n",
    "    return Path.cwd().parent.parent\n",
    "\n",
    "PROJECT_ROOT = find_project_root()\n",
    "sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import defaultdict, Counter\n",
    "from typing import Dict, List, Tuple\n",
    "from dataclasses import dataclass\n",
    "from tqdm.auto import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "print(f\"Project root: {PROJECT_ROOT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "@dataclass\n",
    "class DataConfig:\n",
    "    \"\"\"Configuration for data preparation.\"\"\"\n",
    "    # Hard negative difficulty ranges (cosine similarity)\n",
    "    easy_range: Tuple[float, float] = (0.3, 0.5)\n",
    "    medium_range: Tuple[float, float] = (0.5, 0.7)\n",
    "    hard_range: Tuple[float, float] = (0.7, 0.9)\n",
    "    \n",
    "    # Sampling ratios\n",
    "    easy_ratio: float = 0.33\n",
    "    medium_ratio: float = 0.33\n",
    "    hard_ratio: float = 0.34\n",
    "    \n",
    "    # Number of negatives per anchor\n",
    "    negatives_per_anchor: int = 5\n",
    "    \n",
    "    # Dataset split\n",
    "    train_ratio: float = 0.9\n",
    "    val_ratio: float = 0.1\n",
    "    \n",
    "    # Batch size for embedding computation\n",
    "    batch_size: int = 128\n",
    "    \n",
    "config = DataConfig()\n",
    "print(f\"Data Configuration:\")\n",
    "print(f\"  Easy range: {config.easy_range}\")\n",
    "print(f\"  Medium range: {config.medium_range}\")\n",
    "print(f\"  Hard range: {config.hard_range}\")\n",
    "print(f\"  Negatives per anchor: {config.negatives_per_anchor}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "DATA_DIR = PROJECT_ROOT / \"dataset\" / \"v21.3_filtered_enhanced\"\n",
    "OUTPUT_DIR = DATA_DIR\n",
    "\n",
    "print(f\"Data directory: {DATA_DIR}\")\n",
    "print(f\"Output directory: {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Filtered Synonym Pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load filtered synonym pairs from 01_noise_filtering.ipynb\n",
    "filtered_pairs_path = DATA_DIR / \"filtered_synonym_pairs.jsonl\"\n",
    "\n",
    "synonym_pairs = []\n",
    "with open(filtered_pairs_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        synonym_pairs.append(json.loads(line.strip()))\n",
    "\n",
    "print(f\"Loaded {len(synonym_pairs):,} filtered synonym pairs\")\n",
    "\n",
    "# Sample\n",
    "print(\"\\nSample pairs:\")\n",
    "for pair in synonym_pairs[:5]:\n",
    "    print(f\"  {pair['source']} -> {pair['target']} (sim={pair['similarity']:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load embeddings and terms\n",
    "embeddings = np.load(DATA_DIR / \"term_embeddings.npy\")\n",
    "with open(DATA_DIR / \"term_list.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    terms = json.load(f)\n",
    "\n",
    "term_to_idx = {term: idx for idx, term in enumerate(terms)}\n",
    "\n",
    "print(f\"Embeddings shape: {embeddings.shape}\")\n",
    "print(f\"Terms count: {len(terms):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Build Anchor-Positive Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build anchor to positives mapping\n",
    "anchor_to_positives = defaultdict(set)\n",
    "\n",
    "for pair in synonym_pairs:\n",
    "    source, target = pair[\"source\"], pair[\"target\"]\n",
    "    \n",
    "    # Skip if not in vocabulary\n",
    "    if source not in term_to_idx or target not in term_to_idx:\n",
    "        continue\n",
    "    \n",
    "    anchor_to_positives[source].add(target)\n",
    "    anchor_to_positives[target].add(source)  # Bidirectional\n",
    "\n",
    "print(f\"Unique anchors: {len(anchor_to_positives):,}\")\n",
    "\n",
    "# Distribution of positives per anchor\n",
    "positive_counts = [len(v) for v in anchor_to_positives.values()]\n",
    "print(f\"\\nPositives per anchor:\")\n",
    "print(f\"  Mean: {np.mean(positive_counts):.2f}\")\n",
    "print(f\"  Min: {np.min(positive_counts)}\")\n",
    "print(f\"  Max: {np.max(positive_counts)}\")\n",
    "print(f\"  Median: {np.median(positive_counts):.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Hard Negative Mining\n",
    "\n",
    "Sample negatives based on similarity difficulty levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def mine_hard_negatives(\n",
    "    anchor: str,\n",
    "    positives: set,\n",
    "    embeddings: np.ndarray,\n",
    "    term_to_idx: Dict[str, int],\n",
    "    terms: List[str],\n",
    "    config: DataConfig,\n",
    ") -> Dict[str, List[str]]:\n",
    "    \"\"\"\n",
    "    Mine hard negatives for an anchor at different difficulty levels.\n",
    "    \n",
    "    Returns:\n",
    "        Dict with keys 'easy', 'medium', 'hard', each containing a list of negatives.\n",
    "    \"\"\"\n",
    "    anchor_idx = term_to_idx[anchor]\n",
    "    anchor_emb = embeddings[anchor_idx:anchor_idx+1]\n",
    "    \n",
    "    # Compute similarity to all terms\n",
    "    similarities = cosine_similarity(anchor_emb, embeddings)[0]\n",
    "    \n",
    "    # Get candidate negatives (not anchor, not positives)\n",
    "    exclude = positives | {anchor}\n",
    "    \n",
    "    easy_negatives = []\n",
    "    medium_negatives = []\n",
    "    hard_negatives = []\n",
    "    \n",
    "    for idx, sim in enumerate(similarities):\n",
    "        term = terms[idx]\n",
    "        if term in exclude:\n",
    "            continue\n",
    "        \n",
    "        # Categorize by difficulty\n",
    "        if config.easy_range[0] <= sim < config.easy_range[1]:\n",
    "            easy_negatives.append((term, sim))\n",
    "        elif config.medium_range[0] <= sim < config.medium_range[1]:\n",
    "            medium_negatives.append((term, sim))\n",
    "        elif config.hard_range[0] <= sim < config.hard_range[1]:\n",
    "            hard_negatives.append((term, sim))\n",
    "    \n",
    "    return {\n",
    "        \"easy\": easy_negatives,\n",
    "        \"medium\": medium_negatives,\n",
    "        \"hard\": hard_negatives,\n",
    "    }\n",
    "\n",
    "# Test with one anchor\n",
    "test_anchor = list(anchor_to_positives.keys())[0]\n",
    "test_positives = anchor_to_positives[test_anchor]\n",
    "test_negatives = mine_hard_negatives(\n",
    "    test_anchor, test_positives, embeddings, term_to_idx, terms, config\n",
    ")\n",
    "\n",
    "print(f\"Test anchor: {test_anchor}\")\n",
    "print(f\"Positives: {list(test_positives)[:5]}\")\n",
    "print(f\"Easy negatives: {len(test_negatives['easy'])}\")\n",
    "print(f\"Medium negatives: {len(test_negatives['medium'])}\")\n",
    "print(f\"Hard negatives: {len(test_negatives['hard'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_balanced_negatives(\n",
    "    negatives_by_difficulty: Dict[str, List[Tuple[str, float]]],\n",
    "    n_total: int,\n",
    "    config: DataConfig,\n",
    ") -> List[Tuple[str, float, str]]:\n",
    "    \"\"\"\n",
    "    Sample negatives with balanced difficulty.\n",
    "    \n",
    "    Returns:\n",
    "        List of (negative_term, similarity, difficulty) tuples.\n",
    "    \"\"\"\n",
    "    n_easy = int(n_total * config.easy_ratio)\n",
    "    n_medium = int(n_total * config.medium_ratio)\n",
    "    n_hard = n_total - n_easy - n_medium\n",
    "    \n",
    "    sampled = []\n",
    "    \n",
    "    # Sample easy\n",
    "    if negatives_by_difficulty[\"easy\"]:\n",
    "        n_sample = min(n_easy, len(negatives_by_difficulty[\"easy\"]))\n",
    "        for term, sim in random.sample(negatives_by_difficulty[\"easy\"], n_sample):\n",
    "            sampled.append((term, sim, \"easy\"))\n",
    "    \n",
    "    # Sample medium\n",
    "    if negatives_by_difficulty[\"medium\"]:\n",
    "        n_sample = min(n_medium, len(negatives_by_difficulty[\"medium\"]))\n",
    "        for term, sim in random.sample(negatives_by_difficulty[\"medium\"], n_sample):\n",
    "            sampled.append((term, sim, \"medium\"))\n",
    "    \n",
    "    # Sample hard\n",
    "    if negatives_by_difficulty[\"hard\"]:\n",
    "        n_sample = min(n_hard, len(negatives_by_difficulty[\"hard\"]))\n",
    "        for term, sim in random.sample(negatives_by_difficulty[\"hard\"], n_sample):\n",
    "            sampled.append((term, sim, \"hard\"))\n",
    "    \n",
    "    # If not enough, fill from available\n",
    "    if len(sampled) < n_total:\n",
    "        all_negatives = (\n",
    "            negatives_by_difficulty[\"easy\"] + \n",
    "            negatives_by_difficulty[\"medium\"] + \n",
    "            negatives_by_difficulty[\"hard\"]\n",
    "        )\n",
    "        already_sampled = {s[0] for s in sampled}\n",
    "        remaining = [n for n in all_negatives if n[0] not in already_sampled]\n",
    "        \n",
    "        n_need = n_total - len(sampled)\n",
    "        for term, sim in random.sample(remaining, min(n_need, len(remaining))):\n",
    "            # Determine difficulty\n",
    "            if config.easy_range[0] <= sim < config.easy_range[1]:\n",
    "                difficulty = \"easy\"\n",
    "            elif config.medium_range[0] <= sim < config.medium_range[1]:\n",
    "                difficulty = \"medium\"\n",
    "            else:\n",
    "                difficulty = \"hard\"\n",
    "            sampled.append((term, sim, difficulty))\n",
    "    \n",
    "    return sampled\n",
    "\n",
    "# Test\n",
    "test_sampled = sample_balanced_negatives(\n",
    "    test_negatives, config.negatives_per_anchor, config\n",
    ")\n",
    "print(f\"Sampled negatives:\")\n",
    "for neg, sim, diff in test_sampled:\n",
    "    print(f\"  {neg} (sim={sim:.3f}, {diff})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Create Triplet Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create triplets for all anchors\n",
    "triplets = []\n",
    "skipped = 0\n",
    "difficulty_stats = Counter()\n",
    "\n",
    "for anchor in tqdm(anchor_to_positives.keys(), desc=\"Creating triplets\"):\n",
    "    positives = anchor_to_positives[anchor]\n",
    "    \n",
    "    # Mine negatives\n",
    "    negatives_by_difficulty = mine_hard_negatives(\n",
    "        anchor, positives, embeddings, term_to_idx, terms, config\n",
    "    )\n",
    "    \n",
    "    # Sample balanced negatives\n",
    "    sampled_negatives = sample_balanced_negatives(\n",
    "        negatives_by_difficulty, config.negatives_per_anchor, config\n",
    "    )\n",
    "    \n",
    "    if not sampled_negatives:\n",
    "        skipped += 1\n",
    "        continue\n",
    "    \n",
    "    # Create triplets: one for each positive-negative pair\n",
    "    for positive in positives:\n",
    "        for negative, neg_sim, difficulty in sampled_negatives:\n",
    "            triplet = {\n",
    "                \"anchor\": anchor,\n",
    "                \"positive\": positive,\n",
    "                \"negative\": negative,\n",
    "                \"negative_similarity\": neg_sim,\n",
    "                \"difficulty\": difficulty,\n",
    "            }\n",
    "            triplets.append(triplet)\n",
    "            difficulty_stats[difficulty] += 1\n",
    "\n",
    "print(f\"\\nCreated {len(triplets):,} triplets\")\n",
    "print(f\"Skipped anchors (no negatives): {skipped:,}\")\n",
    "print(f\"\\nDifficulty distribution:\")\n",
    "for diff, count in difficulty_stats.most_common():\n",
    "    print(f\"  {diff}: {count:,} ({100*count/len(triplets):.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample triplets\n",
    "print(\"\\nSample triplets:\")\n",
    "for triplet in random.sample(triplets, min(10, len(triplets))):\n",
    "    print(f\"  Anchor: {triplet['anchor']}\")\n",
    "    print(f\"  Positive: {triplet['positive']}\")\n",
    "    print(f\"  Negative: {triplet['negative']} (sim={triplet['negative_similarity']:.3f}, {triplet['difficulty']})\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Split into Train/Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle triplets\n",
    "random.shuffle(triplets)\n",
    "\n",
    "# Split\n",
    "n_train = int(len(triplets) * config.train_ratio)\n",
    "train_triplets = triplets[:n_train]\n",
    "val_triplets = triplets[n_train:]\n",
    "\n",
    "print(f\"Dataset split:\")\n",
    "print(f\"  Train: {len(train_triplets):,} ({100*len(train_triplets)/len(triplets):.1f}%)\")\n",
    "print(f\"  Validation: {len(val_triplets):,} ({100*len(val_triplets)/len(triplets):.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Save as HuggingFace Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "# Convert to datasets format\n",
    "def triplets_to_dict(triplets: List[Dict]) -> Dict[str, List]:\n",
    "    \"\"\"Convert list of triplet dicts to dict of lists.\"\"\"\n",
    "    return {\n",
    "        \"anchor\": [t[\"anchor\"] for t in triplets],\n",
    "        \"positive\": [t[\"positive\"] for t in triplets],\n",
    "        \"negative\": [t[\"negative\"] for t in triplets],\n",
    "        \"negative_similarity\": [t[\"negative_similarity\"] for t in triplets],\n",
    "        \"difficulty\": [t[\"difficulty\"] for t in triplets],\n",
    "    }\n",
    "\n",
    "train_dataset = Dataset.from_dict(triplets_to_dict(train_triplets))\n",
    "val_dataset = Dataset.from_dict(triplets_to_dict(val_triplets))\n",
    "\n",
    "dataset_dict = DatasetDict({\n",
    "    \"train\": train_dataset,\n",
    "    \"validation\": val_dataset,\n",
    "})\n",
    "\n",
    "print(f\"Dataset:\")\n",
    "print(dataset_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save dataset\n",
    "dataset_path = OUTPUT_DIR / \"triplet_dataset\"\n",
    "dataset_dict.save_to_disk(str(dataset_path))\n",
    "print(f\"Saved dataset to: {dataset_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also save as JSONL for compatibility\n",
    "train_jsonl = OUTPUT_DIR / \"train_triplets.jsonl\"\n",
    "with open(train_jsonl, \"w\", encoding=\"utf-8\") as f:\n",
    "    for triplet in train_triplets:\n",
    "        f.write(json.dumps(triplet, ensure_ascii=False) + \"\\n\")\n",
    "print(f\"Saved train triplets to: {train_jsonl}\")\n",
    "\n",
    "val_jsonl = OUTPUT_DIR / \"val_triplets.jsonl\"\n",
    "with open(val_jsonl, \"w\", encoding=\"utf-8\") as f:\n",
    "    for triplet in val_triplets:\n",
    "        f.write(json.dumps(triplet, ensure_ascii=False) + \"\\n\")\n",
    "print(f\"Saved validation triplets to: {val_jsonl}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data preparation statistics\n",
    "stats = {\n",
    "    \"config\": {\n",
    "        \"easy_range\": list(config.easy_range),\n",
    "        \"medium_range\": list(config.medium_range),\n",
    "        \"hard_range\": list(config.hard_range),\n",
    "        \"easy_ratio\": config.easy_ratio,\n",
    "        \"medium_ratio\": config.medium_ratio,\n",
    "        \"hard_ratio\": config.hard_ratio,\n",
    "        \"negatives_per_anchor\": config.negatives_per_anchor,\n",
    "        \"train_ratio\": config.train_ratio,\n",
    "        \"val_ratio\": config.val_ratio,\n",
    "    },\n",
    "    \"dataset\": {\n",
    "        \"total_triplets\": len(triplets),\n",
    "        \"train_triplets\": len(train_triplets),\n",
    "        \"val_triplets\": len(val_triplets),\n",
    "        \"unique_anchors\": len(anchor_to_positives),\n",
    "        \"skipped_anchors\": skipped,\n",
    "    },\n",
    "    \"difficulty_distribution\": dict(difficulty_stats),\n",
    "}\n",
    "\n",
    "stats_path = OUTPUT_DIR / \"data_preparation_stats.json\"\n",
    "with open(stats_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(stats, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"Saved statistics to: {stats_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### Data Preparation Complete\n",
    "\n",
    "Created triplet dataset with balanced hard negatives:\n",
    "\n",
    "| Metric | Value |\n",
    "|--------|-------|\n",
    "| Total Triplets | See stats above |\n",
    "| Train Set | 90% |\n",
    "| Validation Set | 10% |\n",
    "\n",
    "### Difficulty Balance\n",
    "\n",
    "| Difficulty | Range | Target Ratio |\n",
    "|------------|-------|-------------|\n",
    "| Easy | 0.3-0.5 | 33% |\n",
    "| Medium | 0.5-0.7 | 33% |\n",
    "| Hard | 0.7-0.9 | 34% |\n",
    "\n",
    "### Output Files\n",
    "\n",
    "| File | Description |\n",
    "|------|-------------|\n",
    "| `triplet_dataset/` | HuggingFace Dataset format |\n",
    "| `train_triplets.jsonl` | Training triplets (JSONL) |\n",
    "| `val_triplets.jsonl` | Validation triplets (JSONL) |\n",
    "| `data_preparation_stats.json` | Statistics |\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "1. `03_training.ipynb`: Train SPLADE model with triplet loss\n",
    "2. `04_evaluation.ipynb`: Evaluate with Recall@K, MRR, nDCG"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

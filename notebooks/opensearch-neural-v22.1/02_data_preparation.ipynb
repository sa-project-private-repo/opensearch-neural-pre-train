{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# v22.1 Data Preparation\n",
    "\n",
    "Generate training triplets with curriculum learning phases optimized for SPLADELossV23.\n",
    "\n",
    "## Key Features\n",
    "\n",
    "1. **Length Classification**: single_term, short_phrase, sentence\n",
    "2. **Hard Negative Mining**: Using BM25Scorer for quality hard negatives\n",
    "3. **Curriculum Learning Splits**: 3 phases with progressive difficulty\n",
    "4. **IDF Weight Computation**: For IDFAwareFLOPSLoss in SPLADELossV23\n",
    "\n",
    "## Curriculum Phases\n",
    "\n",
    "| Phase | Epochs | Data Focus | Description |\n",
    "|-------|--------|------------|-------------|\n",
    "| 1 | 1-7 | 50% single-term, 30% short, 20% sentence | Single-term focus |\n",
    "| 2 | 8-14 | 33% each (balanced) | Balanced learning |\n",
    "| 3 | 15-20 | Full data + hard negatives | Final refinement |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def find_project_root() -> Path:\n",
    "    \"\"\"Find the project root directory.\"\"\"\n",
    "    current = Path.cwd()\n",
    "    for parent in [current] + list(current.parents):\n",
    "        if (parent / \"pyproject.toml\").exists() or (parent / \"src\").exists():\n",
    "            return parent\n",
    "    return Path.cwd().parent.parent\n",
    "\n",
    "\n",
    "PROJECT_ROOT = find_project_root()\n",
    "sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "import json\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "from collections import defaultdict, Counter\n",
    "from typing import Dict, List, Set, Tuple, Optional\n",
    "from dataclasses import dataclass, asdict\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "RANDOM_SEED = 42\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "print(f\"Project root: {PROJECT_ROOT}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-2",
   "metadata": {},
   "source": [
    "## 1. Configuration and Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "V22_0_DATA_DIR = PROJECT_ROOT / \"data\" / \"v22.0\"\n",
    "V22_1_DATA_DIR = PROJECT_ROOT / \"data\" / \"v22.1\"\n",
    "HF_DATA_DIR = PROJECT_ROOT / \"data\" / \"huggingface_korean\"\n",
    "\n",
    "V22_1_DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Configuration\n",
    "CONFIG = {\n",
    "    \"val_ratio\": 0.1,\n",
    "    \"n_negatives_per_pair\": 3,\n",
    "    \"hard_negative_top_k\": 100,\n",
    "    \"jaccard_filter_threshold\": 0.9,\n",
    "    # Curriculum phase ratios\n",
    "    \"phase1_ratios\": {\"single_term\": 0.50, \"short_phrase\": 0.30, \"sentence\": 0.20},\n",
    "    \"phase2_ratios\": {\"single_term\": 0.33, \"short_phrase\": 0.33, \"sentence\": 0.34},\n",
    "}\n",
    "\n",
    "print(f\"Input directory: {V22_0_DATA_DIR}\")\n",
    "print(f\"Output directory: {V22_1_DATA_DIR}\")\n",
    "print(f\"\\nConfiguration:\")\n",
    "for key, value in CONFIG.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-4",
   "metadata": {},
   "source": [
    "## 2. Load Source Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_jsonl(path: Path) -> List[Dict]:\n",
    "    \"\"\"Load JSONL file into list of dictionaries.\"\"\"\n",
    "    data = []\n",
    "    if path.exists():\n",
    "        with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "            for line in f:\n",
    "                data.append(json.loads(line))\n",
    "    return data\n",
    "\n",
    "\n",
    "# Load v22.0 augmented pairs\n",
    "augmented_pairs_path = V22_0_DATA_DIR / \"augmented_synonym_pairs.jsonl\"\n",
    "pairs = load_jsonl(augmented_pairs_path)\n",
    "print(f\"Loaded {len(pairs):,} augmented pairs from v22.0\")\n",
    "\n",
    "# Load single-term expanded triplets\n",
    "single_term_path = V22_0_DATA_DIR / \"single_term_expanded.jsonl\"\n",
    "single_term_triplets = load_jsonl(single_term_path)\n",
    "print(f\"Loaded {len(single_term_triplets):,} single-term expanded triplets\")\n",
    "\n",
    "# Load MS MARCO triplets for Phase 3\n",
    "msmarco_path = V22_0_DATA_DIR / \"msmarco_direct_triplets.jsonl\"\n",
    "msmarco_triplets = load_jsonl(msmarco_path)\n",
    "print(f\"Loaded {len(msmarco_triplets):,} MS MARCO direct triplets\")\n",
    "\n",
    "# Build source -> targets mapping for negative filtering\n",
    "source_to_targets: Dict[str, Set[str]] = defaultdict(set)\n",
    "for pair in pairs:\n",
    "    source_to_targets[pair[\"source\"]].add(pair[\"target\"])\n",
    "\n",
    "print(f\"\\nUnique sources: {len(source_to_targets):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show sample data\n",
    "if pairs:\n",
    "    print(\"Sample augmented pair:\")\n",
    "    print(json.dumps(pairs[0], ensure_ascii=False, indent=2))\n",
    "\n",
    "if single_term_triplets:\n",
    "    print(\"\\nSample single-term triplet:\")\n",
    "    print(json.dumps(single_term_triplets[0], ensure_ascii=False, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-7",
   "metadata": {},
   "source": [
    "## 3. Length Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_length_class(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Classify text by character length.\n",
    "    \n",
    "    Args:\n",
    "        text: Input text string\n",
    "        \n",
    "    Returns:\n",
    "        Length class: 'single_term', 'short_phrase', or 'sentence'\n",
    "    \"\"\"\n",
    "    length = len(text)\n",
    "    if length <= 3:\n",
    "        return \"single_term\"\n",
    "    elif length <= 8:\n",
    "        return \"short_phrase\"\n",
    "    else:\n",
    "        return \"sentence\"\n",
    "\n",
    "\n",
    "# Classify all pairs by source length\n",
    "pairs_by_length: Dict[str, List[Dict]] = defaultdict(list)\n",
    "for pair in pairs:\n",
    "    source_text = pair.get(\"source\", \"\")\n",
    "    length_class = get_length_class(source_text)\n",
    "    pairs_by_length[length_class].append(pair)\n",
    "\n",
    "print(\"Pairs by length class:\")\n",
    "print(\"=\" * 50)\n",
    "for length_class in [\"single_term\", \"short_phrase\", \"sentence\"]:\n",
    "    count = len(pairs_by_length[length_class])\n",
    "    pct = count / len(pairs) * 100 if pairs else 0\n",
    "    print(f\"  {length_class:<15}: {count:>8,} ({pct:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show examples for each length class\n",
    "print(\"\\nExamples by length class:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for length_class in [\"single_term\", \"short_phrase\", \"sentence\"]:\n",
    "    examples = pairs_by_length[length_class][:3]\n",
    "    print(f\"\\n{length_class}:\")\n",
    "    for ex in examples:\n",
    "        source = ex.get(\"source\", \"\")\n",
    "        target = ex.get(\"target\", \"\")\n",
    "        print(f\"  '{source}' -> '{target}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-10",
   "metadata": {},
   "source": [
    "## 4. Build Corpus for Negative Mining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build vocabulary from all available sources\n",
    "all_terms: Set[str] = set()\n",
    "\n",
    "# Add terms from augmented pairs\n",
    "for pair in pairs:\n",
    "    all_terms.add(pair.get(\"source\", \"\"))\n",
    "    all_terms.add(pair.get(\"target\", \"\"))\n",
    "\n",
    "# Add terms from single-term triplets\n",
    "for triplet in single_term_triplets:\n",
    "    all_terms.add(triplet.get(\"anchor\", \"\"))\n",
    "    all_terms.add(triplet.get(\"positive\", \"\"))\n",
    "    negative = triplet.get(\"negative\", \"\")\n",
    "    if negative:\n",
    "        all_terms.add(negative)\n",
    "\n",
    "# Remove empty strings\n",
    "all_terms.discard(\"\")\n",
    "all_terms_list = list(all_terms)\n",
    "\n",
    "print(f\"Total unique terms in corpus: {len(all_terms_list):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-12",
   "metadata": {},
   "source": [
    "## 5. Hard Negative Mining with BM25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.hard_negative_miner import BM25Scorer, HardNegativeMiner\n",
    "\n",
    "# Initialize BM25 scorer for hard negative mining\n",
    "print(\"Fitting BM25 scorer on corpus...\")\n",
    "bm25_scorer = BM25Scorer(k1=1.5, b=0.75, epsilon=0.25)\n",
    "bm25_scorer.fit(all_terms_list)\n",
    "\n",
    "print(f\"BM25 fitted on {bm25_scorer.corpus_size:,} documents\")\n",
    "print(f\"Average document length: {bm25_scorer.avgdl:.2f}\")\n",
    "print(f\"Vocabulary size: {len(bm25_scorer.idf):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class TrainingTriplet:\n",
    "    \"\"\"Training triplet for contrastive learning.\"\"\"\n",
    "    anchor: str\n",
    "    positive: str\n",
    "    negative: str\n",
    "    difficulty: str  # \"easy\", \"medium\", \"hard\"\n",
    "    length_class: str  # \"single_term\", \"short_phrase\", \"sentence\"\n",
    "    pair_type: str\n",
    "    source: str  # dataset source\n",
    "\n",
    "\n",
    "def compute_char_overlap(text1: str, text2: str) -> float:\n",
    "    \"\"\"Compute character overlap ratio between two texts.\"\"\"\n",
    "    chars1 = set(text1.lower())\n",
    "    chars2 = set(text2.lower())\n",
    "    if not chars1 or not chars2:\n",
    "        return 0.0\n",
    "    intersection = len(chars1 & chars2)\n",
    "    union = len(chars1 | chars2)\n",
    "    return intersection / union if union > 0 else 0.0\n",
    "\n",
    "\n",
    "def classify_difficulty(source: str, negative: str) -> str:\n",
    "    \"\"\"\n",
    "    Classify difficulty based on character overlap and length similarity.\n",
    "    \n",
    "    Args:\n",
    "        source: Anchor text\n",
    "        negative: Negative text\n",
    "        \n",
    "    Returns:\n",
    "        Difficulty level: 'easy', 'medium', or 'hard'\n",
    "    \"\"\"\n",
    "    char_overlap = compute_char_overlap(source, negative)\n",
    "    len_diff = abs(len(source) - len(negative))\n",
    "    \n",
    "    # Hard: High character overlap and similar length\n",
    "    if char_overlap >= 0.4 and len_diff <= 2:\n",
    "        return \"hard\"\n",
    "    # Medium: Some overlap or similar length\n",
    "    elif char_overlap >= 0.2 or len_diff <= 3:\n",
    "        return \"medium\"\n",
    "    # Easy: Low overlap and different length\n",
    "    else:\n",
    "        return \"easy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_hard_negatives_bm25(\n",
    "    source: str,\n",
    "    positives: Set[str],\n",
    "    bm25: BM25Scorer,\n",
    "    corpus: List[str],\n",
    "    n: int = 10,\n",
    "    top_k: int = 100,\n",
    ") -> List[Tuple[str, str]]:\n",
    "    \"\"\"\n",
    "    Find hard negatives using BM25 scoring.\n",
    "    \n",
    "    Args:\n",
    "        source: Query/anchor text\n",
    "        positives: Set of positive texts to exclude\n",
    "        bm25: Fitted BM25Scorer\n",
    "        corpus: Full corpus list\n",
    "        n: Number of negatives to return\n",
    "        top_k: Number of candidates to consider\n",
    "        \n",
    "    Returns:\n",
    "        List of (negative, difficulty) tuples\n",
    "    \"\"\"\n",
    "    # Get top-k candidates by BM25 score\n",
    "    candidates = bm25.get_top_k(source, k=top_k)\n",
    "    \n",
    "    negatives = []\n",
    "    for idx, score in candidates:\n",
    "        candidate = corpus[idx]\n",
    "        \n",
    "        # Skip if candidate is source or positive\n",
    "        if candidate == source or candidate in positives:\n",
    "            continue\n",
    "        \n",
    "        # Compute difficulty\n",
    "        difficulty = classify_difficulty(source, candidate)\n",
    "        negatives.append((candidate, difficulty))\n",
    "        \n",
    "        if len(negatives) >= n:\n",
    "            break\n",
    "    \n",
    "    return negatives\n",
    "\n",
    "\n",
    "def find_random_negatives(\n",
    "    source: str,\n",
    "    positives: Set[str],\n",
    "    corpus: List[str],\n",
    "    n: int = 10,\n",
    ") -> List[Tuple[str, str]]:\n",
    "    \"\"\"\n",
    "    Find random negatives with difficulty classification.\n",
    "    \n",
    "    Args:\n",
    "        source: Query/anchor text\n",
    "        positives: Set of positive texts to exclude\n",
    "        corpus: Full corpus list\n",
    "        n: Number of negatives to return\n",
    "        \n",
    "    Returns:\n",
    "        List of (negative, difficulty) tuples\n",
    "    \"\"\"\n",
    "    # Sample random candidates\n",
    "    sample_size = min(len(corpus), n * 10)\n",
    "    candidates = random.sample(corpus, sample_size)\n",
    "    \n",
    "    negatives = []\n",
    "    for candidate in candidates:\n",
    "        if candidate == source or candidate in positives:\n",
    "            continue\n",
    "        \n",
    "        difficulty = classify_difficulty(source, candidate)\n",
    "        negatives.append((candidate, difficulty))\n",
    "        \n",
    "        if len(negatives) >= n:\n",
    "            break\n",
    "    \n",
    "    return negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_triplets_for_pair(\n",
    "    pair: Dict,\n",
    "    bm25: BM25Scorer,\n",
    "    corpus: List[str],\n",
    "    source_to_targets: Dict[str, Set[str]],\n",
    "    n_negatives: int = 3,\n",
    "    use_bm25: bool = True,\n",
    ") -> List[TrainingTriplet]:\n",
    "    \"\"\"\n",
    "    Generate training triplets for a synonym pair.\n",
    "    \n",
    "    Args:\n",
    "        pair: Dictionary with source and target\n",
    "        bm25: Fitted BM25Scorer\n",
    "        corpus: Full corpus list\n",
    "        source_to_targets: Mapping from source to all its targets\n",
    "        n_negatives: Number of negatives per pair\n",
    "        use_bm25: Use BM25 for hard negative mining\n",
    "        \n",
    "    Returns:\n",
    "        List of TrainingTriplet objects\n",
    "    \"\"\"\n",
    "    source = pair.get(\"source\", \"\")\n",
    "    target = pair.get(\"target\", \"\")\n",
    "    positives = source_to_targets.get(source, {target})\n",
    "    length_class = get_length_class(source)\n",
    "    pair_type = pair.get(\"pair_type\", \"original\")\n",
    "    data_source = pair.get(\"category\", \"unknown\")\n",
    "    \n",
    "    # Find negatives\n",
    "    if use_bm25:\n",
    "        negatives = find_hard_negatives_bm25(\n",
    "            source, positives, bm25, corpus, n=n_negatives * 2\n",
    "        )\n",
    "    else:\n",
    "        negatives = find_random_negatives(\n",
    "            source, positives, corpus, n=n_negatives * 2\n",
    "        )\n",
    "    \n",
    "    # Balance by difficulty\n",
    "    by_difficulty: Dict[str, List[str]] = defaultdict(list)\n",
    "    for neg, diff in negatives:\n",
    "        by_difficulty[diff].append(neg)\n",
    "    \n",
    "    triplets = []\n",
    "    for difficulty in [\"easy\", \"medium\", \"hard\"]:\n",
    "        candidates = by_difficulty[difficulty]\n",
    "        n_select = min(len(candidates), max(1, n_negatives // 3))\n",
    "        selected = random.sample(candidates, n_select) if candidates else []\n",
    "        \n",
    "        for neg in selected:\n",
    "            triplets.append(TrainingTriplet(\n",
    "                anchor=source,\n",
    "                positive=target,\n",
    "                negative=neg,\n",
    "                difficulty=difficulty,\n",
    "                length_class=length_class,\n",
    "                pair_type=pair_type,\n",
    "                source=data_source,\n",
    "            ))\n",
    "    \n",
    "    return triplets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate triplets from augmented pairs\n",
    "print(\"Generating triplets from augmented pairs...\")\n",
    "augmented_triplets: List[TrainingTriplet] = []\n",
    "\n",
    "for pair in tqdm(pairs, desc=\"Generating triplets\"):\n",
    "    triplets = generate_triplets_for_pair(\n",
    "        pair=pair,\n",
    "        bm25=bm25_scorer,\n",
    "        corpus=all_terms_list,\n",
    "        source_to_targets=source_to_targets,\n",
    "        n_negatives=CONFIG[\"n_negatives_per_pair\"],\n",
    "        use_bm25=True,\n",
    "    )\n",
    "    augmented_triplets.extend(triplets)\n",
    "\n",
    "print(f\"\\nGenerated {len(augmented_triplets):,} triplets from augmented pairs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert existing single-term expanded triplets\n",
    "single_term_training: List[TrainingTriplet] = []\n",
    "\n",
    "for triplet in single_term_triplets:\n",
    "    single_term_training.append(TrainingTriplet(\n",
    "        anchor=triplet[\"anchor\"],\n",
    "        positive=triplet[\"positive\"],\n",
    "        negative=triplet.get(\"negative\", \"\"),\n",
    "        difficulty=triplet.get(\"difficulty\", \"medium\"),\n",
    "        length_class=\"single_term\",\n",
    "        pair_type=\"single_term_expanded\",\n",
    "        source=\"single_term_expanded\",\n",
    "    ))\n",
    "\n",
    "print(f\"Converted {len(single_term_training):,} single-term expanded triplets\")\n",
    "\n",
    "# Merge all triplets\n",
    "all_triplets = augmented_triplets + single_term_training\n",
    "print(f\"\\nTotal triplets: {len(all_triplets):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-19",
   "metadata": {},
   "source": [
    "## 6. Triplet Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_triplet_statistics(triplets: List[TrainingTriplet], title: str = \"Triplet Statistics\"):\n",
    "    \"\"\"Print statistics for a list of triplets.\"\"\"\n",
    "    print(f\"\\n{title}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # By difficulty\n",
    "    difficulty_counts: Dict[str, int] = defaultdict(int)\n",
    "    for t in triplets:\n",
    "        difficulty_counts[t.difficulty] += 1\n",
    "    \n",
    "    print(\"\\nBy Difficulty:\")\n",
    "    for diff in [\"easy\", \"medium\", \"hard\"]:\n",
    "        count = difficulty_counts[diff]\n",
    "        pct = count / len(triplets) * 100 if triplets else 0\n",
    "        print(f\"  {diff:<10}: {count:>8,} ({pct:.1f}%)\")\n",
    "    \n",
    "    # By length class\n",
    "    length_counts: Dict[str, int] = defaultdict(int)\n",
    "    for t in triplets:\n",
    "        length_counts[t.length_class] += 1\n",
    "    \n",
    "    print(\"\\nBy Length Class:\")\n",
    "    for lc in [\"single_term\", \"short_phrase\", \"sentence\"]:\n",
    "        count = length_counts[lc]\n",
    "        pct = count / len(triplets) * 100 if triplets else 0\n",
    "        print(f\"  {lc:<15}: {count:>8,} ({pct:.1f}%)\")\n",
    "    \n",
    "    # By pair type (top 10)\n",
    "    type_counts: Dict[str, int] = defaultdict(int)\n",
    "    for t in triplets:\n",
    "        type_counts[t.pair_type] += 1\n",
    "    \n",
    "    print(\"\\nBy Pair Type (top 10):\")\n",
    "    for pt, count in sorted(type_counts.items(), key=lambda x: -x[1])[:10]:\n",
    "        pct = count / len(triplets) * 100 if triplets else 0\n",
    "        print(f\"  {pt:<25}: {count:>8,} ({pct:.1f}%)\")\n",
    "\n",
    "\n",
    "print_triplet_statistics(all_triplets, \"All Triplets Statistics\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-21",
   "metadata": {},
   "source": [
    "## 7. Create Curriculum Learning Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_curriculum_splits(\n",
    "    triplets: List[TrainingTriplet],\n",
    "    phase1_ratios: Dict[str, float],\n",
    "    phase2_ratios: Dict[str, float],\n",
    ") -> Dict[str, List[TrainingTriplet]]:\n",
    "    \"\"\"\n",
    "    Create curriculum learning splits for SPLADELossV23.\n",
    "    \n",
    "    - Phase 1 (epochs 1-7): Single-term focus (50% single, 30% short, 20% sentence)\n",
    "    - Phase 2 (epochs 8-14): Balanced (33% each)\n",
    "    - Phase 3 (epochs 15-20): Full data with hard negatives\n",
    "    \n",
    "    Args:\n",
    "        triplets: All training triplets\n",
    "        phase1_ratios: Ratios for phase 1\n",
    "        phase2_ratios: Ratios for phase 2\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary of phase name to triplet list\n",
    "    \"\"\"\n",
    "    # Group by length class\n",
    "    by_length: Dict[str, List[TrainingTriplet]] = defaultdict(list)\n",
    "    for t in triplets:\n",
    "        by_length[t.length_class].append(t)\n",
    "    \n",
    "    single_term = by_length[\"single_term\"]\n",
    "    short_phrase = by_length[\"short_phrase\"]\n",
    "    sentence = by_length[\"sentence\"]\n",
    "    \n",
    "    print(f\"Available data:\")\n",
    "    print(f\"  single_term: {len(single_term):,}\")\n",
    "    print(f\"  short_phrase: {len(short_phrase):,}\")\n",
    "    print(f\"  sentence: {len(sentence):,}\")\n",
    "    \n",
    "    # Phase 1: Single-term focus\n",
    "    # Calculate target sizes based on single_term being 50%\n",
    "    phase1_base = len(single_term)\n",
    "    phase1_short_target = int(phase1_base * phase1_ratios[\"short_phrase\"] / phase1_ratios[\"single_term\"])\n",
    "    phase1_sentence_target = int(phase1_base * phase1_ratios[\"sentence\"] / phase1_ratios[\"single_term\"])\n",
    "    \n",
    "    phase1 = single_term.copy()\n",
    "    phase1 += random.sample(short_phrase, min(len(short_phrase), phase1_short_target))\n",
    "    phase1 += random.sample(sentence, min(len(sentence), phase1_sentence_target))\n",
    "    random.shuffle(phase1)\n",
    "    \n",
    "    # Phase 2: Balanced learning\n",
    "    min_class_size = min(len(single_term), len(short_phrase), len(sentence))\n",
    "    phase2 = []\n",
    "    phase2 += random.sample(single_term, min(len(single_term), min_class_size))\n",
    "    phase2 += random.sample(short_phrase, min(len(short_phrase), min_class_size))\n",
    "    phase2 += random.sample(sentence, min(len(sentence), min_class_size))\n",
    "    random.shuffle(phase2)\n",
    "    \n",
    "    # Phase 3: Full data (all triplets)\n",
    "    phase3 = triplets.copy()\n",
    "    random.shuffle(phase3)\n",
    "    \n",
    "    return {\n",
    "        \"phase1_single_term_focus\": phase1,\n",
    "        \"phase2_balanced\": phase2,\n",
    "        \"phase3_full\": phase3,\n",
    "    }\n",
    "\n",
    "\n",
    "curriculum_splits = create_curriculum_splits(\n",
    "    all_triplets,\n",
    "    CONFIG[\"phase1_ratios\"],\n",
    "    CONFIG[\"phase2_ratios\"],\n",
    ")\n",
    "\n",
    "print(\"\\nCurriculum Splits:\")\n",
    "for phase, data in curriculum_splits.items():\n",
    "    print(f\"  {phase}: {len(data):,} triplets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify length class distribution in each phase\n",
    "print(\"\\nLength Class Distribution by Phase:\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for phase_name, phase_data in curriculum_splits.items():\n",
    "    length_dist: Dict[str, int] = defaultdict(int)\n",
    "    for t in phase_data:\n",
    "        length_dist[t.length_class] += 1\n",
    "    \n",
    "    print(f\"\\n{phase_name}:\")\n",
    "    for lc in [\"single_term\", \"short_phrase\", \"sentence\"]:\n",
    "        count = length_dist[lc]\n",
    "        pct = count / len(phase_data) * 100 if phase_data else 0\n",
    "        print(f\"  {lc:<15}: {count:>8,} ({pct:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-24",
   "metadata": {},
   "source": [
    "## 8. Add MS MARCO Triplets to Phase 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert MS MARCO triplets and add to Phase 3\n",
    "msmarco_training: List[TrainingTriplet] = []\n",
    "\n",
    "for triplet in msmarco_triplets:\n",
    "    negative = triplet.get(\"negative\", \"\")\n",
    "    if not negative:\n",
    "        continue\n",
    "        \n",
    "    msmarco_training.append(TrainingTriplet(\n",
    "        anchor=triplet[\"anchor\"],\n",
    "        positive=triplet[\"positive\"],\n",
    "        negative=negative,\n",
    "        difficulty=triplet.get(\"difficulty\", \"medium\"),\n",
    "        length_class=triplet.get(\"length_class\", \"sentence\"),\n",
    "        pair_type=triplet.get(\"pair_type\", \"msmarco_direct\"),\n",
    "        source=\"msmarco\",\n",
    "    ))\n",
    "\n",
    "print(f\"Converted {len(msmarco_training):,} MS MARCO triplets\")\n",
    "\n",
    "# Add to Phase 3\n",
    "original_phase3_size = len(curriculum_splits[\"phase3_full\"])\n",
    "curriculum_splits[\"phase3_full\"].extend(msmarco_training)\n",
    "random.shuffle(curriculum_splits[\"phase3_full\"])\n",
    "\n",
    "print(f\"Phase 3 size: {original_phase3_size:,} -> {len(curriculum_splits['phase3_full']):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-26",
   "metadata": {},
   "source": [
    "## 9. Train/Validation Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_split(\n",
    "    triplets: List[TrainingTriplet],\n",
    "    val_ratio: float = 0.1,\n",
    ") -> Tuple[List[TrainingTriplet], List[TrainingTriplet]]:\n",
    "    \"\"\"\n",
    "    Split triplets into train and validation sets by anchor.\n",
    "    \n",
    "    Splits by anchor to prevent data leakage between train and validation.\n",
    "    \n",
    "    Args:\n",
    "        triplets: List of training triplets\n",
    "        val_ratio: Ratio of anchors for validation\n",
    "        \n",
    "    Returns:\n",
    "        Tuple of (train_triplets, val_triplets)\n",
    "    \"\"\"\n",
    "    # Group by anchor\n",
    "    by_anchor: Dict[str, List[TrainingTriplet]] = defaultdict(list)\n",
    "    for t in triplets:\n",
    "        by_anchor[t.anchor].append(t)\n",
    "    \n",
    "    # Shuffle anchors\n",
    "    anchors = list(by_anchor.keys())\n",
    "    random.shuffle(anchors)\n",
    "    \n",
    "    # Split anchors\n",
    "    val_size = int(len(anchors) * val_ratio)\n",
    "    val_anchors = set(anchors[:val_size])\n",
    "    \n",
    "    train_triplets = []\n",
    "    val_triplets = []\n",
    "    \n",
    "    for anchor, anchor_triplets in by_anchor.items():\n",
    "        if anchor in val_anchors:\n",
    "            val_triplets.extend(anchor_triplets)\n",
    "        else:\n",
    "            train_triplets.extend(anchor_triplets)\n",
    "    \n",
    "    return train_triplets, val_triplets\n",
    "\n",
    "\n",
    "# Split full dataset\n",
    "train_triplets, val_triplets = train_val_split(\n",
    "    all_triplets,\n",
    "    val_ratio=CONFIG[\"val_ratio\"],\n",
    ")\n",
    "\n",
    "print(f\"Train triplets: {len(train_triplets):,}\")\n",
    "print(f\"Validation triplets: {len(val_triplets):,}\")\n",
    "print(f\"Validation ratio: {len(val_triplets) / (len(train_triplets) + len(val_triplets)) * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-28",
   "metadata": {},
   "source": [
    "## 10. Compute IDF Weights for SPLADELossV23\n",
    "\n",
    "IDF weights are used in IDFAwareFLOPSLoss to weight token importance.\n",
    "\n",
    "Formula: `idf[token] = log(1 + (N - df + 0.5) / (df + 0.5))`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_idf_weights(\n",
    "    triplets: List[TrainingTriplet],\n",
    "    tokenizer_name: str = \"opensearch-project/opensearch-neural-sparse-encoding-multilingual-v1\",\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Compute IDF weights for vocabulary based on training data.\n",
    "    \n",
    "    Uses BM25-style IDF: log(1 + (N - df + 0.5) / (df + 0.5))\n",
    "    \n",
    "    Args:\n",
    "        triplets: Training triplets\n",
    "        tokenizer_name: Name of tokenizer to use\n",
    "        \n",
    "    Returns:\n",
    "        IDF weights tensor of shape (vocab_size,)\n",
    "    \"\"\"\n",
    "    from transformers import AutoTokenizer\n",
    "    \n",
    "    print(f\"Loading tokenizer: {tokenizer_name}\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
    "    vocab_size = tokenizer.vocab_size\n",
    "    \n",
    "    print(f\"Vocabulary size: {vocab_size:,}\")\n",
    "    \n",
    "    # Collect all texts\n",
    "    all_texts: List[str] = []\n",
    "    for t in triplets:\n",
    "        all_texts.append(t.anchor)\n",
    "        all_texts.append(t.positive)\n",
    "    \n",
    "    # Remove duplicates\n",
    "    unique_texts = list(set(all_texts))\n",
    "    N = len(unique_texts)\n",
    "    print(f\"Number of unique documents: {N:,}\")\n",
    "    \n",
    "    # Compute document frequencies\n",
    "    df = Counter()\n",
    "    \n",
    "    print(\"Computing document frequencies...\")\n",
    "    for text in tqdm(unique_texts, desc=\"Tokenizing\"):\n",
    "        tokens = tokenizer.encode(text, add_special_tokens=False)\n",
    "        unique_tokens = set(tokens)\n",
    "        df.update(unique_tokens)\n",
    "    \n",
    "    # Compute IDF for each token\n",
    "    print(\"Computing IDF weights...\")\n",
    "    idf_weights = torch.zeros(vocab_size, dtype=torch.float32)\n",
    "    \n",
    "    for token_id in range(vocab_size):\n",
    "        doc_freq = df.get(token_id, 0)\n",
    "        # BM25-style IDF\n",
    "        idf = math.log(1 + (N - doc_freq + 0.5) / (doc_freq + 0.5))\n",
    "        idf_weights[token_id] = idf\n",
    "    \n",
    "    # Statistics\n",
    "    nonzero_count = (idf_weights > 0).sum().item()\n",
    "    print(f\"\\nIDF Statistics:\")\n",
    "    print(f\"  Non-zero IDF tokens: {nonzero_count:,}\")\n",
    "    print(f\"  Min IDF: {idf_weights.min().item():.4f}\")\n",
    "    print(f\"  Max IDF: {idf_weights.max().item():.4f}\")\n",
    "    print(f\"  Mean IDF: {idf_weights.mean().item():.4f}\")\n",
    "    \n",
    "    return idf_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute IDF weights using training triplets\n",
    "idf_weights = compute_idf_weights(train_triplets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze IDF distribution\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get non-zero IDF values\n",
    "nonzero_idf = idf_weights[idf_weights > 0].numpy()\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Histogram of IDF values\n",
    "axes[0].hist(nonzero_idf, bins=50, edgecolor='black', alpha=0.7)\n",
    "axes[0].set_xlabel('IDF Value')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "axes[0].set_title('IDF Distribution (Non-zero values)')\n",
    "axes[0].axvline(nonzero_idf.mean(), color='r', linestyle='--', label=f'Mean: {nonzero_idf.mean():.2f}')\n",
    "axes[0].legend()\n",
    "\n",
    "# Log-scale histogram\n",
    "axes[1].hist(nonzero_idf, bins=50, edgecolor='black', alpha=0.7)\n",
    "axes[1].set_xlabel('IDF Value')\n",
    "axes[1].set_ylabel('Frequency (log scale)')\n",
    "axes[1].set_title('IDF Distribution (Log scale)')\n",
    "axes[1].set_yscale('log')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Percentile statistics\n",
    "percentiles = [10, 25, 50, 75, 90, 95, 99]\n",
    "print(\"\\nIDF Percentiles:\")\n",
    "for p in percentiles:\n",
    "    value = np.percentile(nonzero_idf, p)\n",
    "    print(f\"  {p}th percentile: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-32",
   "metadata": {},
   "source": [
    "## 11. Save Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_triplets(triplets: List[TrainingTriplet], path: Path) -> None:\n",
    "    \"\"\"\n",
    "    Save triplets to JSONL file.\n",
    "    \n",
    "    Args:\n",
    "        triplets: List of training triplets\n",
    "        path: Output file path\n",
    "    \"\"\"\n",
    "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "        for t in triplets:\n",
    "            f.write(json.dumps(asdict(t), ensure_ascii=False) + \"\\n\")\n",
    "    print(f\"Saved {len(triplets):,} triplets to {path}\")\n",
    "\n",
    "\n",
    "# Save main train/val splits\n",
    "save_triplets(train_triplets, V22_1_DATA_DIR / \"training_triplets.jsonl\")\n",
    "save_triplets(val_triplets, V22_1_DATA_DIR / \"validation_triplets.jsonl\")\n",
    "\n",
    "# Save curriculum learning splits\n",
    "for phase, data in curriculum_splits.items():\n",
    "    save_triplets(data, V22_1_DATA_DIR / f\"{phase}_triplets.jsonl\")\n",
    "\n",
    "# Save IDF weights\n",
    "idf_path = V22_1_DATA_DIR / \"idf_weights.pt\"\n",
    "torch.save(idf_weights, idf_path)\n",
    "print(f\"Saved IDF weights to {idf_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-34",
   "metadata": {},
   "source": [
    "## 12. Verify Problem Term Coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-35",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROBLEM_TERMS = [\"\\ucd94\\ucc9c\", \"\\ub370\\uc774\\ud130\\ubca0\\uc774\\uc2a4\", \"\\uc99d\\uc0c1\", \"\\uc9c8\\ud658\", \"\\uc778\\uc290\\ub9b0\"]\n",
    "\n",
    "print(\"Problem Term Coverage in Training Triplets:\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"{'Term':<15} {'As Anchor':>12} {'As Positive':>12} {'Total':>12}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "for term in PROBLEM_TERMS:\n",
    "    as_anchor = sum(1 for t in train_triplets if t.anchor == term)\n",
    "    as_positive = sum(1 for t in train_triplets if t.positive == term)\n",
    "    total = as_anchor + as_positive\n",
    "    print(f\"{term:<15} {as_anchor:>12} {as_positive:>12} {total:>12}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-36",
   "metadata": {},
   "source": [
    "## 13. Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-37",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"v22.1 Data Preparation Summary\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"\\nInput Data:\")\n",
    "print(f\"  Augmented pairs: {len(pairs):,}\")\n",
    "print(f\"  Single-term expanded: {len(single_term_triplets):,}\")\n",
    "print(f\"  MS MARCO triplets: {len(msmarco_triplets):,}\")\n",
    "\n",
    "print(f\"\\nOutput Data:\")\n",
    "print(f\"  Total triplets: {len(all_triplets):,}\")\n",
    "print(f\"  Training triplets: {len(train_triplets):,}\")\n",
    "print(f\"  Validation triplets: {len(val_triplets):,}\")\n",
    "\n",
    "print(f\"\\nCurriculum Phases (optimized for SPLADELossV23):\")\n",
    "for phase, data in curriculum_splits.items():\n",
    "    length_dist: Dict[str, int] = defaultdict(int)\n",
    "    for t in data:\n",
    "        length_dist[t.length_class] += 1\n",
    "    \n",
    "    print(f\"\\n  {phase} ({len(data):,} triplets):\")\n",
    "    for lc in [\"single_term\", \"short_phrase\", \"sentence\"]:\n",
    "        count = length_dist[lc]\n",
    "        pct = count / len(data) * 100 if data else 0\n",
    "        print(f\"    {lc}: {count:,} ({pct:.1f}%)\")\n",
    "\n",
    "print(f\"\\nIDF Weights:\")\n",
    "print(f\"  Shape: {idf_weights.shape}\")\n",
    "print(f\"  Non-zero tokens: {(idf_weights > 0).sum().item():,}\")\n",
    "print(f\"  Mean IDF: {idf_weights.mean().item():.4f}\")\n",
    "\n",
    "print(f\"\\nOutput Files:\")\n",
    "for f in sorted(V22_1_DATA_DIR.glob(\"*\")):\n",
    "    size_mb = f.stat().st_size / 1024 / 1024\n",
    "    print(f\"  {f.name}: {size_mb:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-38",
   "metadata": {},
   "source": [
    "## 14. Sample Output Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify output file format\n",
    "print(\"Sample Training Triplet:\")\n",
    "print(\"=\" * 60)\n",
    "if train_triplets:\n",
    "    sample = train_triplets[0]\n",
    "    print(json.dumps(asdict(sample), ensure_ascii=False, indent=2))\n",
    "\n",
    "print(\"\\nSample from each phase:\")\n",
    "print(\"=\" * 60)\n",
    "for phase_name, phase_data in curriculum_splits.items():\n",
    "    if phase_data:\n",
    "        print(f\"\\n{phase_name}:\")\n",
    "        sample = phase_data[0]\n",
    "        print(f\"  Anchor: {sample.anchor}\")\n",
    "        print(f\"  Positive: {sample.positive}\")\n",
    "        print(f\"  Negative: {sample.negative}\")\n",
    "        print(f\"  Difficulty: {sample.difficulty}\")\n",
    "        print(f\"  Length class: {sample.length_class}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify IDF weights can be loaded\n",
    "loaded_idf = torch.load(V22_1_DATA_DIR / \"idf_weights.pt\")\n",
    "print(f\"IDF weights loaded successfully\")\n",
    "print(f\"  Shape: {loaded_idf.shape}\")\n",
    "print(f\"  Dtype: {loaded_idf.dtype}\")\n",
    "print(f\"  Device: {loaded_idf.device}\")\n",
    "\n",
    "# Verify values match\n",
    "assert torch.allclose(idf_weights, loaded_idf), \"IDF weights mismatch!\"\n",
    "print(\"  Verification: PASSED\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-41",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "1. Run `03_training.ipynb` with SPLADELossV23\n",
    "2. Use phase-specific data for curriculum learning:\n",
    "   - Phase 1 (epochs 1-7): `phase1_single_term_focus_triplets.jsonl`\n",
    "   - Phase 2 (epochs 8-14): `phase2_balanced_triplets.jsonl`\n",
    "   - Phase 3 (epochs 15-20): `phase3_full_triplets.jsonl`\n",
    "3. Load `idf_weights.pt` for IDFAwareFLOPSLoss in SPLADELossV23"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

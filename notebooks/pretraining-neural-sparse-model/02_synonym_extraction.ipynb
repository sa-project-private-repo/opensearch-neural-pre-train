{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Korean-English Synonym Extraction\n",
    "\n",
    "This notebook extracts Korean-English synonym pairs from Wikipedia articles.\n",
    "\n",
    "## Extraction Methods\n",
    "1. **Inter-language links**: Match articles across Korean/English Wikipedia\n",
    "2. **Parenthetical mentions**: \"인공지능 (Artificial Intelligence)\"\n",
    "3. **First sentence definitions**: Common in encyclopedia entries\n",
    "\n",
    "## Output\n",
    "- Combined bilingual synonym dictionary\n",
    "- Confidence scores for each pair\n",
    "- Multiple sources tracked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import sys\nsys.path.append('../..')\n\nfrom src.data.synonym_extractor import SynonymExtractor, SynonymAugmenter\nfrom pathlib import Path\nimport json\nfrom typing import Optional"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Input paths\nko_articles_path = \"../../dataset/wikipedia/ko_articles.jsonl\"\nen_articles_path = \"../../dataset/wikipedia/en_articles.jsonl\"\n\n# Output paths\nwiki_synonyms_path = \"../../dataset/synonyms/wiki_synonyms.json\"\nentity_synonyms_path = \"../../dataset/synonyms/entity_synonyms.json\"\ncombined_synonyms_path = \"../../dataset/synonyms/combined_synonyms.json\"\n\n# Create output directory\nPath(wiki_synonyms_path).parent.mkdir(parents=True, exist_ok=True)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Initialize Extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extractor = SynonymExtractor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Extract from Inter-language Links\n",
    "\n",
    "Match Korean and English articles that refer to the same concept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interlang_synonyms = extractor.extract_from_interlang_links(\n",
    "    ko_articles_path=ko_articles_path,\n",
    "    en_articles_path=en_articles_path,\n",
    ")\n",
    "\n",
    "print(f\"\\nExtracted {len(interlang_synonyms)} synonyms from inter-language links\")\n",
    "print(\"\\nSample synonyms:\")\n",
    "for syn in interlang_synonyms[:10]:\n",
    "    print(f\"  {syn['korean']:20s} → {syn['english']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Extract from Parentheses (Korean Articles)\n",
    "\n",
    "Extract synonym pairs from parenthetical mentions in Korean articles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paren_ko_synonyms = extractor.extract_from_parentheses(\n",
    "    articles_path=ko_articles_path,\n",
    "    language=\"ko\",\n",
    ")\n",
    "\n",
    "print(f\"\\nExtracted {len(paren_ko_synonyms)} synonyms from Korean parentheses\")\n",
    "print(\"\\nSample synonyms:\")\n",
    "for syn in paren_ko_synonyms[:10]:\n",
    "    print(f\"  {syn['korean']:20s} → {syn['english']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Extract from First Sentences (Korean Articles)\n",
    "\n",
    "Extract synonym pairs from article definitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def_ko_synonyms = extractor.extract_from_first_sentence(\n",
    "    articles_path=ko_articles_path,\n",
    "    language=\"ko\",\n",
    ")\n",
    "\n",
    "print(f\"\\nExtracted {len(def_ko_synonyms)} synonyms from Korean definitions\")\n",
    "print(\"\\nSample synonyms:\")\n",
    "for syn in def_ko_synonyms[:10]:\n",
    "    print(f\"  {syn['korean']:20s} → {syn['english']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Combine and Filter Synonyms\n",
    "\n",
    "Merge all sources, deduplicate, and filter by confidence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all synonym sources\n",
    "combined_synonyms = extractor.combine_and_filter(\n",
    "    synonym_lists=[\n",
    "        interlang_synonyms,\n",
    "        paren_ko_synonyms,\n",
    "        def_ko_synonyms,\n",
    "    ],\n",
    "    min_confidence=0.5,\n",
    "    output_path=wiki_synonyms_path,\n",
    ")\n",
    "\n",
    "print(f\"\\nFinal synonym count: {len(combined_synonyms)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Add Existing Synonyms\n",
    "\n",
    "Merge with existing manually created synonym dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Load existing synonyms\nexisting_synonyms_path = \"../../dataset/llm_generated/enhanced_synonyms.json\"\n\ntry:\n    with open(existing_synonyms_path, \"r\", encoding=\"utf-8\") as f:\n        existing_synonyms = json.load(f)\n    \n    # Convert to new format\n    existing_formatted = []\n    for syn in existing_synonyms:\n        existing_formatted.append({\n            \"korean\": syn[\"korean\"],\n            \"english\": syn[\"english\"],\n            \"confidence\": 1.0,\n            \"sources\": [\"manual\"],\n        })\n    \n    print(f\"Loaded {len(existing_formatted)} existing synonyms\")\n    \n    # Combine with Wikipedia synonyms\n    all_synonyms = extractor.combine_and_filter(\n        synonym_lists=[combined_synonyms, existing_formatted],\n        min_confidence=0.5,\n        output_path=combined_synonyms_path,\n    )\n    \n    print(f\"\\nTotal unique synonyms: {len(all_synonyms)}\")\n    \nexcept FileNotFoundError:\n    print(f\"No existing synonyms found at {existing_synonyms_path}\")\n    all_synonyms = combined_synonyms"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Augment with Variations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmenter = SynonymAugmenter()\n",
    "\n",
    "# Generate variations (lowercase, etc.)\n",
    "augmented_synonyms = augmenter.generate_variations(all_synonyms)\n",
    "\n",
    "print(f\"Augmented from {len(all_synonyms)} to {len(augmented_synonyms)} synonyms\")\n",
    "\n",
    "# Save augmented version\n",
    "with open(combined_synonyms_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(augmented_synonyms, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"Saved to {combined_synonyms_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Analyze Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Confidence distribution\n",
    "confidences = [syn['confidence'] for syn in augmented_synonyms]\n",
    "print(\"Confidence distribution:\")\n",
    "print(f\"  Mean: {sum(confidences) / len(confidences):.2f}\")\n",
    "print(f\"  Min: {min(confidences):.2f}\")\n",
    "print(f\"  Max: {max(confidences):.2f}\")\n",
    "\n",
    "# Source distribution\n",
    "all_sources = []\n",
    "for syn in augmented_synonyms:\n",
    "    all_sources.extend(syn.get('sources', []))\n",
    "\n",
    "source_counts = Counter(all_sources)\n",
    "print(\"\\nSource distribution:\")\n",
    "for source, count in source_counts.most_common():\n",
    "    print(f\"  {source:25s}: {count:5d}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Display High-Quality Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by confidence\n",
    "high_quality = sorted(\n",
    "    augmented_synonyms,\n",
    "    key=lambda x: x['confidence'],\n",
    "    reverse=True\n",
    ")[:50]\n",
    "\n",
    "print(\"Top 50 high-quality synonym pairs:\")\n",
    "print(\"=\" * 80)\n",
    "for i, syn in enumerate(high_quality, 1):\n",
    "    sources = \", \".join(syn.get('sources', []))\n",
    "    print(f\"{i:2d}. {syn['korean']:25s} → {syn['english']:30s} [{syn['confidence']:.2f}]\")\n",
    "    print(f\"    Sources: {sources}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "We've successfully extracted Korean-English synonym pairs from Wikipedia using multiple methods:\n",
    "- Inter-language links (highest confidence)\n",
    "- Parenthetical mentions\n",
    "- First sentence definitions\n",
    "\n",
    "The combined dictionary is ready for use in Neural Sparse model pre-training.\n",
    "\n",
    "**Next steps:**\n",
    "- Prepare training data with synonym pairs\n",
    "- Implement Neural Sparse encoder\n",
    "- Pre-train model with cross-lingual alignment"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
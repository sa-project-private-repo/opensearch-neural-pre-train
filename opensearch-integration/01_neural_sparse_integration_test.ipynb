{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# OpenSearch Neural Sparse Integration Test\n",
    "\n",
    "This notebook tests the v21.4 Korean Neural Sparse Encoder integration with OpenSearch.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "1. OpenSearch cluster running (local or remote)\n",
    "2. ML plugin enabled\n",
    "3. v21.4 model uploaded to HuggingFace or model artifacts available locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "def find_project_root():\n",
    "    current = Path.cwd()\n",
    "    for parent in [current] + list(current.parents):\n",
    "        if (parent / \"pyproject.toml\").exists() or (parent / \"src\").exists():\n",
    "            return parent\n",
    "    return Path.cwd().parent.parent\n",
    "\n",
    "PROJECT_ROOT = find_project_root()\n",
    "sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "\n",
    "print(f\"Project root: {PROJECT_ROOT}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-2",
   "metadata": {},
   "source": [
    "## 1. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenSearch Configuration\n",
    "OPENSEARCH_HOST = \"localhost\"\n",
    "OPENSEARCH_PORT = 9200\n",
    "OPENSEARCH_URL = f\"http://{OPENSEARCH_HOST}:{OPENSEARCH_PORT}\"\n",
    "\n",
    "# Model paths\n",
    "MODEL_PATH = PROJECT_ROOT / \"huggingface\" / \"v21.4\"\n",
    "CHECKPOINT_PATH = PROJECT_ROOT / \"outputs\" / \"v21.4_korean_enhanced\" / \"best_model.pt\"\n",
    "\n",
    "# Index configuration\n",
    "INDEX_NAME = \"korean_sparse_test_v21_4\"\n",
    "\n",
    "print(f\"OpenSearch URL: {OPENSEARCH_URL}\")\n",
    "print(f\"Model path: {MODEL_PATH}\")\n",
    "print(f\"Index name: {INDEX_NAME}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-4",
   "metadata": {},
   "source": [
    "## 2. Load Model for Local Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KoreanNeuralSparseEncoder:\n",
    "    \"\"\"Korean Neural Sparse Encoder for OpenSearch integration.\"\"\"\n",
    "    \n",
    "    def __init__(self, model_path: Path, device: str = 'cpu'):\n",
    "        self.device = device\n",
    "        \n",
    "        # Load from HuggingFace format or checkpoint\n",
    "        if (model_path / \"model.safetensors\").exists() or (model_path / \"pytorch_model.bin\").exists():\n",
    "            self.model = AutoModelForMaskedLM.from_pretrained(model_path)\n",
    "            self.tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "        else:\n",
    "            # Load from training checkpoint\n",
    "            checkpoint = torch.load(CHECKPOINT_PATH, map_location='cpu')\n",
    "            config = checkpoint.get('config', {})\n",
    "            model_name = config.get('model_name', 'skt/A.X-Encoder-base')\n",
    "            \n",
    "            self.model = AutoModelForMaskedLM.from_pretrained(model_name)\n",
    "            self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "            \n",
    "            # Load trained weights\n",
    "            state_dict = checkpoint['model_state_dict']\n",
    "            new_state_dict = {k[6:] if k.startswith('model.') else k: v for k, v in state_dict.items()}\n",
    "            self.model.load_state_dict(new_state_dict, strict=True)\n",
    "        \n",
    "        self.model = self.model.to(device)\n",
    "        self.model.eval()\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def encode(self, text: str, top_k: int = 20) -> dict:\n",
    "        \"\"\"\n",
    "        Encode text to sparse vector format for OpenSearch.\n",
    "        \n",
    "        Returns:\n",
    "            Dictionary mapping token strings to weights (OpenSearch sparse_vector format)\n",
    "        \"\"\"\n",
    "        inputs = self.tokenizer(\n",
    "            text,\n",
    "            return_tensors='pt',\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            max_length=64\n",
    "        ).to(self.device)\n",
    "        \n",
    "        outputs = self.model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        \n",
    "        # SPLADE: log(1 + ReLU(x))\n",
    "        token_scores = torch.log1p(self.relu(logits))\n",
    "        \n",
    "        # Mask padding\n",
    "        mask = inputs['attention_mask'].unsqueeze(-1).float()\n",
    "        token_scores = token_scores * mask\n",
    "        \n",
    "        # Max pooling\n",
    "        sparse_repr = token_scores.max(dim=1).values[0]  # [vocab_size]\n",
    "        \n",
    "        # Get top tokens\n",
    "        top_values, top_indices = sparse_repr.topk(top_k)\n",
    "        \n",
    "        result = {}\n",
    "        for idx, val in zip(top_indices.tolist(), top_values.tolist()):\n",
    "            if val > 0:\n",
    "                token = self.tokenizer.decode([idx]).strip()\n",
    "                if token and token not in ['[CLS]', '[SEP]', '[PAD]', '[UNK]', '[MASK]']:\n",
    "                    result[token] = round(val, 4)\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def encode_batch(self, texts: list, top_k: int = 20) -> list:\n",
    "        \"\"\"Encode multiple texts.\"\"\"\n",
    "        return [self.encode(text, top_k) for text in texts]\n",
    "\n",
    "\n",
    "# Initialize encoder\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "encoder = KoreanNeuralSparseEncoder(MODEL_PATH, device)\n",
    "print(f\"Encoder initialized on {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test encoding\n",
    "test_text = \"당뇨병 환자의 인슐린 치료\"\n",
    "sparse_vector = encoder.encode(test_text)\n",
    "\n",
    "print(f\"Input: {test_text}\")\n",
    "print(f\"Sparse vector ({len(sparse_vector)} tokens):\")\n",
    "for token, weight in sorted(sparse_vector.items(), key=lambda x: -x[1])[:10]:\n",
    "    print(f\"  {token}: {weight}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-7",
   "metadata": {},
   "source": [
    "## 3. OpenSearch Connection Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def check_opensearch_connection():\n",
    "    \"\"\"Check if OpenSearch is accessible.\"\"\"\n",
    "    try:\n",
    "        response = requests.get(OPENSEARCH_URL, timeout=5)\n",
    "        if response.status_code == 200:\n",
    "            info = response.json()\n",
    "            print(f\"OpenSearch connected!\")\n",
    "            print(f\"  Version: {info.get('version', {}).get('number', 'unknown')}\")\n",
    "            print(f\"  Cluster: {info.get('cluster_name', 'unknown')}\")\n",
    "            return True\n",
    "    except requests.exceptions.ConnectionError:\n",
    "        print(f\"Cannot connect to OpenSearch at {OPENSEARCH_URL}\")\n",
    "        print(\"Make sure OpenSearch is running.\")\n",
    "    return False\n",
    "\n",
    "opensearch_available = check_opensearch_connection()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-9",
   "metadata": {},
   "source": [
    "## 4. Create Index with Sparse Vector Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sparse_index(index_name: str):\n",
    "    \"\"\"Create index with sparse_vector field mapping.\"\"\"\n",
    "    \n",
    "    # Delete if exists\n",
    "    requests.delete(f\"{OPENSEARCH_URL}/{index_name}\")\n",
    "    \n",
    "    # Create index with mapping\n",
    "    mapping = {\n",
    "        \"settings\": {\n",
    "            \"number_of_shards\": 1,\n",
    "            \"number_of_replicas\": 0\n",
    "        },\n",
    "        \"mappings\": {\n",
    "            \"properties\": {\n",
    "                \"text\": {\n",
    "                    \"type\": \"text\",\n",
    "                    \"analyzer\": \"standard\"\n",
    "                },\n",
    "                \"sparse_embedding\": {\n",
    "                    \"type\": \"rank_features\"\n",
    "                },\n",
    "                \"category\": {\n",
    "                    \"type\": \"keyword\"\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    response = requests.put(\n",
    "        f\"{OPENSEARCH_URL}/{index_name}\",\n",
    "        json=mapping,\n",
    "        headers={\"Content-Type\": \"application/json\"}\n",
    "    )\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        print(f\"Index '{index_name}' created successfully!\")\n",
    "        return True\n",
    "    else:\n",
    "        print(f\"Error creating index: {response.text}\")\n",
    "        return False\n",
    "\n",
    "if opensearch_available:\n",
    "    create_sparse_index(INDEX_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-11",
   "metadata": {},
   "source": [
    "## 5. Index Test Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test documents covering various domains\n",
    "TEST_DOCUMENTS = [\n",
    "    # Medical domain\n",
    "    {\"text\": \"당뇨병 환자는 인슐린 주사를 맞아야 합니다.\", \"category\": \"medical\"},\n",
    "    {\"text\": \"고혈압 증상으로는 두통과 어지러움이 있습니다.\", \"category\": \"medical\"},\n",
    "    {\"text\": \"암 환자의 항암 치료 부작용을 관리하는 방법\", \"category\": \"medical\"},\n",
    "    {\"text\": \"감기 증상 완화를 위한 약물 복용 방법\", \"category\": \"medical\"},\n",
    "    {\"text\": \"폐렴 질환의 진단과 치료 과정\", \"category\": \"medical\"},\n",
    "    \n",
    "    # Legal domain\n",
    "    {\"text\": \"부동산 계약 해지 시 위약금 규정\", \"category\": \"legal\"},\n",
    "    {\"text\": \"임대차 보호법에 따른 세입자 권리\", \"category\": \"legal\"},\n",
    "    {\"text\": \"상속법에 따른 유산 분배 절차\", \"category\": \"legal\"},\n",
    "    {\"text\": \"저작권 침해에 대한 법적 대응 방안\", \"category\": \"legal\"},\n",
    "    {\"text\": \"노동법 위반 시 처벌 규정 안내\", \"category\": \"legal\"},\n",
    "    \n",
    "    # Technology domain\n",
    "    {\"text\": \"데이터베이스 최적화를 위한 인덱스 설계\", \"category\": \"tech\"},\n",
    "    {\"text\": \"머신러닝 모델 학습을 위한 데이터 전처리\", \"category\": \"tech\"},\n",
    "    {\"text\": \"클라우드 서버 보안 설정 가이드\", \"category\": \"tech\"},\n",
    "    {\"text\": \"웹 애플리케이션 성능 최적화 방법\", \"category\": \"tech\"},\n",
    "    {\"text\": \"API 개발을 위한 RESTful 설계 원칙\", \"category\": \"tech\"},\n",
    "]\n",
    "\n",
    "print(f\"Prepared {len(TEST_DOCUMENTS)} test documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_documents(index_name: str, documents: list):\n",
    "    \"\"\"Index documents with sparse embeddings.\"\"\"\n",
    "    \n",
    "    indexed = 0\n",
    "    for i, doc in enumerate(documents):\n",
    "        # Generate sparse embedding\n",
    "        sparse_vector = encoder.encode(doc[\"text\"], top_k=30)\n",
    "        \n",
    "        # Prepare document\n",
    "        doc_body = {\n",
    "            \"text\": doc[\"text\"],\n",
    "            \"sparse_embedding\": sparse_vector,\n",
    "            \"category\": doc[\"category\"]\n",
    "        }\n",
    "        \n",
    "        # Index document\n",
    "        response = requests.put(\n",
    "            f\"{OPENSEARCH_URL}/{index_name}/_doc/{i}\",\n",
    "            json=doc_body,\n",
    "            headers={\"Content-Type\": \"application/json\"}\n",
    "        )\n",
    "        \n",
    "        if response.status_code in [200, 201]:\n",
    "            indexed += 1\n",
    "        else:\n",
    "            print(f\"Error indexing doc {i}: {response.text}\")\n",
    "    \n",
    "    # Refresh index\n",
    "    requests.post(f\"{OPENSEARCH_URL}/{index_name}/_refresh\")\n",
    "    \n",
    "    print(f\"Indexed {indexed}/{len(documents)} documents\")\n",
    "    return indexed\n",
    "\n",
    "if opensearch_available:\n",
    "    index_documents(INDEX_NAME, TEST_DOCUMENTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-14",
   "metadata": {},
   "source": [
    "## 6. Sparse Search Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparse_search(index_name: str, query: str, top_k: int = 5):\n",
    "    \"\"\"\n",
    "    Perform sparse vector search using rank_feature queries.\n",
    "    \"\"\"\n",
    "    # Encode query\n",
    "    query_vector = encoder.encode(query, top_k=20)\n",
    "    \n",
    "    # Build rank_feature queries\n",
    "    should_queries = []\n",
    "    for token, weight in query_vector.items():\n",
    "        should_queries.append({\n",
    "            \"rank_feature\": {\n",
    "                \"field\": f\"sparse_embedding.{token}\",\n",
    "                \"boost\": weight\n",
    "            }\n",
    "        })\n",
    "    \n",
    "    # Search query\n",
    "    search_body = {\n",
    "        \"query\": {\n",
    "            \"bool\": {\n",
    "                \"should\": should_queries,\n",
    "                \"minimum_should_match\": 1\n",
    "            }\n",
    "        },\n",
    "        \"size\": top_k,\n",
    "        \"_source\": [\"text\", \"category\"]\n",
    "    }\n",
    "    \n",
    "    response = requests.post(\n",
    "        f\"{OPENSEARCH_URL}/{index_name}/_search\",\n",
    "        json=search_body,\n",
    "        headers={\"Content-Type\": \"application/json\"}\n",
    "    )\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        results = response.json()\n",
    "        hits = results.get(\"hits\", {}).get(\"hits\", [])\n",
    "        return hits\n",
    "    else:\n",
    "        print(f\"Search error: {response.text}\")\n",
    "        return []\n",
    "\n",
    "\n",
    "def print_search_results(query: str, results: list):\n",
    "    \"\"\"Pretty print search results.\"\"\"\n",
    "    print(f\"\\nQuery: {query}\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    if not results:\n",
    "        print(\"No results found\")\n",
    "        return\n",
    "    \n",
    "    for i, hit in enumerate(results, 1):\n",
    "        score = hit.get(\"_score\", 0)\n",
    "        source = hit.get(\"_source\", {})\n",
    "        text = source.get(\"text\", \"\")\n",
    "        category = source.get(\"category\", \"\")\n",
    "        print(f\"{i}. [{category}] {text}\")\n",
    "        print(f\"   Score: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test queries\n",
    "TEST_QUERIES = [\n",
    "    # Single term queries (problem terms from v21.3)\n",
    "    \"인슐린\",\n",
    "    \"데이터베이스\",\n",
    "    \"증상\",\n",
    "    \"질환\",\n",
    "    \"추천\",\n",
    "    \n",
    "    # Short phrase queries\n",
    "    \"당뇨병 치료\",\n",
    "    \"법적 분쟁\",\n",
    "    \"서버 보안\",\n",
    "    \n",
    "    # Natural language queries\n",
    "    \"암 환자 식단 추천\",\n",
    "    \"부동산 계약서 작성 방법\",\n",
    "]\n",
    "\n",
    "if opensearch_available:\n",
    "    print(\"=\" * 60)\n",
    "    print(\"Sparse Search Results\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    for query in TEST_QUERIES:\n",
    "        results = sparse_search(INDEX_NAME, query, top_k=3)\n",
    "        print_search_results(query, results)\n",
    "else:\n",
    "    print(\"OpenSearch not available. Skipping search tests.\")\n",
    "    print(\"\\nTo run these tests:\")\n",
    "    print(\"1. Start OpenSearch locally or connect to a remote cluster\")\n",
    "    print(\"2. Update OPENSEARCH_HOST and OPENSEARCH_PORT\")\n",
    "    print(\"3. Re-run this notebook\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-17",
   "metadata": {},
   "source": [
    "## 7. Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relevance ground truth for evaluation\n",
    "RELEVANCE_GT = {\n",
    "    \"인슐린\": [\"medical\"],\n",
    "    \"데이터베이스\": [\"tech\"],\n",
    "    \"증상\": [\"medical\"],\n",
    "    \"질환\": [\"medical\"],\n",
    "    \"당뇨병 치료\": [\"medical\"],\n",
    "    \"법적 분쟁\": [\"legal\"],\n",
    "    \"서버 보안\": [\"tech\"],\n",
    "    \"암 환자 식단 추천\": [\"medical\"],\n",
    "    \"부동산 계약서 작성 방법\": [\"legal\"],\n",
    "}\n",
    "\n",
    "def evaluate_search(query: str, results: list, expected_categories: list):\n",
    "    \"\"\"Evaluate search result relevance.\"\"\"\n",
    "    if not results:\n",
    "        return 0.0\n",
    "    \n",
    "    # Check if top result is in expected category\n",
    "    top_category = results[0].get(\"_source\", {}).get(\"category\", \"\")\n",
    "    return 1.0 if top_category in expected_categories else 0.0\n",
    "\n",
    "\n",
    "if opensearch_available:\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"Search Relevance Evaluation\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    total_queries = 0\n",
    "    correct = 0\n",
    "    \n",
    "    for query, expected in RELEVANCE_GT.items():\n",
    "        results = sparse_search(INDEX_NAME, query, top_k=1)\n",
    "        score = evaluate_search(query, results, expected)\n",
    "        \n",
    "        total_queries += 1\n",
    "        correct += score\n",
    "        \n",
    "        status = \"✓\" if score == 1.0 else \"✗\"\n",
    "        top_cat = results[0].get(\"_source\", {}).get(\"category\", \"N/A\") if results else \"N/A\"\n",
    "        print(f\"{status} '{query}' -> {top_cat} (expected: {expected})\")\n",
    "    \n",
    "    precision = correct / total_queries * 100 if total_queries > 0 else 0\n",
    "    print(f\"\\nPrecision@1: {precision:.1f}% ({int(correct)}/{total_queries})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-19",
   "metadata": {},
   "source": [
    "## 8. Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanup_index(index_name: str):\n",
    "    \"\"\"Delete test index.\"\"\"\n",
    "    response = requests.delete(f\"{OPENSEARCH_URL}/{index_name}\")\n",
    "    if response.status_code == 200:\n",
    "        print(f\"Index '{index_name}' deleted\")\n",
    "    else:\n",
    "        print(f\"Cleanup failed: {response.text}\")\n",
    "\n",
    "# Uncomment to cleanup:\n",
    "# if opensearch_available:\n",
    "#     cleanup_index(INDEX_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-21",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"OpenSearch Integration Test Complete!\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\nNext Steps:\")\n",
    "print(\"1. Deploy model to OpenSearch ML node\")\n",
    "print(\"2. Register model with OpenSearch ML plugin\")\n",
    "print(\"3. Create neural sparse ingest pipeline\")\n",
    "print(\"4. Index production documents with sparse embeddings\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

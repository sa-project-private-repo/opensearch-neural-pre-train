{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenSearch Neural Sparse Integration Test\n",
    "\n",
    "This notebook tests the korean-neural-sparse-encoder-v1 model with OpenSearch.\n",
    "\n",
    "**Approach**: External embedding - Generate sparse vectors locally and index to OpenSearch.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- AWS credentials configured (default profile)\n",
    "- OpenSearch domain: ltr-vector.awsbuddy.com\n",
    "- Required packages: opensearch-py, requests-aws4auth, boto3, transformers, torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: /home/west/Documents/cursor-workspace/opensearch-neural-pre-train\n",
      "Huggingface dir: /home/west/Documents/cursor-workspace/opensearch-neural-pre-train/huggingface\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add project root to path\n",
    "PROJECT_ROOT = Path.cwd().parent\n",
    "HUGGINGFACE_DIR = PROJECT_ROOT / \"huggingface\"\n",
    "sys.path.insert(0, str(HUGGINGFACE_DIR))\n",
    "\n",
    "print(f\"Project root: {PROJECT_ROOT}\")\n",
    "print(f\"Huggingface dir: {HUGGINGFACE_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Packages imported successfully\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import time\n",
    "from typing import Dict, List, Any\n",
    "\n",
    "import boto3\n",
    "import torch\n",
    "from opensearchpy import OpenSearch, RequestsHttpConnection\n",
    "from opensearchpy.helpers import bulk\n",
    "from requests_aws4auth import AWS4Auth\n",
    "from transformers import AutoTokenizer, AutoConfig\n",
    "from safetensors.torch import load_file\n",
    "\n",
    "from modeling_splade import SPLADEModel\n",
    "\n",
    "print(\"Packages imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Neural Sparse Model (Local)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/west/Documents/cursor-workspace/opensearch-neural-pre-train/.venv/lib/python3.12/site-packages/torch/cuda/__init__.py:435: UserWarning: \n",
      "    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.\n",
      "    Minimum and Maximum cuda capability supported by this version of PyTorch is\n",
      "    (8.0) - (12.0)\n",
      "    \n",
      "  queued_call()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded on cuda\n",
      "Vocab size: 50000\n"
     ]
    }
   ],
   "source": [
    "# Load model from local huggingface folder\n",
    "tokenizer = AutoTokenizer.from_pretrained(str(HUGGINGFACE_DIR))\n",
    "config = AutoConfig.from_pretrained(str(HUGGINGFACE_DIR))\n",
    "model = SPLADEModel(config)\n",
    "\n",
    "# Load weights\n",
    "state_dict = load_file(str(HUGGINGFACE_DIR / \"model.safetensors\"))\n",
    "model.load_state_dict(state_dict, strict=False)\n",
    "model.eval()\n",
    "\n",
    "# Use GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "print(f\"Model loaded on {device}\")\n",
    "print(f\"Vocab size: {config.vocab_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_sparse(text: str, top_k: int = 100) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Encode text to sparse vector.\n",
    "    \n",
    "    Returns dict of {token: weight} for non-zero weights.\n",
    "    \"\"\"\n",
    "    inputs = tokenizer(\n",
    "        text,\n",
    "        return_tensors=\"pt\",\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=64,\n",
    "    )\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        sparse_repr, _ = model(**inputs)\n",
    "    \n",
    "    # Get top-k non-zero values\n",
    "    weights = sparse_repr[0].cpu()\n",
    "    top_values, top_indices = weights.topk(top_k)\n",
    "    \n",
    "    result = {}\n",
    "    for idx, val in zip(top_indices.tolist(), top_values.tolist()):\n",
    "        if val > 0:\n",
    "            token = tokenizer.decode([idx]).strip()\n",
    "            if token and not token.startswith(\"##\"):  # Skip subword tokens for cleaner output\n",
    "                result[token] = round(val, 4)\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "def encode_sparse_full(text: str, min_weight: float = 0.1) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Encode text to sparse vector with all tokens above threshold.\n",
    "    \n",
    "    Returns dict of {token_id: weight} for weights > min_weight.\n",
    "    Uses token IDs as keys for OpenSearch compatibility.\n",
    "    \"\"\"\n",
    "    inputs = tokenizer(\n",
    "        text,\n",
    "        return_tensors=\"pt\",\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=64,\n",
    "    )\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        sparse_repr, _ = model(**inputs)\n",
    "    \n",
    "    weights = sparse_repr[0].cpu()\n",
    "    \n",
    "    # Get all non-zero values above threshold\n",
    "    non_zero_mask = weights > min_weight\n",
    "    non_zero_indices = non_zero_mask.nonzero(as_tuple=True)[0]\n",
    "    \n",
    "    result = {}\n",
    "    for idx in non_zero_indices.tolist():\n",
    "        val = weights[idx].item()\n",
    "        token = tokenizer.decode([idx]).strip()\n",
    "        if token:  # Skip empty tokens\n",
    "            # Use token string as key (OpenSearch rank_features requires string keys)\n",
    "            result[token] = round(val, 4)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1228 15:21:00.375000 3292845 torch/_inductor/utils.py:1661] [1/0_1] Not enough SMs to use max_autotune_gemm mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "'손해배상':\n",
      "  손해: 3.1094\n",
      "  상: 2.6562\n",
      "  배: 2.3906\n",
      "  보상: 2.2812\n",
      "  피해: 2.2656\n",
      "  손실: 2.2344\n",
      "  손: 2.2031\n",
      "\n",
      "'인공지능':\n",
      "  인공지능: 3.1094\n",
      "  AI: 2.5781\n",
      "  지능: 2.4062\n",
      "  알고리즘: 2.3125\n",
      "  로봇: 2.1406\n",
      "  인공: 2.0938\n",
      "  컴퓨팅: 2.0625\n",
      "  플랫폼: 2.0469\n",
      "  컴퓨터: 2.0469\n",
      "\n",
      "'진단':\n",
      "  진단: 3.2188\n",
      "  검진: 2.5469\n",
      "  diagn: 2.3906\n",
      "  검사: 2.3906\n",
      "  확진: 2.3438\n",
      "  진료: 2.3125\n",
      "  점검: 2.2656\n",
      "  측정: 2.2656\n"
     ]
    }
   ],
   "source": [
    "# Test encoding\n",
    "test_queries = [\"손해배상\", \"인공지능\", \"진단\"]\n",
    "\n",
    "for query in test_queries:\n",
    "    sparse = encode_sparse(query, top_k=10)\n",
    "    print(f\"\\n'{query}':\")\n",
    "    for token, weight in list(sparse.items())[:10]:\n",
    "        print(f\"  {token}: {weight}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Connect to OpenSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to OpenSearch\n",
      "Cluster name: 505725882051:ltr-vector\n"
     ]
    }
   ],
   "source": [
    "# OpenSearch configuration\n",
    "OPENSEARCH_HOST = \"ltr-vector.awsbuddy.com\"\n",
    "OPENSEARCH_PORT = 443\n",
    "AWS_REGION = \"us-east-1\"\n",
    "\n",
    "# Get AWS credentials\n",
    "credentials = boto3.Session().get_credentials()\n",
    "awsauth = AWS4Auth(\n",
    "    credentials.access_key,\n",
    "    credentials.secret_key,\n",
    "    AWS_REGION,\n",
    "    \"es\",\n",
    "    session_token=credentials.token,\n",
    ")\n",
    "\n",
    "# Create OpenSearch client\n",
    "client = OpenSearch(\n",
    "    hosts=[{\"host\": OPENSEARCH_HOST, \"port\": OPENSEARCH_PORT}],\n",
    "    http_auth=awsauth,\n",
    "    use_ssl=True,\n",
    "    verify_certs=True,\n",
    "    connection_class=RequestsHttpConnection,\n",
    "    timeout=60,\n",
    ")\n",
    "\n",
    "# Test connection\n",
    "info = client.info()\n",
    "print(f\"Connected to OpenSearch\")\n",
    "print(f\"Cluster name: {info['cluster_name']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create Index with rank_features Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index created: korean-neural-sparse-test\n"
     ]
    }
   ],
   "source": [
    "INDEX_NAME = \"korean-neural-sparse-test\"\n",
    "\n",
    "# Delete index if exists\n",
    "try:\n",
    "    client.indices.delete(index=INDEX_NAME)\n",
    "    print(f\"Deleted existing index: {INDEX_NAME}\")\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# Create index with rank_features for sparse vectors\n",
    "index_body = {\n",
    "    \"settings\": {\n",
    "        \"index\": {\n",
    "            \"number_of_shards\": 1,\n",
    "            \"number_of_replicas\": 0,\n",
    "        }\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"title\": {\"type\": \"text\", \"analyzer\": \"standard\"},\n",
    "            \"content\": {\"type\": \"text\", \"analyzer\": \"standard\"},\n",
    "            \"category\": {\"type\": \"keyword\"},\n",
    "            \"title_sparse\": {\"type\": \"rank_features\"},\n",
    "            \"content_sparse\": {\"type\": \"rank_features\"},\n",
    "        }\n",
    "    },\n",
    "}\n",
    "\n",
    "try:\n",
    "    response = client.indices.create(index=INDEX_NAME, body=index_body)\n",
    "    print(f\"Index created: {INDEX_NAME}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error creating index: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Prepare and Index Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total documents: 25\n"
     ]
    }
   ],
   "source": [
    "# Korean test documents (legal, medical, tech, business, general)\n",
    "DOCUMENTS = [\n",
    "    # Legal domain\n",
    "    {\n",
    "        \"title\": \"손해배상 청구 소송\",\n",
    "        \"content\": \"피고는 원고에게 발생한 손해에 대하여 배상할 책임이 있습니다. 본 사건에서 피고의 과실로 인해 원고가 입은 손해를 산정합니다.\",\n",
    "        \"category\": \"legal\",\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"계약 위반 및 해지\",\n",
    "        \"content\": \"계약 당사자 일방이 계약상 의무를 위반한 경우, 상대방은 계약을 해지할 수 있습니다. 계약 해지 시 원상회복 의무가 발생합니다.\",\n",
    "        \"category\": \"legal\",\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"부동산 매매 계약서\",\n",
    "        \"content\": \"매도인과 매수인은 아래 부동산에 대하여 매매계약을 체결합니다. 매매대금은 계약금, 중도금, 잔금으로 나누어 지급합니다.\",\n",
    "        \"category\": \"legal\",\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"형사 소송 절차 안내\",\n",
    "        \"content\": \"형사 소송은 수사, 기소, 공판, 판결의 순서로 진행됩니다. 피고인은 변호인의 조력을 받을 권리가 있습니다.\",\n",
    "        \"category\": \"legal\",\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"이혼 소송과 재산분할\",\n",
    "        \"content\": \"이혼 시 부부가 혼인 중 공동으로 형성한 재산은 분할의 대상이 됩니다. 재산분할 비율은 기여도에 따라 결정됩니다.\",\n",
    "        \"category\": \"legal\",\n",
    "    },\n",
    "    # Medical domain\n",
    "    {\n",
    "        \"title\": \"당뇨병 진단 및 치료\",\n",
    "        \"content\": \"당뇨병은 혈당 수치가 비정상적으로 높은 상태입니다. 진단을 위해 공복혈당 검사와 당화혈색소 검사를 시행합니다.\",\n",
    "        \"category\": \"medical\",\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"고혈압 관리 가이드\",\n",
    "        \"content\": \"고혈압은 혈압이 정상 범위를 초과하는 상태입니다. 생활습관 개선과 약물 치료를 통해 혈압을 조절할 수 있습니다.\",\n",
    "        \"category\": \"medical\",\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"암 조기 검진의 중요성\",\n",
    "        \"content\": \"암은 조기에 발견하면 완치율이 높습니다. 정기적인 건강검진을 통해 암을 조기에 발견할 수 있습니다.\",\n",
    "        \"category\": \"medical\",\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"감기와 독감의 차이\",\n",
    "        \"content\": \"감기와 독감은 모두 호흡기 질환이지만 원인 바이러스가 다릅니다. 독감은 고열과 근육통이 심하게 나타납니다.\",\n",
    "        \"category\": \"medical\",\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"우울증 치료 방법\",\n",
    "        \"content\": \"우울증은 전문적인 치료가 필요한 정신건강 질환입니다. 약물치료와 심리상담을 병행하면 효과적입니다.\",\n",
    "        \"category\": \"medical\",\n",
    "    },\n",
    "    # IT/Tech domain\n",
    "    {\n",
    "        \"title\": \"인공지능 기술 동향\",\n",
    "        \"content\": \"인공지능과 머신러닝 기술이 빠르게 발전하고 있습니다. 딥러닝 모델은 자연어 처리와 이미지 인식에서 뛰어난 성능을 보입니다.\",\n",
    "        \"category\": \"tech\",\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"클라우드 컴퓨팅 서비스\",\n",
    "        \"content\": \"클라우드 컴퓨팅은 인터넷을 통해 컴퓨팅 자원을 제공하는 서비스입니다. AWS, Azure, GCP가 대표적인 클라우드 서비스입니다.\",\n",
    "        \"category\": \"tech\",\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"검색 엔진 최적화 가이드\",\n",
    "        \"content\": \"검색 엔진 최적화(SEO)는 웹사이트가 검색 결과에서 상위에 노출되도록 하는 기법입니다. 키워드 분석과 콘텐츠 최적화가 중요합니다.\",\n",
    "        \"category\": \"tech\",\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"데이터베이스 설계 원칙\",\n",
    "        \"content\": \"효율적인 데이터베이스 설계는 데이터 중복을 최소화하고 무결성을 보장합니다. 정규화를 통해 테이블 구조를 최적화합니다.\",\n",
    "        \"category\": \"tech\",\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"사이버 보안 위협 대응\",\n",
    "        \"content\": \"사이버 공격으로부터 시스템을 보호하기 위해 방화벽, 암호화, 접근 제어 등의 보안 조치가 필요합니다.\",\n",
    "        \"category\": \"tech\",\n",
    "    },\n",
    "    # General/Business domain\n",
    "    {\n",
    "        \"title\": \"효과적인 마케팅 전략\",\n",
    "        \"content\": \"고객의 니즈를 파악하고 타겟 시장을 선정하는 것이 마케팅의 기본입니다. 디지털 마케팅과 SNS 활용이 중요해지고 있습니다.\",\n",
    "        \"category\": \"business\",\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"재무제표 분석 방법\",\n",
    "        \"content\": \"재무제표는 기업의 재무 상태를 보여주는 문서입니다. 손익계산서, 대차대조표, 현금흐름표를 통해 기업을 분석할 수 있습니다.\",\n",
    "        \"category\": \"business\",\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"스타트업 창업 가이드\",\n",
    "        \"content\": \"스타트업 창업 시 사업계획서 작성, 투자 유치, 팀 구성이 중요합니다. MVP를 통해 아이디어를 검증하세요.\",\n",
    "        \"category\": \"business\",\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"리더십과 팀 관리\",\n",
    "        \"content\": \"좋은 리더는 팀원들과 소통하고 동기부여를 합니다. 목표 설정과 피드백이 팀 성과 향상에 중요합니다.\",\n",
    "        \"category\": \"business\",\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"투자와 자산관리\",\n",
    "        \"content\": \"분산 투자를 통해 위험을 줄이고 장기적인 수익을 추구합니다. 주식, 채권, 부동산 등 다양한 자산에 투자하세요.\",\n",
    "        \"category\": \"business\",\n",
    "    },\n",
    "    # Additional documents\n",
    "    {\n",
    "        \"title\": \"환경 보호와 지속가능성\",\n",
    "        \"content\": \"기후변화에 대응하기 위해 탄소 배출을 줄이고 재생에너지를 활용해야 합니다. 지속가능한 발전이 중요합니다.\",\n",
    "        \"category\": \"general\",\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"교육의 미래와 온라인 학습\",\n",
    "        \"content\": \"온라인 교육 플랫폼이 확산되면서 언제 어디서나 학습이 가능해졌습니다. 개인화된 학습 경험을 제공합니다.\",\n",
    "        \"category\": \"general\",\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"건강한 식단 관리\",\n",
    "        \"content\": \"균형 잡힌 식단은 건강 유지의 기본입니다. 채소, 과일, 단백질을 적절히 섭취하고 가공식품은 줄이세요.\",\n",
    "        \"category\": \"general\",\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"여행 계획 세우기\",\n",
    "        \"content\": \"여행지 선정, 숙소 예약, 일정 계획이 여행 준비의 핵심입니다. 현지 문화와 음식을 미리 조사하세요.\",\n",
    "        \"category\": \"general\",\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"스트레스 관리 방법\",\n",
    "        \"content\": \"스트레스는 현대인의 건강을 위협합니다. 운동, 명상, 취미활동을 통해 스트레스를 효과적으로 해소하세요.\",\n",
    "        \"category\": \"general\",\n",
    "    },\n",
    "]\n",
    "\n",
    "print(f\"Total documents: {len(DOCUMENTS)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating sparse vectors...\n",
      "  Processed 5/25 documents\n",
      "  Processed 10/25 documents\n",
      "  Processed 15/25 documents\n",
      "  Processed 20/25 documents\n",
      "  Processed 25/25 documents\n",
      "Done! Generated sparse vectors for 25 documents\n"
     ]
    }
   ],
   "source": [
    "# Generate sparse vectors for all documents\n",
    "print(\"Generating sparse vectors...\")\n",
    "\n",
    "for i, doc in enumerate(DOCUMENTS):\n",
    "    # Generate sparse vectors for title and content\n",
    "    doc[\"title_sparse\"] = encode_sparse_full(doc[\"title\"], min_weight=0.5)\n",
    "    doc[\"content_sparse\"] = encode_sparse_full(doc[\"content\"], min_weight=0.5)\n",
    "    \n",
    "    if (i + 1) % 5 == 0:\n",
    "        print(f\"  Processed {i + 1}/{len(DOCUMENTS)} documents\")\n",
    "\n",
    "print(f\"Done! Generated sparse vectors for {len(DOCUMENTS)} documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample document:\n",
      "  Title: 손해배상 청구 소송\n",
      "  Category: legal\n",
      "  Title sparse tokens (3072): [('<unused5>', 0.5469), ('#', 0.9727), ('%', 0.5703), (',', 1.1016), ('-', 0.9883)]...\n",
      "  Content sparse tokens (28269): [('<unk>', 1.8281), ('<mask>', 0.5625), ('<unused17>', 0.7109), ('<unused21>', 0.5195), ('<unused23>', 0.5703)]...\n"
     ]
    }
   ],
   "source": [
    "# Check a sample document\n",
    "sample_doc = DOCUMENTS[0]\n",
    "print(f\"Sample document:\")\n",
    "print(f\"  Title: {sample_doc['title']}\")\n",
    "print(f\"  Category: {sample_doc['category']}\")\n",
    "print(f\"  Title sparse tokens ({len(sample_doc['title_sparse'])}): {list(sample_doc['title_sparse'].items())[:5]}...\")\n",
    "print(f\"  Content sparse tokens ({len(sample_doc['content_sparse'])}): {list(sample_doc['content_sparse'].items())[:5]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexed 25 documents\n"
     ]
    }
   ],
   "source": [
    "# Index documents\n",
    "def index_documents(documents: List[Dict]):\n",
    "    \"\"\"Index documents with pre-computed sparse vectors.\"\"\"\n",
    "    actions = []\n",
    "    for i, doc in enumerate(documents):\n",
    "        action = {\n",
    "            \"_index\": INDEX_NAME,\n",
    "            \"_id\": str(i + 1),\n",
    "            \"_source\": doc,\n",
    "        }\n",
    "        actions.append(action)\n",
    "    \n",
    "    try:\n",
    "        success, errors = bulk(client, actions, refresh=True)\n",
    "        print(f\"Indexed {success} documents\")\n",
    "        if errors:\n",
    "            print(f\"Errors: {errors}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error indexing: {e}\")\n",
    "\n",
    "index_documents(DOCUMENTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document count: 25\n"
     ]
    }
   ],
   "source": [
    "# Verify indexed documents\n",
    "response = client.count(index=INDEX_NAME)\n",
    "print(f\"Document count: {response['count']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Search with rank_feature Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparse_search(query: str, field: str = \"content_sparse\", size: int = 5) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Perform sparse vector search using rank_feature query.\n",
    "    \n",
    "    Generates sparse vector for query and searches using rank_feature.\n",
    "    \"\"\"\n",
    "    # Generate query sparse vector\n",
    "    query_sparse = encode_sparse_full(query, min_weight=0.5)\n",
    "    \n",
    "    # Build rank_feature query for each token\n",
    "    should_clauses = []\n",
    "    for token, weight in query_sparse.items():\n",
    "        should_clauses.append({\n",
    "            \"rank_feature\": {\n",
    "                \"field\": f\"{field}.{token}\",\n",
    "                \"boost\": weight,\n",
    "            }\n",
    "        })\n",
    "    \n",
    "    if not should_clauses:\n",
    "        print(f\"No valid tokens for query: {query}\")\n",
    "        return []\n",
    "    \n",
    "    search_body = {\n",
    "        \"size\": size,\n",
    "        \"query\": {\n",
    "            \"bool\": {\n",
    "                \"should\": should_clauses,\n",
    "            }\n",
    "        },\n",
    "        \"_source\": [\"title\", \"category\", \"content\"],\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = client.search(index=INDEX_NAME, body=search_body)\n",
    "        return response[\"hits\"][\"hits\"]\n",
    "    except Exception as e:\n",
    "        print(f\"Search error: {e}\")\n",
    "        return []\n",
    "\n",
    "\n",
    "def print_results(query: str, results: List[Dict]):\n",
    "    \"\"\"Print search results.\"\"\"\n",
    "    print(f\"\\nQuery: '{query}'\")\n",
    "    print(\"-\" * 60)\n",
    "    for i, hit in enumerate(results, 1):\n",
    "        print(f\"{i}. [{hit['_source']['category']}] {hit['_source']['title']}\")\n",
    "        print(f\"   Score: {hit['_score']:.4f}\")\n",
    "    if not results:\n",
    "        print(\"No results found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query: '손해배상'\n",
      "------------------------------------------------------------\n",
      "1. [legal] 손해배상 청구 소송\n",
      "   Score: 964.5612\n",
      "2. [legal] 계약 위반 및 해지\n",
      "   Score: 926.5616\n",
      "3. [legal] 부동산 매매 계약서\n",
      "   Score: 894.8417\n",
      "4. [legal] 이혼 소송과 재산분할\n",
      "   Score: 861.4494\n",
      "5. [business] 재무제표 분석 방법\n",
      "   Score: 845.6030\n",
      "\n",
      "Query: '계약 위반'\n",
      "------------------------------------------------------------\n",
      "1. [legal] 계약 위반 및 해지\n",
      "   Score: 956.9678\n",
      "2. [legal] 손해배상 청구 소송\n",
      "   Score: 889.4637\n",
      "3. [legal] 부동산 매매 계약서\n",
      "   Score: 876.0530\n",
      "4. [legal] 형사 소송 절차 안내\n",
      "   Score: 848.0267\n",
      "5. [legal] 이혼 소송과 재산분할\n",
      "   Score: 842.7261\n",
      "\n",
      "Query: '당뇨병 치료'\n",
      "------------------------------------------------------------\n",
      "1. [medical] 당뇨병 진단 및 치료\n",
      "   Score: 1539.4568\n",
      "2. [medical] 고혈압 관리 가이드\n",
      "   Score: 1492.2563\n",
      "3. [medical] 감기와 독감의 차이\n",
      "   Score: 1459.8280\n",
      "4. [medical] 암 조기 검진의 중요성\n",
      "   Score: 1401.4888\n",
      "5. [general] 건강한 식단 관리\n",
      "   Score: 1400.3647\n",
      "\n",
      "Query: '암 검진'\n",
      "------------------------------------------------------------\n",
      "1. [medical] 암 조기 검진의 중요성\n",
      "   Score: 756.8114\n",
      "2. [medical] 당뇨병 진단 및 치료\n",
      "   Score: 717.5651\n",
      "3. [medical] 감기와 독감의 차이\n",
      "   Score: 689.5749\n",
      "4. [medical] 고혈압 관리 가이드\n",
      "   Score: 686.9532\n",
      "5. [medical] 우울증 치료 방법\n",
      "   Score: 663.6484\n",
      "\n",
      "Query: '인공지능'\n",
      "------------------------------------------------------------\n",
      "1. [tech] 인공지능 기술 동향\n",
      "   Score: 750.9667\n",
      "2. [tech] 검색 엔진 최적화 가이드\n",
      "   Score: 614.4052\n",
      "3. [business] 효과적인 마케팅 전략\n",
      "   Score: 608.9392\n",
      "4. [tech] 클라우드 컴퓨팅 서비스\n",
      "   Score: 591.4534\n",
      "5. [general] 교육의 미래와 온라인 학습\n",
      "   Score: 549.1635\n",
      "\n",
      "Query: '검색 엔진'\n",
      "------------------------------------------------------------\n",
      "1. [tech] 검색 엔진 최적화 가이드\n",
      "   Score: 688.8321\n",
      "2. [tech] 인공지능 기술 동향\n",
      "   Score: 653.7181\n",
      "3. [business] 효과적인 마케팅 전략\n",
      "   Score: 650.1107\n",
      "4. [business] 스타트업 창업 가이드\n",
      "   Score: 616.8607\n",
      "5. [tech] 클라우드 컴퓨팅 서비스\n",
      "   Score: 604.7906\n",
      "\n",
      "Query: '투자 전략'\n",
      "------------------------------------------------------------\n",
      "1. [business] 스타트업 창업 가이드\n",
      "   Score: 845.7888\n",
      "2. [business] 투자와 자산관리\n",
      "   Score: 842.6621\n",
      "3. [business] 효과적인 마케팅 전략\n",
      "   Score: 827.7104\n",
      "4. [business] 재무제표 분석 방법\n",
      "   Score: 812.4267\n",
      "5. [tech] 검색 엔진 최적화 가이드\n",
      "   Score: 803.6546\n",
      "\n",
      "Query: '스트레스 해소'\n",
      "------------------------------------------------------------\n",
      "1. [general] 스트레스 관리 방법\n",
      "   Score: 1079.3570\n",
      "2. [medical] 고혈압 관리 가이드\n",
      "   Score: 954.7086\n",
      "3. [legal] 계약 위반 및 해지\n",
      "   Score: 946.9476\n",
      "4. [medical] 감기와 독감의 차이\n",
      "   Score: 926.9116\n",
      "5. [general] 건강한 식단 관리\n",
      "   Score: 924.6913\n"
     ]
    }
   ],
   "source": [
    "# Test sparse search\n",
    "TEST_QUERIES = [\n",
    "    \"손해배상\",\n",
    "    \"계약 위반\",\n",
    "    \"당뇨병 치료\",\n",
    "    \"암 검진\",\n",
    "    \"인공지능\",\n",
    "    \"검색 엔진\",\n",
    "    \"투자 전략\",\n",
    "    \"스트레스 해소\",\n",
    "]\n",
    "\n",
    "for query in TEST_QUERIES:\n",
    "    results = sparse_search(query)\n",
    "    print_results(query, results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Compare with BM25 Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bm25_search(query: str, size: int = 5) -> List[Dict]:\n",
    "    \"\"\"Perform BM25 text search.\"\"\"\n",
    "    search_body = {\n",
    "        \"size\": size,\n",
    "        \"query\": {\n",
    "            \"multi_match\": {\n",
    "                \"query\": query,\n",
    "                \"fields\": [\"title^2\", \"content\"],\n",
    "            }\n",
    "        },\n",
    "        \"_source\": [\"title\", \"category\"],\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = client.search(index=INDEX_NAME, body=search_body)\n",
    "        return response[\"hits\"][\"hits\"]\n",
    "    except Exception as e:\n",
    "        print(f\"Search error: {e}\")\n",
    "        return []\n",
    "\n",
    "\n",
    "def compare_search(query: str):\n",
    "    \"\"\"Compare sparse vs BM25 search.\"\"\"\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"Query: '{query}'\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Show query expansion\n",
    "    query_sparse = encode_sparse(query, top_k=10)\n",
    "    print(f\"\\n[Query Expansion]\")\n",
    "    print(f\"  {', '.join([f'{t}({w:.2f})' for t, w in list(query_sparse.items())[:8]])}\")\n",
    "    \n",
    "    print(f\"\\n[Sparse Search Results]\")\n",
    "    sparse_results = sparse_search(query)\n",
    "    for i, hit in enumerate(sparse_results[:3], 1):\n",
    "        print(f\"  {i}. [{hit['_source']['category']}] {hit['_source']['title']} (score: {hit['_score']:.2f})\")\n",
    "    \n",
    "    print(f\"\\n[BM25 Results]\")\n",
    "    bm25_results = bm25_search(query)\n",
    "    for i, hit in enumerate(bm25_results[:3], 1):\n",
    "        print(f\"  {i}. [{hit['_source']['category']}] {hit['_source']['title']} (score: {hit['_score']:.2f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "Query: '배상 청구'\n",
      "======================================================================\n",
      "\n",
      "[Query Expansion]\n",
      "  청구(3.16), 배상(3.11), 구(2.50), 보상(2.48), 요구(2.38), 청(2.27)\n",
      "\n",
      "[Sparse Search Results]\n",
      "  1. [legal] 계약 위반 및 해지 (score: 1131.26)\n",
      "  2. [legal] 손해배상 청구 소송 (score: 1113.73)\n",
      "  3. [legal] 부동산 매매 계약서 (score: 1065.51)\n",
      "\n",
      "[BM25 Results]\n",
      "  1. [legal] 손해배상 청구 소송 (score: 2.67)\n",
      "\n",
      "======================================================================\n",
      "Query: '병원 진찰'\n",
      "======================================================================\n",
      "\n",
      "[Query Expansion]\n",
      "  병원(3.12), 진(3.08), 병실(2.52), 의료(2.50), 진료(2.45), 진이(2.42), 질(2.41)\n",
      "\n",
      "[Sparse Search Results]\n",
      "  1. [medical] 암 조기 검진의 중요성 (score: 957.50)\n",
      "  2. [legal] 형사 소송 절차 안내 (score: 899.46)\n",
      "  3. [medical] 당뇨병 진단 및 치료 (score: 895.52)\n",
      "\n",
      "[BM25 Results]\n",
      "\n",
      "======================================================================\n",
      "Query: 'AI 기술'\n",
      "======================================================================\n",
      "\n",
      "[Query Expansion]\n",
      "  기술(3.14), AI(3.11), 인공지능(2.69), 기술력(2.45), IT(2.42), technology(2.42), 기(2.39), Technology(2.38)\n",
      "\n",
      "[Sparse Search Results]\n",
      "  1. [tech] 인공지능 기술 동향 (score: 1045.30)\n",
      "  2. [tech] 검색 엔진 최적화 가이드 (score: 1032.57)\n",
      "  3. [tech] 클라우드 컴퓨팅 서비스 (score: 1032.43)\n",
      "\n",
      "[BM25 Results]\n",
      "  1. [tech] 인공지능 기술 동향 (score: 2.67)\n",
      "\n",
      "======================================================================\n",
      "Query: '약정 체결'\n",
      "======================================================================\n",
      "\n",
      "[Query Expansion]\n",
      "  약정(3.03), 체결(2.97), 계약(2.61), 협정(2.42), 협약(2.41), 약속(2.38), 특약(2.33)\n",
      "\n",
      "[Sparse Search Results]\n",
      "  1. [legal] 부동산 매매 계약서 (score: 770.02)\n",
      "  2. [legal] 계약 위반 및 해지 (score: 734.67)\n",
      "  3. [legal] 이혼 소송과 재산분할 (score: 679.27)\n",
      "\n",
      "[BM25 Results]\n",
      "\n",
      "======================================================================\n",
      "Query: '투자 수익'\n",
      "======================================================================\n",
      "\n",
      "[Query Expansion]\n",
      "  투자(3.06), 수익(2.94), 투자자(2.67), 수입(2.31), 자본(2.30), 수익금(2.25)\n",
      "\n",
      "[Sparse Search Results]\n",
      "  1. [business] 투자와 자산관리 (score: 637.79)\n",
      "  2. [business] 스타트업 창업 가이드 (score: 610.67)\n",
      "  3. [business] 재무제표 분석 방법 (score: 609.96)\n",
      "\n",
      "[BM25 Results]\n",
      "  1. [business] 스타트업 창업 가이드 (score: 1.29)\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Compare searches - these queries test synonym expansion\n",
    "COMPARISON_QUERIES = [\n",
    "    \"배상 청구\",       # Should find 손해배상 documents\n",
    "    \"병원 진찰\",       # Should find 진단/치료 documents  \n",
    "    \"AI 기술\",         # Should find 인공지능 documents\n",
    "    \"약정 체결\",       # Should find 계약 documents\n",
    "    \"투자 수익\",       # Should find 투자/자산관리 documents\n",
    "]\n",
    "\n",
    "for query in COMPARISON_QUERIES:\n",
    "    compare_search(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Cleanup (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanup():\n",
    "    \"\"\"Clean up resources.\"\"\"\n",
    "    try:\n",
    "        client.indices.delete(index=INDEX_NAME)\n",
    "        print(f\"Deleted index: {INDEX_NAME}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error deleting index: {e}\")\n",
    "\n",
    "# Uncomment to cleanup\n",
    "# cleanup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrates:\n",
    "\n",
    "1. **Local Model Loading**: Load korean-neural-sparse-encoder-v1 from huggingface folder\n",
    "2. **Sparse Vector Generation**: Generate sparse vectors using the model\n",
    "3. **OpenSearch Indexing**: Index documents with pre-computed sparse vectors using `rank_features` field\n",
    "4. **Sparse Search**: Search using `rank_feature` query with query expansion\n",
    "5. **BM25 Comparison**: Compare sparse search with traditional BM25\n",
    "\n",
    "### Key Findings\n",
    "\n",
    "The sparse search should show better synonym matching:\n",
    "- \"배상 청구\" → finds \"손해배상\" documents (synonym expansion)\n",
    "- \"AI 기술\" → finds \"인공지능\" documents (AI ↔ 인공지능)\n",
    "- \"약정 체결\" → finds \"계약\" documents (약정 ↔ 계약)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

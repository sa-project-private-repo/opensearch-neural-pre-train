# OpenSearch Neural Sparse Pre-training ê°œì„  ê³„íš

## í”„ë¡œì íŠ¸ ëª©í‘œ

ë‰´ìŠ¤ ë°ì´í„°ë¥¼ í™œìš©í•˜ì—¬ ì‹œê°„ ê°€ì¤‘ì¹˜ ê¸°ë°˜ êµ°ì§‘í™”ë¡œ ë™ì˜ì–´ë¥¼ ë°œê²¬í•˜ê³ , ë¹„ì§€ë„ í•™ìŠµ ë°©ì‹ìœ¼ë¡œ í•œêµ­ì–´ Neural Sparse ê²€ìƒ‰ ëª¨ë¸ì„ ê°œì„ í•©ë‹ˆë‹¤.

## ë°œê²¬ëœ ì£¼ìš” ë¬¸ì œì 

### ğŸ”´ CRITICAL ë¬¸ì œ
- [ ] **ì†ì‹¤ í•¨ìˆ˜ ì˜¤ë¥˜**: BCE with logitsê°€ dot product similarityì™€ ë§ì§€ ì•ŠìŒ
- [ ] **Contrastive Learning ë¶€ì¬**: Query-document rankingì„ ì œëŒ€ë¡œ í•™ìŠµí•˜ì§€ ëª»í•¨
- [ ] **ì‹œê°„ ì •ë³´ ë¯¸í™œìš©**: ë‰´ìŠ¤ ë°ì´í„°ì˜ ë‚ ì§œ ì •ë³´ë¥¼ ì „í˜€ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ

### ğŸŸ¡ MODERATE ë¬¸ì œ
- [ ] **ì•½í•œ Negative Sampling**: ëœë¤ negative 2ê°œë§Œ ì‚¬ìš©
- [ ] **í•™ìŠµ ë°ì´í„° ë¶€ì¡±**: 10k pairsë¡œëŠ” ë¶€ì¡±
- [ ] **í•˜ë“œì½”ë”©ëœ íŠ¸ë Œë“œ í‚¤ì›Œë“œ**: ìˆ˜ë™ìœ¼ë¡œ ì •ì˜ëœ TREND_BOOST

### ğŸŸ¢ MINOR ë¬¸ì œ
- [ ] **ê³¼ë„í•œ Sparsity**: L0 regularizationì´ ë„ˆë¬´ ê°•í•¨ (99.98%)
- [ ] **IDF penalty ëª¨ìˆœ**: Document encoderê°€ IDF statisticsì— ì˜ì¡´

---

## Phase 1: ì†ì‹¤ í•¨ìˆ˜ ë° í•™ìŠµ íŒŒì´í”„ë¼ì¸ ìˆ˜ì • (ìµœìš°ì„ )

### 1.1 ìƒˆë¡œìš´ ì†ì‹¤ í•¨ìˆ˜ êµ¬í˜„
- [ ] In-batch negatives loss í•¨ìˆ˜ ì‘ì„±
  - File: `src/losses.py` (ì‹ ê·œ)
  - í•¨ìˆ˜: `in_batch_negatives_loss()`, `margin_ranking_loss()`
  - Temperature scaling íŒŒë¼ë¯¸í„° ì¶”ê°€

- [ ] Contrastive loss with hard negatives
  - í•¨ìˆ˜: `contrastive_loss_with_hard_negatives()`
  - Triplet margin loss ì˜µì…˜ ì¶”ê°€

### 1.2 í•™ìŠµ íŒŒì´í”„ë¼ì¸ ìˆ˜ì •
- [ ] Batch size ì¦ê°€ (8 â†’ 32 or 64)
  - korean_neural_sparse_training.ipynb ìˆ˜ì •
  - GPU ë©”ëª¨ë¦¬ í™•ì¸ ë° ìµœì í™”

- [ ] ì†ì‹¤ í•¨ìˆ˜ êµì²´
  - BCE â†’ In-batch negatives loss
  - í•˜ì´í¼íŒŒë¼ë¯¸í„° ì¡°ì • (temperature=0.05)

### 1.3 í…ŒìŠ¤íŠ¸ ë° ê²€ì¦
- [ ] test_korean_neural_sparse.py ì—…ë°ì´íŠ¸
  - ìƒˆë¡œìš´ ì†ì‹¤ í•¨ìˆ˜ë¡œ êµì²´
  - í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸ ê²€ì¦

- [ ] ê°„ë‹¨í•œ í•™ìŠµ ì‹¤í–‰ ë° loss curve í™•ì¸

---

## Phase 2: ë°ì´í„° ë¡œë”© ë° ì‹œê°„ ê¸°ë°˜ ë¶„ì„ êµ¬í˜„

### 2.1 ë‰´ìŠ¤ ë°ì´í„° ë¡œë”© ê°œì„ 
- [ ] ë‚ ì§œ ì •ë³´ ì¶”ì¶œ ë° ë³´ì¡´
  - File: `src/data_loader.py` (ì‹ ê·œ)
  - í•¨ìˆ˜: `load_korean_news_with_dates()`
  - ë°ì´í„° êµ¬ì¡°: `{text, date, category, ...}`

- [ ] ë°ì´í„°ì…‹ ë‹¤ê°í™”
  - HuggingFace ë‰´ìŠ¤ ë°ì´í„°ì…‹ ì¶”ê°€ íƒìƒ‰
  - RSS í”¼ë“œ í¬ë¡¤ëŸ¬ êµ¬í˜„ (ì„ íƒ)
  - ìµœì†Œ 50k+ documents í™•ë³´

### 2.2 ì‹œê°„ ê°€ì¤‘ì¹˜ ê¸°ë°˜ IDF êµ¬í˜„
- [ ] Temporal IDF í•¨ìˆ˜ ì‘ì„±
  - File: `src/temporal_analysis.py` (ì‹ ê·œ)
  - í•¨ìˆ˜: `calculate_temporal_idf(documents, dates, decay_factor=0.95)`
  - Exponential decay: weight = decay_factor^(days_old)

- [ ] ì‹œê°„ ìœˆë„ìš°ë³„ IDF ê³„ì‚°
  - í•¨ìˆ˜: `calculate_windowed_idf(documents, dates, window_days=[30, 90, 365])`
  - ì—¬ëŸ¬ ì‹œê°„ëŒ€ì˜ IDFë¥¼ ì•™ìƒë¸”

### 2.3 ìë™ íŠ¸ë Œë“œ ê°ì§€ êµ¬í˜„
- [ ] íŠ¸ë Œë“œ í† í° ìë™ ë°œê²¬
  - í•¨ìˆ˜: `detect_trending_tokens(documents, dates, recent_days=30)`
  - ìµœê·¼ ë¹ˆë„ vs ê³¼ê±° ë¹ˆë„ ë¹„êµ
  - TREND_BOOST ë”•ì…”ë„ˆë¦¬ ìë™ ìƒì„±

- [ ] ì‹œê°„ëŒ€ë³„ ë‹¨ì–´ ë¹ˆë„ ë¶„ì„
  - í•¨ìˆ˜: `analyze_token_frequency_over_time(documents, dates, tokens)`
  - ì‹œê³„ì—´ ë°ì´í„°ë¡œ ì €ì¥

---

## Phase 3: í•˜ë“œì½”ë”© ì œê±° ë° ë¹„ì§€ë„ í•™ìŠµ ê°•í™”

### 3.1 Hard Negative Mining êµ¬í˜„
- [ ] BM25 ê¸°ë°˜ hard negatives
  - File: `src/negative_sampling.py` (ì‹ ê·œ)
  - í•¨ìˆ˜: `add_hard_negatives_bm25(qd_pairs, documents, top_k=100)`
  - rank-bm25 ë¼ì´ë¸ŒëŸ¬ë¦¬ í™œìš©

- [ ] Negative sampling ì „ëµ ê°œì„ 
  - Random negatives: 50%
  - Hard negatives: 50%
  - Negatives per query: 2 â†’ 8+

### 3.2 í•˜ë“œì½”ë”©ëœ ìš”ì†Œ ì œê±°
- [ ] SAMPLE_DOCUMENTS â†’ ì‹¤ì œ ë°ì´í„° ìƒ˜í”Œë§ìœ¼ë¡œ êµì²´
  - test_korean_neural_sparse.py ìˆ˜ì •
  - ëœë¤ ìƒ˜í”Œë§ í•¨ìˆ˜ ì‚¬ìš©

- [ ] TREND_BOOST â†’ ìë™ ê°ì§€ë¡œ êµì²´
  - temporal_analysis.pyì˜ detect_trending_tokens() í™œìš©
  - ë™ì  ë¶€ìŠ¤íŒ… íŒ©í„° ê³„ì‚°

- [ ] ai_domain_terminology.py ì‚¬ìš© ë°©ì‹ ë³€ê²½
  - ì°¸ê³ ìš©/ê²€ì¦ìš©ìœ¼ë¡œë§Œ ì‚¬ìš©
  - ìë™ ë°œê²¬ëœ ë™ì˜ì–´ ìš°ì„  ì ìš©

### 3.3 ë°ì´í„° ì¦ê°• ê°œì„ 
- [ ] Synonym-based augmentation ê°•í™”
  - í˜„ì¬ expansion_ratio=0.2 â†’ 0.5ë¡œ ì¦ê°€
  - ì‹œê°„ ê¸°ë°˜ ë™ì˜ì–´ í™œìš©

- [ ] Query generation
  - ë¬¸ì„œì—ì„œ ìë™ìœ¼ë¡œ query ìƒì„±
  - T5/BART ë“± ìƒì„± ëª¨ë¸ í™œìš© (ì„ íƒ)

---

## Phase 4: ì‹œê°„ ê°€ì¤‘ì¹˜ ê¸°ë°˜ êµ°ì§‘í™” ë° ë™ì˜ì–´ ë°œê²¬

### 4.1 ì‹œê°„ ê¸°ë°˜ í† í° ì„ë² ë”© í´ëŸ¬ìŠ¤í„°ë§
- [ ] ì‹œê°„ ìœˆë„ìš°ë³„ ì„ë² ë”© ì¶”ì¶œ
  - File: `src/temporal_clustering.py` (ì‹ ê·œ)
  - í•¨ìˆ˜: `extract_temporal_embeddings(documents, dates, time_windows)`
  - ê° ì‹œê°„ëŒ€ë³„ë¡œ BERT í† í° ì„ë² ë”© ì¶”ì¶œ

- [ ] êµ°ì§‘í™” ì•Œê³ ë¦¬ì¦˜ ì ìš©
  - í•¨ìˆ˜: `cluster_tokens_temporal(embeddings, method='kmeans', n_clusters=500)`
  - K-means, DBSCAN, Hierarchical clustering ì˜µì…˜
  - ì‹œê°„ì— ë”°ë¥¸ êµ°ì§‘ ë³€í™” ì¶”ì 

### 4.2 ë™ì˜ì–´ ìë™ ë°œê²¬ ê°œì„ 
- [ ] ì‹œê°„ ê°€ì¤‘ì¹˜ ì ìš© ë™ì˜ì–´ ë°œê²¬
  - í•¨ìˆ˜: `discover_synonyms_temporal(documents, dates, embeddings, decay_factor=0.95)`
  - ìµœê·¼ ë°ì´í„°ì— ë†’ì€ ê°€ì¤‘ì¹˜
  - Cosine similarity threshold: 0.75

- [ ] êµ°ì§‘ ê¸°ë°˜ ë™ì˜ì–´ ê·¸ë£¹ í˜•ì„±
  - í•¨ìˆ˜: `build_synonym_groups_from_clusters(clusters, embeddings, threshold=0.8)`
  - ê° í´ëŸ¬ìŠ¤í„°ë¥¼ ë™ì˜ì–´ ê·¸ë£¹ìœ¼ë¡œ ê°„ì£¼
  - ì‹ ë¢°ë„ ì ìˆ˜ ê³„ì‚°

### 4.3 LLM ê¸°ë°˜ ë™ì˜ì–´ ê²€ì¦ (ì„ íƒ)
- [ ] ë¡œì»¬ LLM ë¡œë”©
  - File: `src/llm_validator.py` (ì‹ ê·œ)
  - ëª¨ë¸: GPT-OSS-20B ë˜ëŠ” ì–‘ìí™”ëœ 120B
  - 4-bit quantization ì ìš©

- [ ] ë™ì˜ì–´ í›„ë³´ ê²€ì¦
  - í•¨ìˆ˜: `validate_synonyms_with_llm(synonym_pairs, llm_model)`
  - Batch processingìœ¼ë¡œ íš¨ìœ¨ì„± í™•ë³´
  - ê²€ì¦ í†µê³¼í•œ ë™ì˜ì–´ë§Œ ì‚¬ìš©

---

## Phase 5: í†µí•© ë° í…ŒìŠ¤íŠ¸

### 5.1 ì „ì²´ íŒŒì´í”„ë¼ì¸ í†µí•©
- [ ] korean_neural_sparse_training.ipynb ì „ë©´ ìˆ˜ì •
  - ìƒˆë¡œìš´ ëª¨ë“ˆë“¤ import
  - ì „ì²´ í”Œë¡œìš° ì¬êµ¬ì„±
  - ì„¹ì…˜ë³„ ì„¤ëª… markdown ì¶”ê°€

- [ ] ì„¤ì • íŒŒì¼ ì‘ì„±
  - File: `config.yaml` (ì‹ ê·œ)
  - ëª¨ë“  í•˜ì´í¼íŒŒë¼ë¯¸í„° ì¤‘ì•™í™”
  - ì‹¤í—˜ ì„¤ì • ë²„ì „ ê´€ë¦¬

### 5.2 í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸ ì‘ì„±
- [ ] CLI í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸
  - File: `train.py` (ì‹ ê·œ)
  - argparseë¡œ íŒŒë¼ë¯¸í„° ì œì–´
  - ì²´í¬í¬ì¸íŠ¸ ì €ì¥/ë¡œë“œ ê¸°ëŠ¥

- [ ] í‰ê°€ ìŠ¤í¬ë¦½íŠ¸
  - File: `evaluate.py` (ì‹ ê·œ)
  - ê²€ìƒ‰ ì„±ëŠ¥ í‰ê°€ (MRR, NDCG, Recall@K)
  - Sparsity ë¶„ì„

### 5.3 ë¬¸ì„œí™” ë° ê²€ì¦
- [ ] README ì—…ë°ì´íŠ¸
  - ì „ì²´ ì›Œí¬í”Œë¡œìš° ì„¤ëª…
  - ì‹¤í–‰ ë°©ë²• ê°€ì´ë“œ
  - ìš”êµ¬ì‚¬í•­ ë° ì„¤ì¹˜

- [ ] ìµœì¢… í…ŒìŠ¤íŠ¸
  - End-to-end í•™ìŠµ ì‹¤í–‰
  - ê²°ê³¼ ë¶„ì„ ë° ë¦¬í¬íŠ¸ ì‘ì„±
  - ê¸°ì¡´ ëª¨ë¸ ëŒ€ë¹„ ì„±ëŠ¥ ë¹„êµ

---

## ë””ë ‰í† ë¦¬ êµ¬ì¡° (ì˜ˆì •)

```
opensearch-neural-pre-train/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ losses.py                    # Phase 1
â”‚   â”œâ”€â”€ data_loader.py               # Phase 2
â”‚   â”œâ”€â”€ temporal_analysis.py         # Phase 2
â”‚   â”œâ”€â”€ negative_sampling.py         # Phase 3
â”‚   â”œâ”€â”€ temporal_clustering.py       # Phase 4
â”‚   â””â”€â”€ llm_validator.py            # Phase 4 (ì„ íƒ)
â”œâ”€â”€ config.yaml                      # Phase 5
â”œâ”€â”€ train.py                         # Phase 5
â”œâ”€â”€ evaluate.py                      # Phase 5
â”œâ”€â”€ korean_neural_sparse_training.ipynb
â”œâ”€â”€ neural_sparse_inference.ipynb
â”œâ”€â”€ test_korean_neural_sparse.py
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md

```

---

## ì‹¤í–‰ ìˆœì„œ

### Stage 1: ê¸´ê¸‰ ìˆ˜ì • (1-2ì¼)
1. Phase 1.1-1.2: ì†ì‹¤ í•¨ìˆ˜ ìˆ˜ì • ë° í…ŒìŠ¤íŠ¸
2. Phase 1.3: ê°„ë‹¨í•œ í•™ìŠµìœ¼ë¡œ ê²€ì¦

### Stage 2: ë°ì´í„° ê°œì„  (2-3ì¼)
3. Phase 2.1: ë‰´ìŠ¤ ë°ì´í„° ë‚ ì§œ ì •ë³´ ì¶”ì¶œ
4. Phase 2.2: Temporal IDF êµ¬í˜„
5. Phase 2.3: ìë™ íŠ¸ë Œë“œ ê°ì§€

### Stage 3: ë¹„ì§€ë„ í•™ìŠµ ê°•í™” (2-3ì¼)
6. Phase 3.1: Hard negative mining
7. Phase 3.2: í•˜ë“œì½”ë”© ì œê±°
8. Phase 3.3: ë°ì´í„° ì¦ê°•

### Stage 4: ê³ ê¸‰ ê¸°ëŠ¥ (3-4ì¼)
9. Phase 4.1: ì‹œê°„ ê¸°ë°˜ êµ°ì§‘í™”
10. Phase 4.2: ë™ì˜ì–´ ìë™ ë°œê²¬
11. Phase 4.3: LLM ê²€ì¦ (ì„ íƒ)

### Stage 5: í†µí•© (1-2ì¼)
12. Phase 5.1-5.3: í†µí•© ë° ë¬¸ì„œí™”

---

## ì„±ê³µ ê¸°ì¤€

- [ ] **ì†ì‹¤ í•¨ìˆ˜ ë¬¸ì œ í•´ê²°**: Lossê°€ ì •ìƒì ìœ¼ë¡œ ê°ì†Œ
- [ ] **ì‹œê°„ ì •ë³´ í™œìš©**: Temporal IDFê°€ ì‘ë™í•˜ê³  íŠ¸ë Œë“œ ê°ì§€ ì„±ê³µ
- [ ] **í•˜ë“œì½”ë”© ì œê±°**: ìë™í™”ëœ íŠ¸ë Œë“œ ê°ì§€ ë° ë™ì˜ì–´ ë°œê²¬
- [ ] **ê²€ìƒ‰ ì„±ëŠ¥ ê°œì„ **: ê¸°ì¡´ ëŒ€ë¹„ MRR/NDCG í–¥ìƒ
- [ ] **ë¹„ì§€ë„ í•™ìŠµ ë‹¬ì„±**: ìˆ˜ë™ ë ˆì´ë¸” ì—†ì´ ë™ì˜ì–´ ë°œê²¬
- [ ] **ì¬í˜„ ê°€ëŠ¥ì„±**: ì „ì²´ íŒŒì´í”„ë¼ì¸ì´ config.yamlë¡œ ì¬í˜„ ê°€ëŠ¥

---

## ìœ„í—˜ ìš”ì†Œ ë° ëŒ€ì‘

| ìœ„í—˜ ìš”ì†Œ | ëŒ€ì‘ ë°©ì•ˆ |
|----------|----------|
| GPU ë©”ëª¨ë¦¬ ë¶€ì¡± (batch size ì¦ê°€) | Gradient accumulation ì‚¬ìš© |
| ë‰´ìŠ¤ ë°ì´í„° ë‚ ì§œ ì •ë³´ ì—†ìŒ | ëŒ€ì²´ ë°ì´í„°ì…‹ íƒìƒ‰ ë˜ëŠ” í¬ë¡¤ë§ |
| LLM ë¡œë”© ì‹¤íŒ¨ (ë©”ëª¨ë¦¬) | 4-bit quantization ë˜ëŠ” ë” ì‘ì€ ëª¨ë¸ |
| í•™ìŠµ ì‹œê°„ ê³¼ë‹¤ | ë°ì´í„° ìƒ˜í”Œë§ ë˜ëŠ” ë¶„ì‚° í•™ìŠµ |
| ì„±ëŠ¥ ì €í•˜ | í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ ë° ablation study |

---

## ì§„í–‰ ìƒí™© ì¶”ì 

- ê° ì²´í¬ë°•ìŠ¤ ì™„ë£Œ ì‹œ `[x]`ë¡œ í‘œì‹œ
- Git commit ì‹œ conventional commits ê·œì¹™ ì¤€ìˆ˜
- ê° Phase ì™„ë£Œ ì‹œ í…ŒìŠ¤íŠ¸ ë° ê²€ì¦ í•„ìˆ˜
